{"id":268291396,"title":"PAC Subset Selection in Stochastic Multi-armed Bandits","authors":["Shivaram Kalyanakrishnan","Ambuj Tewari","Peter Auer","Peter Stone"],"_abstract":"ABSTRACT We consider the problem of selecting, from among the arms of a stochastic n-armed bandit, a subset of size m of those arms with the highest expected rewards, based on efficiently sampling the arms. This \"sub-set selection\" problem finds application in a variety of areas. In the authors' previ-ous work (Kalyanakrishnan & Stone, 2010), this problem is framed under a PAC setting (denoted \"Explore-m\"), and corresponding sampling algorithms are analyzed. Whereas the formal analysis therein is restricted to the worst case sample complexity of algo-rithms, in this paper, we design and ana-lyze an algorithm (\"LUCB\") with improved expected sample complexity. Interestingly LUCB bears a close resemblance to the well-known UCB algorithm for regret minimiza-tion. The expected sample complexity bound we show for LUCB is novel even for single-arm selection (Explore-1). We also give a lower bound on the worst case sample com-plexity of PAC algorithms for Explore-m.","cited_in":[{"id":277924329,"url":"https://www.researchgate.net/publication/277924329_Qualitative_Multi-Armed_Bandits_A_Quantile-Based_Approach"},{"id":263545276,"url":"https://www.researchgate.net/publication/263545276_Unimodal_Bandits_without_Smoothness"},{"id":234061312,"url":"https://www.researchgate.net/publication/234061312_Best_Arm_Identification_A_Unified_Approach_to_Fixed_Budget_and_Fixed_Confidence"},{"id":224959372,"url":"https://www.researchgate.net/publication/224959372_Multiple_Identifications_in_Multi-Armed_Bandits"},{"id":262487539,"url":"https://www.researchgate.net/publication/262487539_Top-k_Selection_based_on_Adaptive_Sampling_of_Noisy_Preferences"},{"id":269270916,"url":"https://www.researchgate.net/publication/269270916_Finding_Discriminatory_Genes_A_Methodology_for_Validating_Microarray_Studies"},{"id":259478458,"url":"https://www.researchgate.net/publication/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits"},{"id":277924144,"url":"https://www.researchgate.net/publication/277924144_PAC_Rank_Elicitation_through_Adaptive_Sampling_of_Stochastic_Pairwise_Preferences"},{"id":269307620,"url":"https://www.researchgate.net/publication/269307620_Best-arm_identification_algorithms_for_multi-armed_bandits_in_the_fixed_confidence_setting"},{"id":261836774,"url":"https://www.researchgate.net/publication/261836774_Most_Correlated_Arms_Identification"},{"id":267215308,"url":"https://www.researchgate.net/publication/267215308_Preference-Based_reinforcement_learning_Evolutionary_direct_policy_search_using_a_Preference-Based_racing_algorithm"},{"id":281854812,"url":"https://www.researchgate.net/publication/281854812_Combinatorial_pure_exploration_of_multi-armed_bandits"},{"id":281520830,"url":"https://www.researchgate.net/publication/281520830_Sparse_Zero-Sum_Games_as_Stable_Functional_Feature_Selection"},{"id":288059862,"url":"https://www.researchgate.net/publication/288059862_Satisficing_in_multi-armed_bandit_problems"}],"reference":["https://www.researchgate.net/publication/220320322_Action_Elimination_and_Stopping_Conditions_for_the_Multi-Armed_Bandit_and_Reinforcement_Learning_Problems","https://www.researchgate.net/publication/221497549_Best_Arm_Identification_in_Multi-Armed_Bandits","https://www.researchgate.net/publication/2942622_The_Sample_Complexity_of_Exploration_in_the_Multi-Armed_Bandit_Problem","https://www.researchgate.net/publication/2788600_Sequential_PAC_Learning","https://www.researchgate.net/publication/221344896_Efficient_Selection_of_Multiple_Bandit_Arms_Theory_and_Practice","https://www.researchgate.net/publication/220343796_Finite-time_Analysis_of_the_Multiarmed_Bandit_Problem","https://www.researchgate.net/publication/221346082_Empirical_Bernstein_stopping"]}