{"id":3087002,"title":"Correction to “The Importance of Convexity in Learning With Squared Loss” [Sep 98 1974-1980]","authors":["Lee Wee","Peter Bartlett","R.C. Williamson"],"_abstract":"ABSTRACT The paper “The Importance of Convexity in Learning with Squared Loss” gave a lower bound on the sample complexity of learning with quadratic loss using a nonconvex function class. The proof contains an error. We show that the lower bound is true under a stronger condition that holds for many cases of interest.","cited_in":[{"id":221618614,"url":"https://www.researchgate.net/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning"},{"id":236736803,"url":"https://www.researchgate.net/publication/236736803_Learning_Using_Large_Datasets"},{"id":3086992,"url":"https://www.researchgate.net/publication/3086992_Lower_Bounds_for_the_Empirical_Minimization_Algorithm"}],"reference":["https://www.researchgate.net/publication/239666708_Best_Approximation_in_Inner-Product_Spaces","https://www.researchgate.net/publication/3086721_An_Algebraic_Analytic_and_Algorithmic_Investigation_on_the_Capacity_and_Capacity-Achieving_Input_Probability_Distributions_of_Finite-Input-_Finite-Output_Discrete_Memoryless_Channels","https://www.researchgate.net/publication/3086992_Lower_Bounds_for_the_Empirical_Minimization_Algorithm","https://www.researchgate.net/publication/220360940_Convergence_rates_for_single_hidden_layer_feedforward_networks","https://www.researchgate.net/publication/2295809_Agnostic_PAC-Learning_of_Functions_on_Analog_Neural_Nets","https://www.researchgate.net/publication/222505227_A_generalization_of_Sauer's_lemma","https://www.researchgate.net/publication/242529553_Introduction_to_statistical_pattern_recognition_2nd_ed","https://www.researchgate.net/publication/222190436_Decision_Theoretic_Generalizations_of_the_PAC_Model_for_Neural_Net_and_Other_Learning_Applications","https://www.researchgate.net/publication/220570748_Bounding_Sample_Size_with_the_Vapnik-Chervonenkis_Dimension","https://www.researchgate.net/publication/2322859_On_Efficient_Agnostic_Learning_of_Linear_Combinations_of_Basis_Functions","https://www.researchgate.net/publication/258229723_Convergence_of_stochastic_processes","https://www.researchgate.net/publication/226947811_Toward_Efficient_Agnostic_Learning","https://www.researchgate.net/publication/238681227_Complexity_Regularization_with_Application_to_Artificial_Neural_Networks","https://www.researchgate.net/publication/2261777_Uniform_Ratio_Limit_Theorems_for_Empirical_Processes","https://www.researchgate.net/publication/3079570_The_importance_of_convexity_in_learning_with_squared_loss","https://www.researchgate.net/publication/3087011_Correction_to_An_Algebraic_Analytic_and_Algorithmic_Investigation_on_the_Capacity_and_Capacity-Achieving_Input_Probability_Distributions_of_Finite-Input-Finite-Output_Discrete_Memoryless_Channels_Mar_"]}