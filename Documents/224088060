{"id":224088060,"title":"OpenEAR - Introducing the Munich open-source emotion and affect recognition toolkit","authors":["Florian Eyben","Martin Wollmer","Bj√∂rn Schuller"],"_abstract":"ABSTRACT Various open-source toolkits exist for speech recognition and speech processing. These toolkits have brought a great benefit to the research community, i.e. speeding up research. Yet, no such freely available toolkit exists for automatic affect recognition from speech. We herein introduce a novel open-source affect and emotion recognition engine, which integrates all necessary components in one highly efficient software package. The components include audio recording and audio file reading, state-of-the-art paralinguistic feature extraction and plugable classification modules. In this paper we introduce the engine and extensive baseline results. Pre-trained models for four affect recognition tasks are included in the openEAR distribution. The engine is tailored for multi-threaded, incremental on-line processing of live input in real-time, however it can also be used for batch processing of databases.","cited_in":[{"id":275208397,"url":"https://www.researchgate.net/publication/275208397_Speaker-Independent_Speech_Emotion_Recognition_using_Gaussian_and_SVM_Classifiers"},{"id":269636311,"url":"https://www.researchgate.net/publication/269636311_A_Broadcast_News_Corpus_for_Evaluation_and_Tuning_of_German_LVCSR_Systems"},{"id":281276446,"url":"https://www.researchgate.net/publication/281276446_Emotion_Recognition_In_The_Wild_Challenge_2014_Baseline_Data_and_Protocol"},{"id":267213794,"url":"https://www.researchgate.net/publication/267213794_Speech_Emotion_Recognition_Using_Deep_Neural_Network_and_Extreme_Learning_Machine"},{"id":262697799,"url":"https://www.researchgate.net/publication/262697799_COVAREP_-_A_collaborative_voice_analysis_repository_for_speech_technologies"},{"id":261235391,"url":"https://www.researchgate.net/publication/261235391_A_two-layer_model_for_music_pleasure_regression"},{"id":257267505,"url":"https://www.researchgate.net/publication/257267505_Speaker_state_recognition_using_an_HMM-based_feature_extraction_method"},{"id":229439065,"url":"https://www.researchgate.net/publication/229439065_Automatic_Speaker_Age_and_Gender_Recognition_Using_Acoustic_and_Prosodic_Level_Information_Fusion"},{"id":260591658,"url":"https://www.researchgate.net/publication/260591658_Automated_Acoustic_Classification_of_Bird_Species_from_Real_-Field_Recordings"},{"id":262203674,"url":"https://www.researchgate.net/publication/262203674_AVEC_2012_-_The_continuous_audiovisual_emotion_challenge_-_Aon"},{"id":261280145,"url":"https://www.researchgate.net/publication/261280145_Comparison_between_decision-level_and_feature-level_fusion_of_acoustic_and_linguistic_features_for_spontaneous_emotion_recognition"},{"id":241880731,"url":"https://www.researchgate.net/publication/241880731_Iterative_Perceptual_Learning_for_Social_Behavior_Synthesis"},{"id":224929613,"url":"https://www.researchgate.net/publication/224929613_AVEC_2012_--_The_Continuous_AudioVisual_Emotion_Challenge"},{"id":261469543,"url":"https://www.researchgate.net/publication/261469543_Combining_semantic_and_acoustic_features_for_valence_and_arousal_recognition_in_speech"},{"id":224929626,"url":"https://www.researchgate.net/publication/224929626_Unsupervised_Learning_in_Cross-Corpus_Acoustic_Emotion_Recognition"},{"id":224246179,"url":"https://www.researchgate.net/publication/224246179_A_supervised_approach_to_movie_emotion_tracking"},{"id":224246423,"url":"https://www.researchgate.net/publication/224246423_Sentence_level_emotion_recognition_based_on_decisions_from_subsentence_segments"},{"id":220733712,"url":"https://www.researchgate.net/publication/220733712_Deep_neural_networks_for_acoustic_emotion_recognition_Raising_the_benchmarks"},{"id":220395367,"url":"https://www.researchgate.net/publication/220395367_Real-Time_Recognition_of_Affective_States_from_Nonverbal_Features_of_Speech_and_Its_Application_for_Public_Speaking_Skill_Analysis"},{"id":224929625,"url":"https://www.researchgate.net/publication/224929625_Using_Multiple_Databases_for_Training_in_Emotion_Recognition_To_Unite_or_to_Vote"},{"id":221490104,"url":"https://www.researchgate.net/publication/221490104_Intoxicated_Speech_Detection_by_Fusion_of_Speaker_Normalized_Hierarchical_Features_and_GMM_Supervectors"},{"id":221478974,"url":"https://www.researchgate.net/publication/221478974_Detecting_Sleepiness_by_Fusing_Classifiers_Trained_with_Novel_Acoustic_Features"},{"id":224155355,"url":"https://www.researchgate.net/publication/224155355_Combining_Long_Short-Term_Memory_and_Dynamic_Bayesian_Networks_for_Incremental_Emotion-Sensitive_Artificial_Listening"},{"id":220931779,"url":"https://www.researchgate.net/publication/220931779_Multi-modal_Emotion_Recognition_Using_Canonical_Correlations_and_Acoustic_Features"},{"id":224929656,"url":"https://www.researchgate.net/publication/224929656_The_Essential_Role_of_Language_Resources_for_the_Future_of_Affective_Computing_Systems_A_Recognition_Perspective"},{"id":221483263,"url":"https://www.researchgate.net/publication/221483263_Automatic_classification_of_married_couples'_behavior_using_audio_features"},{"id":228823351,"url":"https://www.researchgate.net/publication/228823351_Considering_Social_and_Emotional_Artificial_Intelligence"},{"id":221479914,"url":"https://www.researchgate.net/publication/221479914_Context-sensitive_multimodal_emotion_recognition_from_speech_and_facial_expression_using_bidirectional_LSTM_modeling"},{"id":221483420,"url":"https://www.researchgate.net/publication/221483420_A_quick_sequential_forward_floating_feature_selection_algorithm_for_emotion_detection_from_speech"},{"id":240319317,"url":"https://www.researchgate.net/publication/240319317_Selecting_appropriate_agent_responses_based_on_noncontent_features"},{"id":221482737,"url":"https://www.researchgate.net/publication/221482737_A_novel_feature_extraction_strategy_for_multi-stream_robust_emotion_identification"},{"id":228579338,"url":"https://www.researchgate.net/publication/228579338_Automatic_height_estimation_from_speech_in_real-world_setup"},{"id":220735898,"url":"https://www.researchgate.net/publication/220735898_Learning_with_synthesized_speech_for_automatic_emotion_recognition"},{"id":227040207,"url":"https://www.researchgate.net/publication/227040207_Estimation_of_unknown_speaker's_height_from_speech"},{"id":224929604,"url":"https://www.researchgate.net/publication/224929604_On_Laughter_and_Speech_Laugh_Based_on_Observations_of_Child-Robot_Interaction"},{"id":224929667,"url":"https://www.researchgate.net/publication/224929667_A_Multimodal_Listener_Behaviour_Driven_by_Audio_Input"},{"id":257879528,"url":"https://www.researchgate.net/publication/257879528_Perceptual_audio_features_for_emotion_detection"},{"id":224929747,"url":"https://www.researchgate.net/publication/224929747_The_INTERSPEECH_2011_Speaker_State_Challenge_--_A_review"},{"id":257571910,"url":"https://www.researchgate.net/publication/257571910_Synthesized_speech_for_model_training_in_cross-corpus_recognition_of_human_emotion"},{"id":224929693,"url":"https://www.researchgate.net/publication/224929693_Towards_Measuring_Similarity_Between_Emotional_Corpora"},{"id":265478971,"url":"https://www.researchgate.net/publication/265478971_Text-dependent_pathological_voice_detection"},{"id":265624167,"url":"https://www.researchgate.net/publication/265624167_Feature_Based_Method_For_Human_Facial_Emotion_Detection_using_Optical_Flow_Based_Analysis"},{"id":224088137,"url":"https://www.researchgate.net/publication/224088137_The_hinterland_of_emotions_Facing_the_open-microphone_challenge"},{"id":221052745,"url":"https://www.researchgate.net/publication/221052745_Learning_and_evaluating_response_prediction_models_using_parallel_listener_consensus"},{"id":220795824,"url":"https://www.researchgate.net/publication/220795824_EmoReSp_an_online_emotion_recognizer_based_on_speech"},{"id":220716653,"url":"https://www.researchgate.net/publication/220716653_Affect_Recognition_in_Real_Life_Scenarios"},{"id":220746010,"url":"https://www.researchgate.net/publication/220746010_CINEMO_-_A_French_Spoken_Language_Resource_for_Complex_Emotions_Facts_and_Baselines"},{"id":221481381,"url":"https://www.researchgate.net/publication/221481381_The_INTERSPEECH_2010_paralinguistic_challenge"},{"id":221486791,"url":"https://www.researchgate.net/publication/221486791_Multi-class_and_hierarchical_SVMs_for_emotion_recognition"},{"id":224929655,"url":"https://www.researchgate.net/publication/224929655_openSMILE_--_The_Munich_Versatile_and_Fast_Open-Source_Audio_Feature_Extractor"},{"id":234796407,"url":"https://www.researchgate.net/publication/234796407_Hello_Emily_how_are_you_today_personalised_dialogue_in_a_toy_to_engage_children"},{"id":221101909,"url":"https://www.researchgate.net/publication/221101909_Latent_Mixture_of_Discriminative_Experts_for_Multimodal_Prediction_Modeling"},{"id":221487659,"url":"https://www.researchgate.net/publication/221487659_Voice_attributes_affecting_likability_perception"},{"id":221152313,"url":"https://www.researchgate.net/publication/221152313_Multimodal_Emotion_Recognition_Based_on_the_Decoupling_of_Emotion_and_Speaker_Information"},{"id":224929665,"url":"https://www.researchgate.net/publication/224929665_Universal_Onset_Detection_with_Bidirectional_Long-Short_Term_Memory_Neural_Networks"},{"id":221484168,"url":"https://www.researchgate.net/publication/221484168_Gender_and_affect_recognition_based_on_GMM_and_GMM-UBM_modeling_with_relevance_MAP_estimation"},{"id":221488522,"url":"https://www.researchgate.net/publication/221488522_Real-life_emotion-related_states_detection_in_call_centers_a_cross-corpora_study"},{"id":224929698,"url":"https://www.researchgate.net/publication/224929698_Word_Accent_and_Emotion"},{"id":220395374,"url":"https://www.researchgate.net/publication/220395374_Cross-Corpus_Acoustic_Emotion_Recognition_Variances_and_Strategies"},{"id":228529023,"url":"https://www.researchgate.net/publication/228529023_Cross-Corpus_Classification_of_Realistic_Emotions-Some_Pilot_Experiments"},{"id":221478005,"url":"https://www.researchgate.net/publication/221478005_Level_of_interest_sensing_in_spoken_dialog_using_multi-level_fusion_of_acoustic_and_lexical_evidence"},{"id":49461039,"url":"https://www.researchgate.net/publication/49461039_Human_Behavior_Understanding"},{"id":215835909,"url":"https://www.researchgate.net/publication/215835909_The_SEMAINE_API_Towards_a_standards-based_framework_for_building_emotion-oriented_systems"},{"id":224096783,"url":"https://www.researchgate.net/publication/224096783_Acoustic_emotion_recognition_A_benchmark_comparison_of_performances"},{"id":224929634,"url":"https://www.researchgate.net/publication/224929634_On-line_Emotion_Recognition_in_a_3-D_Activation-Valence-Time_Continuum_using_Acoustic_and_Linguistic_Cues"},{"id":224149678,"url":"https://www.researchgate.net/publication/224149678_Late_fusion_of_individual_engines_for_improved_recognition_of_negative_emotion_in_speech_-_learning_vs_democratic_vote"},{"id":221238957,"url":"https://www.researchgate.net/publication/221238957_Audio_Features_Selection_for_Automatic_Height_Estimation_from_Speech"},{"id":232638637,"url":"https://www.researchgate.net/publication/232638637_Cross-Corpus_Acoustic_Emotion_Recognition_Variances_and_Strategies"},{"id":220929149,"url":"https://www.researchgate.net/publication/220929149_Speech_Emotion_Classification_and_Public_Speaking_Skill_Assessment"},{"id":221152292,"url":"https://www.researchgate.net/publication/221152292_Enhancing_Emotion_Recognition_from_Speech_through_Feature_Selection"},{"id":220058141,"url":"https://www.researchgate.net/publication/220058141_Recognition_of_Nonprototypical_Emotions_in_Reverberated_and_Noisy_Speech_by_Nonnegative_Matrix_Factorization"},{"id":252011928,"url":"https://www.researchgate.net/publication/252011928_Learning_emotional_speech_by_using_Dirichlet_Process_Mixtures"},{"id":224929599,"url":"https://www.researchgate.net/publication/224929599_The_Automatic_Recognition_of_Emotions_in_Speech"},{"id":221622069,"url":"https://www.researchgate.net/publication/221622069_Investigating_Glottal_Parameters_and_Teager_Energy_Operators_in_Emotion_Recognition"},{"id":221052273,"url":"https://www.researchgate.net/publication/221052273_Towards_Multimodal_Sentiment_Analysis_Harvesting_Opinions_from_the_Web"},{"id":224929624,"url":"https://www.researchgate.net/publication/224929624_The_interspeech_2011_speaker_state_challenge"},{"id":221017827,"url":"https://www.researchgate.net/publication/221017827_A_Novel_Emotion_Recognizer_from_Speech_Using_Both_Prosodic_and_Linguistic_Features"},{"id":220736748,"url":"https://www.researchgate.net/publication/220736748_Analysis_of_Anger_across_several_agent-customer_interactions_in_French_call_centers"},{"id":221622197,"url":"https://www.researchgate.net/publication/221622197_AVEC_2011-The_First_International_AudioVisual_Emotion_Challenge"},{"id":221486581,"url":"https://www.researchgate.net/publication/221486581_Analyzing_the_Nature_of_ECA_Interactions_in_Children_with_Autism"},{"id":224929672,"url":"https://www.researchgate.net/publication/224929672_Selecting_Training_Data_for_Cross-Corpus_Speech_Emotion_Recognition_Prototypicality_vs_Generalization"},{"id":260961634,"url":"https://www.researchgate.net/publication/260961634_Vocalic_Markers_of_Deception_and_Cognitive_Dissonance_for_Automated_Emotion_Detection_Systems"},{"id":258533119,"url":"https://www.researchgate.net/publication/258533119_Toward_Autonomous_Adaptive_and_Context-Aware_Multimodal_Interfaces_Theoretical_and_Practical_Issues"},{"id":222646238,"url":"https://www.researchgate.net/publication/222646238_Detecting_emotional_state_of_a_child_in_a_conversational_computer_game"},{"id":45709576,"url":"https://www.researchgate.net/publication/45709576_New_technologies_for_information_retrieval_to_achieve_situational_awareness_and_higher_patient_safety_in_the_surgical_operating_room_The_MRI_institutional_approach_and_review_of_the_literature"},{"id":221292146,"url":"https://www.researchgate.net/publication/221292146_Bilingual_acoustic_feature_selection_for_emotion_estimation_using_a_3D_continuous_model"},{"id":252012017,"url":"https://www.researchgate.net/publication/252012017_Detection_of_heterogeneous_structures_using_hierarchical_segmentation"},{"id":224238101,"url":"https://www.researchgate.net/publication/224238101_A_novel_perceptual_feature_set_for_audio_emotion_recognition"},{"id":224238096,"url":"https://www.researchgate.net/publication/224238096_Modeling_hidden_dynamics_of_multimodal_cues_for_spontaneous_agreement_and_disagreement_recognition"},{"id":224246178,"url":"https://www.researchgate.net/publication/224246178_A_hierarchical_static-dynamic_framework_for_emotion_classification"},{"id":224224891,"url":"https://www.researchgate.net/publication/224224891_Online_Driver_Distraction_Detection_Using_Long_Short-Term_Memory"},{"id":224251543,"url":"https://www.researchgate.net/publication/224251543_Spontaneous_children's_emotion_recognition_by_categorical_classification_of_acoustic_features"},{"id":220633913,"url":"https://www.researchgate.net/publication/220633913_An_Evaluation_of_Emotion_Units_and_Feature_Types_for_Real-Time_Speech_Emotion_Recognition"},{"id":220515965,"url":"https://www.researchgate.net/publication/220515965_Age_and_gender_detection_in_the_I-DASH_project"},{"id":236165515,"url":"https://www.researchgate.net/publication/236165515_A_systematic_strategy_for_robust_automatic_dialect_identification"},{"id":221621975,"url":"https://www.researchgate.net/publication/221621975_EmoWisconsin_An_Emotional_Children_Speech_Database_in_Mexican_Spanish"},{"id":222650661,"url":"https://www.researchgate.net/publication/222650661_Recognising_realistic_emotions_and_affect_in_speech_State_of_the_art_and_lessons_learnt_from_the_first_challenge"},{"id":221523887,"url":"https://www.researchgate.net/publication/221523887_Improving_Spontaneous_Children's_Emotion_Recognition_by_Acoustic_Feature_Selection_and_Feature-Level_Fusion_of_Acoustic_and_Linguistic_Parameters"},{"id":230793132,"url":"https://www.researchgate.net/publication/230793132_Comparative_Study_on_Feature_Selection_and_Fusion_Schemes_for_Emotion_Recognition_from_Speech"},{"id":224929559,"url":"https://www.researchgate.net/publication/224929559_Ten_Recent_Trends_in_Computational_Paralinguistics"},{"id":235696467,"url":"https://www.researchgate.net/publication/235696467_Can_Prosody_Inform_Sentiment_Analysis_Experiments_on_Short_Spoken_Reviews"},{"id":229272723,"url":"https://www.researchgate.net/publication/229272723_Acoustic_feature_selection_and_classification_of_emotions_in_speech_using_a_3D_continuous_emotion_model"},{"id":221890301,"url":"https://www.researchgate.net/publication/221890301_Live_Speech_Driven_Head-and-Eye_Motion_Generators"},{"id":257433914,"url":"https://www.researchgate.net/publication/257433914_Acoustic_Bird_Activity_Detection_on_Real-Field_Data"},{"id":257011969,"url":"https://www.researchgate.net/publication/257011969_Classification_of_emotional_speech_using_3DEC_hierarchical_classifier"},{"id":256309235,"url":"https://www.researchgate.net/publication/256309235_Prediction_of_Strategy_and_Outcome_as_Negotiation_Unfolds_by_Using_Basic_Verbal_and_Behavioral_Features"},{"id":260353896,"url":"https://www.researchgate.net/publication/260353896_Infinite_Hidden_Conditional_Random_Fields_for_Human_Behavior_Analysis"},{"id":257267503,"url":"https://www.researchgate.net/publication/257267503_On_the_development_of_an_automatic_voice_pleasantness_classification_and_intensity_estimation_system"},{"id":224929574,"url":"https://www.researchgate.net/publication/224929574_Paralinguistics_in_Speech_and_Language_-_State-of-the-Art_and_the_Challenge"},{"id":261265404,"url":"https://www.researchgate.net/publication/261265404_Emotion_recognition_method_based_on_normalization_of_prosodic_features"},{"id":261282884,"url":"https://www.researchgate.net/publication/261282884_Using_emotional_noise_to_uncloud_audio-visual_emotion_perceptual_evaluation"},{"id":260349630,"url":"https://www.researchgate.net/publication/260349630_Latent_Mixture_of_Discriminative_Experts"},{"id":236615221,"url":"https://www.researchgate.net/publication/236615221_Reward-based_learning_for_virtual_neurorobotics_through_emotional_speech_processing"},{"id":260304857,"url":"https://www.researchgate.net/publication/260304857_Multimodal_Sentiment_Analysis_of_Spanish_Online_Videos"},{"id":260324149,"url":"https://www.researchgate.net/publication/260324149_Sleepiness_detection_from_speech_by_perceptual_features"},{"id":260701110,"url":"https://www.researchgate.net/publication/260701110_On_Acoustic_Emotion_Recognition_Compensating_for_Covariate_Shift"},{"id":257431658,"url":"https://www.researchgate.net/publication/257431658_Integration_of_Temporal_Contextual_Information_for_Robust_Acoustic_Recognition_of_Bird_Species_from_Real-Field_Data"},{"id":260862944,"url":"https://www.researchgate.net/publication/260862944_First_Progresses_in_Evaluation_of_Resonance_in_Staff_Selection_through_Speech_Emotion_Recognition"},{"id":259889785,"url":"https://www.researchgate.net/publication/259889785_Sparse_Autoencoder-Based_Feature_Transfer_Learning_for_Speech_Emotion_Recognition"},{"id":260692528,"url":"https://www.researchgate.net/publication/260692528_Listening_Heads"},{"id":258439617,"url":"https://www.researchgate.net/publication/258439617_Excitation_source_and_low_level_descriptor_features_fusion_for_emotion_recognition_using_SVM_and_ANN"},{"id":261277197,"url":"https://www.researchgate.net/publication/261277197_Feature_space_dimension_reduction_in_speech_emotion_recognition_using_support_vector_machine"},{"id":261344956,"url":"https://www.researchgate.net/publication/261344956_Identifying_salient_sub-utterance_emotion_dynamics_using_flexible_units_and_estimates_of_affective_flow"},{"id":262157517,"url":"https://www.researchgate.net/publication/262157517_AVEC_2013_-_The_continuous_AudioVisual_Emotion_and_depression_recognition_challenge"},{"id":259481577,"url":"https://www.researchgate.net/publication/259481577_Versio_en_catala_Catalan_version"},{"id":236960677,"url":"https://www.researchgate.net/publication/236960677_Induction_recording_and_recognition_of_natural_emotions_from_facial_expressions_and_speech_prosody"},{"id":258636276,"url":"https://www.researchgate.net/publication/258636276_A_Multimodal_Emotion_Detection_System_during_Human-Robot_Interaction"},{"id":230662368,"url":"https://www.researchgate.net/publication/230662368_Children's_Emotion_Recognition_from_Spontaneous_Speech_Using_a_Reduced_Set_of_Acoustic_and_Linguistic_Features"},{"id":271547555,"url":"https://www.researchgate.net/publication/271547555_Acoustic_feature_selection_utilizing_multiple_kernel_learning_for_classification_of_children_with_autism_spectrum_and_typically_developing_children"},{"id":262313360,"url":"https://www.researchgate.net/publication/262313360_Emotion_Recognition_In_The_Wild_Challenge_2013"},{"id":259133418,"url":"https://www.researchgate.net/publication/259133418_Shape-based_modeling_of_the_fundamental_frequency_contour_for_emotion_detection_in_speech"},{"id":265854202,"url":"https://www.researchgate.net/publication/265854202_Medium_term_speaker_state_detection_by_perceptually_masked_spectral_features"},{"id":282708932,"url":"https://www.researchgate.net/publication/282708932_Speech_emotion_recognition_with_cross-lingual_databases"},{"id":259516753,"url":"https://www.researchgate.net/publication/259516753_Medium-term_speaker_states-A_review_on_intoxication_sleepiness_and_the_first_challenge"},{"id":269295255,"url":"https://www.researchgate.net/publication/269295255_Introducing_shared-hidden-layer_autoencoders_for_transfer_learning_and_their_application_in_acoustic_emotion_recognition"},{"id":268238986,"url":"https://www.researchgate.net/publication/268238986_A_feature_selection_and_feature_fusion_combination_method_for_speaker-independent_speech_emotion_recognition"},{"id":263850602,"url":"https://www.researchgate.net/publication/263850602_Audio_Onset_Detection_A_Wavelet_Packet_Based_Approach_with_Recurrent_Neural_Networks"},{"id":263551043,"url":"https://www.researchgate.net/publication/263551043_Evaluation_of_Resonance_in_Staff_Selection_through_Multimedia_Contents"},{"id":269688106,"url":"https://www.researchgate.net/publication/269688106_Emotion_Recognition_from_Speech_using_Discriminative_Features"},{"id":266561641,"url":"https://www.researchgate.net/publication/266561641_Representation_of_Facial_Expression_Categories_in_Continuous_Arousal-Valence_Space_Feature_and_Correlation"},{"id":282301283,"url":"https://www.researchgate.net/publication/282301283_Cross_corpus_speech_emotion_recognition_using_semi-supervised_discriminant_analysis"},{"id":289004980,"url":"https://www.researchgate.net/publication/289004980_Building_a_robust_system_for_multimodal_emotion_recognition"},{"id":282713044,"url":"https://www.researchgate.net/publication/282713044_Minimal_cross-correlation_criterion_for_speech_emotion_multi-level_feature_selection"},{"id":278241579,"url":"https://www.researchgate.net/publication/278241579_On_the_Importance_of_Subtext_in_Recommender_Systems"},{"id":282517768,"url":"https://www.researchgate.net/publication/282517768_Fusing_audio_visual_and_textual_clues_for_sentiment_analysis_from_multimodal_content"},{"id":281518601,"url":"https://www.researchgate.net/publication/281518601_Speaker_height_estimation_from_speech_Fusing_spectral_regression_and_statistical_acoustic_models"},{"id":273488773,"url":"https://www.researchgate.net/publication/273488773_Variational_Infinite_Hidden_Conditional_Random_Fields"},{"id":283015075,"url":"https://www.researchgate.net/publication/283015075_Cross-corpus_analysis_for_acoustic_recognition_of_negative_interactions"},{"id":282602122,"url":"https://www.researchgate.net/publication/282602122_Exploring_Dataset_Similarities_using_PCA-based_Feature_Selection"},{"id":282854832,"url":"https://www.researchgate.net/publication/282854832_A_new_Dataset_of_Telephone-Based_Human-Human_Call-Center_Interaction_with_Emotional_Evaluation"},{"id":282891494,"url":"https://www.researchgate.net/publication/282891494_A_Robust_Method_for_Speech_Emotion_Recognition_Based_on_Infinite_Student's_t_-Mixture_Model"},{"id":284593847,"url":"https://www.researchgate.net/publication/284593847_Video_and_Image_based_Emotion_Recognition_Challenges_in_the_Wild_EmotiW_2015"},{"id":280734667,"url":"https://www.researchgate.net/publication/280734667_Sentic_Computing_A_Common-Sense-Based_Framework_for_Concept-Level_Sentiment_Analysis"},{"id":280734741,"url":"https://www.researchgate.net/publication/280734741_Sentic_Computing_A_Common-Sense-Based_Framework_for_Concept-Level_Sentiment_Analysis"}],"reference":["https://www.researchgate.net/publication/221490308_INTERSPEECH_2007_The_Relevance_of_Feature_Type_for_the_Automatic_Classification_of_Emotional_User_States_Low_Level_Descriptors_and_Functionals","https://www.researchgate.net/publication/221491017_A_database_of_German_emotional_speech","https://www.researchgate.net/publication/222421400_Being_bored_Recognising_natural_interest_by_extensive_audiovisual_integration_for_real-life_application","https://www.researchgate.net/publication/237131440_PRAAT_Doing_phonetics_by_computer_Version_410_Computer_program","https://www.researchgate.net/publication/224711637_Support_Vector_Regression_for_Automatic_Recognition_of_Spontaneous_Emotions_in_Speech","https://www.researchgate.net/publication/221345676_Discriminative_parameter_learning_for_Bayesian_networks","https://www.researchgate.net/publication/220726872_Static_and_Dynamic_Modelling_for_the_Recognition_of_Non-verbal_Vocalisations_in_Conversational_Speech","https://www.researchgate.net/publication/200777596_EmoVoice_-_A_framework_for_online_recognition_of_emotions_from_voice","https://www.researchgate.net/publication/23493444_A_Survey_of_Affect_Recognition_Methods_Audio_Visual_and_Spontaneous_Expressions","https://www.researchgate.net/publication/228715647_LIBSVM_A_library_for_support_vector_machines","https://www.researchgate.net/publication/13853244_Long_Short-term_Memory","https://www.researchgate.net/publication/259810776_PRAAT_Doing_phonetics_by_computer_Version_5351","https://www.researchgate.net/publication/224929704_Abandoning_Emotion_Classes_--_Towards_Continuous_Emotion_Recognition_with_Modelling_of_Long-Range_Dependencies","https://www.researchgate.net/publication/225127505_EmoVoice_-_A_Framework_for_Online_Recognition_of_Emotions_from_Voice","https://www.researchgate.net/publication/220017784_Data_Mining_Pratical_Machine_Learning_Tools_and_Techniques","https://www.researchgate.net/publication/224929671_The_Interspeech_2009_Emotion_Challenge","https://www.researchgate.net/publication/220733194_Brute-forcing_hierarchical_functionals_for_paralinguistics_A_waste_of_feature_space","https://www.researchgate.net/publication/221787452_Psychological_Motivated_Multi-Stage_Emotion_Classification_Exploiting_Voice_Quality_Features"]}