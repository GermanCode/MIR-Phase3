{"id":287250858,"title":"Action Recognition with Image Based CNN Features","authors":["Mahdyar Ravanbakhsh","Hossein Mousavi","Mohammad Rastegari","Vittorio Murino","Larry S. Davis"],"_abstract":"ABSTRACT Most of human actions consist of complex temporal compositions of more simple actions. Action recognition tasks usually relies on complex handcrafted structures as features to represent the human action model. Convolutional Neural Nets (CNN) have shown to be a powerful tool that eliminate the need for designing handcrafted features. Usually, the output of the last layer in CNN (a layer before the classification layer -known as fc7) is used as a generic feature for images. In this paper, we show that fc7 features, per se, can not get a good performance for the task of action recognition, when the network is trained only on images. We present a feature structure on top of fc7 features, which can capture the temporal variation in a video. To represent the temporal components, which is needed to capture motion information, we introduced a hierarchical structure. The hierarchical model enables to capture sub-actions from a complex action. At the higher levels of the hierarchy, it represents a coarse capture of action sequence and lower levels represent fine action elements. Furthermore, we introduce a method for extracting key-frames using binary coding of each frame in a video, which helps to improve the performance of our hierarchical model. We experimented our method on several action datasets and show that our method achieves superior results compared to other state-of-the-arts methods.","cited_in":[],"reference":["https://www.researchgate.net/publication/278047977_P-CNN_Pose-based_CNN_Features_for_Action_Recognition","https://www.researchgate.net/publication/260031847_Robust_action_recognition_using_local_motion_and_group_sparsity","https://www.researchgate.net/publication/281327886_Histograms_of_Oriented_Gradients_for_Human_Detection","https://www.researchgate.net/publication/4260080_Hierarchical_Matching_of_Deformable_Shapes","https://www.researchgate.net/publication/45660306_Action_Recognition_Using_Mined_Hierarchical_Compound_Features","https://www.researchgate.net/publication/221363276_Iterative_quantization_A_procrustean_approach_to_learning_binary_codes","https://www.researchgate.net/publication/282718100_Incremental_Activity_Modeling_and_Recognition_in_Streaming_Videos","https://www.researchgate.net/publication/221305416_Object_Scene_and_Actions_Combining_Multiple_Features_for_Human_Action_Recognition","https://www.researchgate.net/publication/264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding","https://www.researchgate.net/publication/286594438_Large-Scale_Video_Classification_with_Convolutional_Neural_Networks","https://www.researchgate.net/publication/221364540_Learning_a_hierarchy_of_discriminative_space-time_neighborhood_features_for_human_action_recognition_In_IEEE_CVPR","https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks","https://www.researchgate.net/publication/281427730_Action_Recognition_by_Hierarchical_Mid-level_Action_Elements","https://www.researchgate.net/publication/224254831_Appendix_Learning_Hierarchical_Invariant_Spatio-Temporal_Features_for_Action_Recognition_with_Independent_Subspace_Analysis","https://www.researchgate.net/publication/224579268_Recognizing_realistic_actions_from_videos_in_the_Wild","https://www.researchgate.net/publication/262452311_Bag_of_Visual_Words_and_Fusion_Methods_for_Action_Recognition_Comprehensive_Study_and_Good_Practice","https://www.researchgate.net/publication/221362695_Action_MACH_a_spatio-temporal_Maximum_Average_Correlation_Height_filter_for_action_recognition","https://www.researchgate.net/publication/230668339_Action_Bank_A_High-Level_Representation_of_Activity_in_Video","https://www.researchgate.net/publication/4090526_Recognizing_human_actions_A_local_SVM_approach","https://www.researchgate.net/publication/259441043_OverFeat_Integrated_Recognition_Localization_and_Detection_using_Convolutional_Networks","https://www.researchgate.net/publication/262974436_Two-Stream_Convolutional_Networks_for_Action_Recognition_in_Videos","https://www.researchgate.net/publication/265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","https://www.researchgate.net/publication/283907683_Visual_Saliency_Detection_Using_Group_Lasso_Regularization_in_Videos_of_Natural_Scenes","https://www.researchgate.net/publication/265787949_Going_Deeper_with_Convolutions","https://www.researchgate.net/publication/51025101_Action_Recognition_by_Dense_Trajectories","https://www.researchgate.net/publication/259385324_Motionlets_Mid-Level_3D_Parts_for_Human_Motion_Recognition","https://www.researchgate.net/publication/283806925_Video_Action_Detection_with_Relational_Dynamic-Poselets","https://www.researchgate.net/publication/277023590_Action_Recognition_with_Trajectory-Pooled_Deep-Convolutional_Descriptors","https://www.researchgate.net/publication/277895560_Learning_to_track_for_spatio-temporal_action_localization","https://www.researchgate.net/publication/221304362_An_Efficient_Dense_and_Scale-Invariant_Spatio-Temporal_Interest_Point_Detector","https://www.researchgate.net/publication/221362058_Discriminative_subvolume_search_for_efficient_action_detection_In_IEEE_CVPR","https://www.researchgate.net/publication/258424423_Visualizing_and_Understanding_Convolutional_Neural_Networks","https://www.researchgate.net/publication/258839715_PANDA_Pose_Aligned_Networks_for_Deep_Attribute_Modeling","https://www.researchgate.net/publication/279839496_Learning_Deep_Features_for_Scene_Recognition_using_Places_Database"]}