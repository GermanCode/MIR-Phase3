{"id":221491017,"title":"A database of German emotional speech","authors":["Felix Burkhardt","Astrid Paeschke","M. Rolfes","Walter F. Sendlmeier","Benjamin Weiss"],"_abstract":"The article describes a database of emotional speech. Ten actors (5 female and 5 male) simulated the emotions, producing 10 German utterances (5 short and 5 longer sentences) which could be used in everyday communication and are interpretable in all applied emotions. The recordings were taken in an anechoic chamber with high-quality recording equipment. In addition to the sound electro-glottograms were recorded. The speech material comprises about 800 sentences (seven emotions * ten actors * ten sentences + some second versions). The complete database was evaluated in a perception test regarding the recognisability of emotions and their naturalness. Utterances recognised better than 80% and judged as natural by more than 60% of the listeners were phonetically labelled in a narrow transcription with special markers for voice-quality, phonatory and articulatory settings and articulatory features. The database can be accessed by the public via the internet (http://www.expressive-speech.net/emodb/).","cited_in":[{"id":286239774,"url":"https://www.researchgate.net/publication/286239774_Reconocimiento_y_Regionalizacion_de_las_Emociones_en_el_Plano_Excitacion-Valencia"},{"id":286924958,"url":"https://www.researchgate.net/publication/286924958_Annotators'_agreement_and_spontaneous_emotion_classification_performance"},{"id":282517768,"url":"https://www.researchgate.net/publication/282517768_Fusing_audio_visual_and_textual_clues_for_sentiment_analysis_from_multimodal_content"},{"id":282477009,"url":"https://www.researchgate.net/publication/282477009_Four-stage_feature_selection_to_recognize_emotion_from_speech_signals"},{"id":277078368,"url":"https://www.researchgate.net/publication/277078368_Emotion_recognition_from_speech_Tools_and_challenges"},{"id":274195818,"url":"https://www.researchgate.net/publication/274195818_Ein_Datenset_zur_Untersuchung_emotionaler_Sprache_in_Kundenbindungsdialogen"},{"id":290168922,"url":"https://www.researchgate.net/publication/290168922_Detection_des_etats_affectifs_lors_d'interactions_parlees_robustesse_des_indices_non_verbaux"},{"id":273393526,"url":"https://www.researchgate.net/publication/273393526_Speech_Emotion_Recognition_Using_Fourier_Parameters"},{"id":270893946,"url":"https://www.researchgate.net/publication/270893946_Machine_learning_approach_for_emotion_recognition_in_speech"},{"id":282779439,"url":"https://www.researchgate.net/publication/282779439_Emotion_classification_of_speech_using_modulation_features"},{"id":279928865,"url":"https://www.researchgate.net/publication/279928865_Automatic_speech_polarity_detection_using_phase_information_from_complex_analytic_signal_representations"},{"id":263930061,"url":"https://www.researchgate.net/publication/263930061_Speech_Polarity_Detection_Using_Hilbert_Phase_Information"},{"id":286681269,"url":"https://www.researchgate.net/publication/286681269_Location_of_an_emotionally_neutral_region_in_valence-arousal_space_Two-class_vs_three-class_cross_corpora_emotion_recognition_evaluations"},{"id":263861838,"url":"https://www.researchgate.net/publication/263861838_Introducing_the_Oxford_Vocal_OxVoc_Sounds_database_a_validated_set_of_non-acted_affective_sounds_from_human_infants_adults_and_domestic_animals"},{"id":263548209,"url":"https://www.researchgate.net/publication/263548209_Emotion_Identification_Using_Extremely_Low_Frequency_Components_of_Speech_Feature_Contours"},{"id":260395506,"url":"https://www.researchgate.net/publication/260395506_Speech_polarity_determination_A_comparative_evaluation"},{"id":269295715,"url":"https://www.researchgate.net/publication/269295715_Multi-scale_modulation_filtering_in_automatic_detection_of_emotions_in_telephone_speech"},{"id":287248828,"url":"https://www.researchgate.net/publication/287248828_Building_a_naturalistic_emotional_speech_corpus_by_retrieving_expressive_behaviors_from_existing_speech_corpora"},{"id":288492522,"url":"https://www.researchgate.net/publication/288492522_Emotion_Recognition_in_the_Wild"},{"id":260675908,"url":"https://www.researchgate.net/publication/260675908_Detection_of_Affective_States_from_Speech_Signals_using_Ensemble_of_Classifiers"},{"id":269688143,"url":"https://www.researchgate.net/publication/269688143_Emotion_Recognition_from_Speech_using_Teager_based_DSCC_features"},{"id":258450393,"url":"https://www.researchgate.net/publication/258450393_Extended_Weighted_Linear_Prediction_Using_the_Autocorrelation_Snapshot_-A_Robust_Speech_Analysis_Method_and_its_Application_to_Recognition_of_Vocal_Emotions"},{"id":255736693,"url":"https://www.researchgate.net/publication/255736693_Recognition_of_Emotions_in_Mexican_Spanish_Speech_An_Approach_Based_on_Acoustic_Modelling_of_Emotion-Specific_Vowels"},{"id":237050823,"url":"https://www.researchgate.net/publication/237050823_Comparison_of_Perceptual_Features_Efficiency_for_Automatic_Identification_of_Emotional_States_from_Speech"},{"id":237050795,"url":"https://www.researchgate.net/publication/237050795_Recognition_of_Emotional_States_in_Natural_Speech"},{"id":237085116,"url":"https://www.researchgate.net/publication/237085116_On_the_Acoustics_of_Emotion_in_Audio_What_Speech_Music_and_Sound_have_in_Common"},{"id":237836267,"url":"https://www.researchgate.net/publication/237836267_Automatic_detection_of_anger_in_telephone_speech_with_robust_autoregressive_modulation_filtering"},{"id":259133424,"url":"https://www.researchgate.net/publication/259133424_Class-specific_multiple_classifiers_scheme_to_recognize_emotions_from_speech_signals"},{"id":259065800,"url":"https://www.researchgate.net/publication/259065800_Modeling_phonetic_pattern_variability_in_favor_of_the_creation_of_robust_emotion_classifiers_for_real-life_applications"},{"id":229438965,"url":"https://www.researchgate.net/publication/229438965_A_Robust_Unsupervised_Arousal_Rating_Framework_using_Prosody_with_Cross-Corpora_Evaluation"},{"id":271501451,"url":"https://www.researchgate.net/publication/271501451_Epoch_extraction_from_emotional_speech"},{"id":257571902,"url":"https://www.researchgate.net/publication/257571902_Emotion_recognition_from_speech_using_source_system_and_prosodic_features"},{"id":228513346,"url":"https://www.researchgate.net/publication/228513346_Speaker-independent_emotion_recognition_exploiting_a_psychologically-inspired_binary_cascade_classification_schema"},{"id":261091151,"url":"https://www.researchgate.net/publication/261091151_Kolmogorov-Smirnov_test_for_feature_selection_in_emotion_recognition_from_speech"},{"id":261421289,"url":"https://www.researchgate.net/publication/261421289_Comparison_of_adaptation_methods_for_GMM-SVM_based_speech_emotion_recognition"},{"id":265523259,"url":"https://www.researchgate.net/publication/265523259_Speech_Emotion_Recognition_Using_Hybrid_Generative_and_Discriminative_Models"},{"id":261091310,"url":"https://www.researchgate.net/publication/261091310_Articulatory_features_for_expressive_speech_synthesis"},{"id":270588231,"url":"https://www.researchgate.net/publication/270588231_Multi_Corpora_Robustness_Analysis_of_Attributes_Selection_Applied_to_Speech_Emotion_Classification"},{"id":221622135,"url":"https://www.researchgate.net/publication/221622135_ikannotate_-_A_Tool_for_Labelling_Transcription_and_Annotation_of_Emotionally_Coloured_Speech"},{"id":224257535,"url":"https://www.researchgate.net/publication/224257535_Appropriate_emotional_labelling_of_non-acted_speech_using_basic_emotions_geneva_emotion_wheel_and_self_assessment_manikins"},{"id":221045525,"url":"https://www.researchgate.net/publication/221045525_Analysis_of_High-level_Features_for_Vocal_Emotion_Recognition"},{"id":224246528,"url":"https://www.researchgate.net/publication/224246528_Iterative_feature_normalization_for_emotional_speech_detection"},{"id":224246423,"url":"https://www.researchgate.net/publication/224246423_Sentence_level_emotion_recognition_based_on_decisions_from_subsentence_segments"},{"id":224929577,"url":"https://www.researchgate.net/publication/224929577_Affective_Speaker_State_Analysis_in_the_Presence_of_Reverberation"},{"id":220733712,"url":"https://www.researchgate.net/publication/220733712_Deep_neural_networks_for_acoustic_emotion_recognition_Raising_the_benchmarks"},{"id":222840519,"url":"https://www.researchgate.net/publication/222840519_A_prototype_for_a_Conversational_Companion_for_reminiscing_about_images"},{"id":220395367,"url":"https://www.researchgate.net/publication/220395367_Real-Time_Recognition_of_Affective_States_from_Nonverbal_Features_of_Speech_and_Its_Application_for_Public_Speaking_Skill_Analysis"},{"id":221292511,"url":"https://www.researchgate.net/publication/221292511_Benchmarking_classification_models_for_emotion_recognition_in_natural_speech_A_multi-corporal_study"},{"id":227146391,"url":"https://www.researchgate.net/publication/227146391_Two_stage_emotion_recognition_based_on_speaking_rate"},{"id":223848328,"url":"https://www.researchgate.net/publication/223848328_Survey_on_speech_emotion_recognition_Features_classification_schemes_and_databases"},{"id":222820384,"url":"https://www.researchgate.net/publication/222820384_Whodunnit_-_Searching_for_the_Most_Important_Feature_Types_Signalling_Emotion-Related_User_States_in_Speech"},{"id":220906611,"url":"https://www.researchgate.net/publication/220906611_Empath_a_Continuous_Remote_Emotional_Health_Monitoring_System_for_Depressive_Illness"},{"id":221633690,"url":"https://www.researchgate.net/publication/221633690_Emotional_speech_classification_using_hidden_conditional_random_fields"},{"id":241191906,"url":"https://www.researchgate.net/publication/241191906_Emotional_state_recognition_from_speech_via_soft-competition_on_different_acoustic_representations"},{"id":221473077,"url":"https://www.researchgate.net/publication/221473077_Towards_an_online_voice-based_gender_and_internal_state_detection_model"},{"id":221264530,"url":"https://www.researchgate.net/publication/221264530_Vowels_formants_analysis_allows_straightforward_detection_of_high_arousal_emotions"},{"id":221481149,"url":"https://www.researchgate.net/publication/221481149_Vowels_Formants_Analysis_Allows_Straightforward_Detection_of_High_Arousal_Acted_and_Spontaneous_Emotions"},{"id":226240488,"url":"https://www.researchgate.net/publication/226240488_Salient_Features_for_Anger_Recognition_in_German_and_English_IVR_Portals"},{"id":224174385,"url":"https://www.researchgate.net/publication/224174385_Speech_Emotion_Analysis_Exploring_the_Role_of_Context"},{"id":46582426,"url":"https://www.researchgate.net/publication/46582426_Exploring_Language-Independent_Emotional_Acoustic_Features_via_Feature_Selection"},{"id":46582417,"url":"https://www.researchgate.net/publication/46582417_Emotional_State_Categorization_from_Speech_Machine_vs_Human"},{"id":220931391,"url":"https://www.researchgate.net/publication/220931391_Use_of_Line_Spectral_Frequencies_for_Emotion_Recognition_from_Speech"},{"id":251949611,"url":"https://www.researchgate.net/publication/251949611_Emotion_recognition_from_speech_signal_using_epoch_parameters"},{"id":241694943,"url":"https://www.researchgate.net/publication/241694943_Class-Level_Spectral_Features_for_Emotion_Recognition"},{"id":220045150,"url":"https://www.researchgate.net/publication/220045150_Speaker-independent_negative_emotion_recognition"},{"id":232648360,"url":"https://www.researchgate.net/publication/232648360_SVM_-_MLP_-_PNN_classifiers_on_speech_emotion_recognition_field_-_A_comparative_study"},{"id":228370109,"url":"https://www.researchgate.net/publication/228370109_Classification_of_affective_speech_using_normalized_time-frequency_cepstra"},{"id":220120388,"url":"https://www.researchgate.net/publication/220120388_Analysis_of_Statistical_Parametric_and_Unit_Selection_Speech_Synthesis_Systems_Applied_to_Emotional_Speech"},{"id":224096783,"url":"https://www.researchgate.net/publication/224096783_Acoustic_emotion_recognition_A_benchmark_comparison_of_performances"},{"id":228959605,"url":"https://www.researchgate.net/publication/228959605_Modeling_affected_user_behavior_during_human-machine_interaction"},{"id":220517037,"url":"https://www.researchgate.net/publication/220517037_Speech_Emotion_Analysis_Exploring_the_Role_of_Context"},{"id":220716750,"url":"https://www.researchgate.net/publication/220716750_Problems_of_the_Automatic_Emotion_Recognitions_in_Spontaneous_Speech_An_Example_for_the_Recognition_in_a_Dispatcher_Center"},{"id":251927891,"url":"https://www.researchgate.net/publication/251927891_Determining_Optimal_Signal_Features_and_Parameters_for_HMM-Based_Emotion_Classification"},{"id":221487659,"url":"https://www.researchgate.net/publication/221487659_Voice_attributes_affecting_likability_perception"},{"id":220395374,"url":"https://www.researchgate.net/publication/220395374_Cross-Corpus_Acoustic_Emotion_Recognition_Variances_and_Strategies"},{"id":220746533,"url":"https://www.researchgate.net/publication/220746533_Developing_an_Expressive_Speech_Labeling_Tool_Incorporating_the_Temporal_Characteristics_of_Emotion"},{"id":220735898,"url":"https://www.researchgate.net/publication/220735898_Learning_with_synthesized_speech_for_automatic_emotion_recognition"},{"id":221486791,"url":"https://www.researchgate.net/publication/221486791_Multi-class_and_hierarchical_SVMs_for_emotion_recognition"},{"id":267698141,"url":"https://www.researchgate.net/publication/267698141_Classification_on_Speech_Emotion_Recognition_-_A_Comparative_Study"},{"id":224576207,"url":"https://www.researchgate.net/publication/224576207_Automatic_recognition_of_speech_emotion_using_long-term_spectro-temporal_features"},{"id":224395234,"url":"https://www.researchgate.net/publication/224395234_Analysis_of_Emotionally_Salient_Aspects_of_Fundamental_Frequency_for_Emotion_Detection"},{"id":24026978,"url":"https://www.researchgate.net/publication/24026978_An_Edit-Distance_Model_for_the_Approximate_Matching_of_Timed_Strings"},{"id":220656007,"url":"https://www.researchgate.net/publication/220656007_Analysis_of_Emotionally_Salient_Aspects_of_Fundamental_Frequency_for_Emotion_Detection"},{"id":221490017,"url":"https://www.researchgate.net/publication/221490017_Improving_emotion_recognition_using_class-level_spectral_features"},{"id":221478165,"url":"https://www.researchgate.net/publication/221478165_Emotion_recognition_from_speech_using_extended_feature_selection_and_a_simple_classifier"},{"id":221487336,"url":"https://www.researchgate.net/publication/221487336_Data-driven_clustering_in_emotional_space_for_affect_recognition_using_discriminatively_trained_LSTM_networks"},{"id":221481781,"url":"https://www.researchgate.net/publication/221481781_Improving_automatic_emotion_recognition_from_speech_signals"},{"id":221485333,"url":"https://www.researchgate.net/publication/221485333_Emotion_recognition_using_linear_transformations_in_combination_with_video"},{"id":221787454,"url":"https://www.researchgate.net/publication/221787454_Gender_Classification_in_Emotional_Speech"},{"id":224929718,"url":"https://www.researchgate.net/publication/224929718_Balancing_Spoken_Content_Adaptation_and_Unit_Length_in_the_Recognition_of_Emotion_and_Interest"},{"id":220746374,"url":"https://www.researchgate.net/publication/220746374_The_PIT_Corpus_of_German_Multi-Party_Dialogues"},{"id":39997345,"url":"https://www.researchgate.net/publication/39997345_Enabling_Reinforcement_Learning_for_Open_Dialogue_Systems_through_Speech_Stress_Detection"},{"id":200777595,"url":"https://www.researchgate.net/publication/200777595_Dancing_the_Night_Away_Controlling_a_Virtual_Karaoke_Dancer_by_Multimodal_Expressive_Cues"},{"id":235009799,"url":"https://www.researchgate.net/publication/235009799_Stressemotion_classification_using_features_extracted_in_compliance_with_the_front-end_of_the_ETSI_ES_202_211_V111_standard"},{"id":44104243,"url":"https://www.researchgate.net/publication/44104243_Spanish_Expressive_Voices_Corpus_for_Emotion_Research_in_Spanish"},{"id":224929600,"url":"https://www.researchgate.net/publication/224929600_Speaker_Noise_and_Acoustic_Space_Adaptation_for_Emotion_Recognition_in_the_Automotive_Environment"},{"id":220746843,"url":"https://www.researchgate.net/publication/220746843_A_Real-World_Emotional_Speech_Corpus_for_Modern_Greek"},{"id":221482209,"url":"https://www.researchgate.net/publication/221482209_Amplitude_and_amplitude_variation_of_emotional_speech"},{"id":224305584,"url":"https://www.researchgate.net/publication/224305584_In_Search_of_Primary_Rubrics_for_Language_Independent_Emotional_Speech_Identification"},{"id":4273524,"url":"https://www.researchgate.net/publication/4273524_Determining_Efficiency_of_Speech_Feature_Groups_in_Emotion_Detection"},{"id":224711604,"url":"https://www.researchgate.net/publication/224711604_Towards_More_Reality_in_the_Recognition_of_Emotional_Speech"},{"id":4343794,"url":"https://www.researchgate.net/publication/4343794_New_feature_selection_frameworks_in_emotion_recognition_to_evaluate_the_informative_power_of_speech_related_features"},{"id":221487296,"url":"https://www.researchgate.net/publication/221487296_BECAM_tool_-_a_semi-automatic_tool_for_bootstrapping_emotion_corpus_annotation_and_management"},{"id":228938044,"url":"https://www.researchgate.net/publication/228938044_Statistical_analysis_of_glottal_pulses_in_speech_under_psychological_stress"},{"id":221484006,"url":"https://www.researchgate.net/publication/221484006_Visualizing_acoustic_similarities_between_emotions_in_speech_an_acoustic_map_of_emotions"},{"id":224679351,"url":"https://www.researchgate.net/publication/224679351_Evolutionary_Feature_Generation_in_Speech_Emotion_Recognition"},{"id":228586979,"url":"https://www.researchgate.net/publication/228586979_The_recognition_of_emotions_from_speech_using_GentleBoost_classifier_A_comparison_approach"},{"id":224929603,"url":"https://www.researchgate.net/publication/224929603_Recognition_of_Spontaneous_Emotions_by_Speech_within_Automotive_Environment"},{"id":224929723,"url":"https://www.researchgate.net/publication/224929723_Timing_Levels_in_Segment-Based_Speech_Emotion_Recognition"},{"id":228615684,"url":"https://www.researchgate.net/publication/228615684_Improving_automatic_emotion_recognition_from_speech_via_gender_differentiation"},{"id":267849819,"url":"https://www.researchgate.net/publication/267849819_Podrian_los_ordenadores_detectar_emociones_cuando_les_hablamos"},{"id":267685842,"url":"https://www.researchgate.net/publication/267685842_On_Acoustic_Emotion_Recognition_Compensating_for_Covariate_Shift_-_Supplementary_Results"},{"id":268260426,"url":"https://www.researchgate.net/publication/268260426_EMOTIONAL_SPEECH_SYNTHESIS_APPLICATIONS_HISTORY_AND_POSSIBLE_FUTURE"},{"id":228941235,"url":"https://www.researchgate.net/publication/228941235_An_'open-set'detection_evaluation_methodology_for_automatic_emotion_recognition_in_speech"},{"id":228787435,"url":"https://www.researchgate.net/publication/228787435_Emotional_aspects_of_intrinsic_speech_variabilities_in_automatic_speech_recognition"},{"id":242256468,"url":"https://www.researchgate.net/publication/242256468_Applied_to_Human_Centered_Interaction_Analysis"},{"id":251563460,"url":"https://www.researchgate.net/publication/251563460_Une_Approche_Basee_Voyelle_pour_la_Reconnaissance_d'Emotions_Actees"},{"id":226539681,"url":"https://www.researchgate.net/publication/226539681_Challenges_in_speech-based_human-computer_interfaces"},{"id":228787379,"url":"https://www.researchgate.net/publication/228787379_Semantic_audio-visual_data_fusion_for_automatic_emotion_recognition"},{"id":228662880,"url":"https://www.researchgate.net/publication/228662880_Combining_classifiers_with_diverse_feature_sets_for_robust_speaker_independent_emotion_recognition"},{"id":242248730,"url":"https://www.researchgate.net/publication/242248730_ERZELMEK_AUTOMATIKUS_FELISMERESE_A_BESZED_AKUSZTIKUS_JELLEMZOI_ALAPJAN"},{"id":257695579,"url":"https://www.researchgate.net/publication/257695579_A_new_discriminant_NMF_algorithm_and_its_application_to_the_extraction_of_subtle_emotional_differences_in_speech"},{"id":257879528,"url":"https://www.researchgate.net/publication/257879528_Perceptual_audio_features_for_emotion_detection"},{"id":228326209,"url":"https://www.researchgate.net/publication/228326209_Emotion_Recognition_in_the_Noise_Applying_Large_Acoustic_Feature_Sets"},{"id":266496833,"url":"https://www.researchgate.net/publication/266496833_Recognition_of_Emotions_in_Speech"},{"id":267254476,"url":"https://www.researchgate.net/publication/267254476_Audio-based_Emotion_Recognition_for_Advanced_Automatic_Retrieval_in_Judicial_Domain"},{"id":267791907,"url":"https://www.researchgate.net/publication/267791907_System_for_the_Collection_Storage_Analysis_and_Reporting_of_Objective_Behavioral_Measures"},{"id":267987271,"url":"https://www.researchgate.net/publication/267987271_Visual_and_acoustic_features_based_emotion_detection_for_advanced_driver_assistance_system"},{"id":257773842,"url":"https://www.researchgate.net/publication/257773842_A_multimodal_emotion_corpus_for_Filipino_and_its_uses"},{"id":257436125,"url":"https://www.researchgate.net/publication/257436125_Robust_emotion_recognition_in_noisy_speech_via_sparse_representation"},{"id":257571931,"url":"https://www.researchgate.net/publication/257571931_Robust_emotional_speech_classification_in_the_presence_of_babble_noise"},{"id":237616275,"url":"https://www.researchgate.net/publication/237616275_DUYGU_TESPITPROBLEMINDE_KNNMLP_veRBF_SINIFLANDIRICILARIN_BASARIMLARININDEGERLENDIRILMESI_EVALUTATION_OFPERFORMANCE_OFKNNMLP_AND_RBF_CLASSIFIERSINEMOTION_DETECTION_PROBLEM"},{"id":265001918,"url":"https://www.researchgate.net/publication/265001918_Development_of_a_Hybrid_Neural_Network_Model_for_Emotion_Recognition_from_Speech"},{"id":238720759,"url":"https://www.researchgate.net/publication/238720759_Speech_Audio_Image_and_Biomedical_Signal_Processing_using_Neural_Networks"},{"id":267725344,"url":"https://www.researchgate.net/publication/267725344_SPEAKER_RECOGNITION_IN_AN_EMOTIONAL_ENVIRONMENT"},{"id":227243774,"url":"https://www.researchgate.net/publication/227243774_Classifier_Fusion_for_Emotion_Recognition_from_Speech"},{"id":225100089,"url":"https://www.researchgate.net/publication/225100089_Audio-Based_Emotion_Recognition_in_Judicial_Domain_A_Multilayer_Support_Vector_Machines_Approach"},{"id":225270011,"url":"https://www.researchgate.net/publication/225270011_Sound_Processing_Features_for_Speaker-Dependent_and_Phrase-Independent_Emotion_Recognition_in_Berlin_Database"},{"id":221478213,"url":"https://www.researchgate.net/publication/221478213_Emovoice_a_system_to_generate_emotions_in_speech"},{"id":228900858,"url":"https://www.researchgate.net/publication/228900858_Analysis_and_Synthesis_of_Speaker_Age"},{"id":224063797,"url":"https://www.researchgate.net/publication/224063797_Getting_Bored_with_HTK_Using_HMMs_for_Emotion_Recognition_from_Speech_Signals"},{"id":224063798,"url":"https://www.researchgate.net/publication/224063798_A_Post-Processing_Approach_to_Improve_Emotion_Recognition_Rates"},{"id":224641109,"url":"https://www.researchgate.net/publication/224641109_Robust_Estimation_of_Voice_Quality_Parameters_Under_Realworld_Disturbances"},{"id":224683130,"url":"https://www.researchgate.net/publication/224683130_Introducing_the_Database_ExamStress_for_Speech_under_Stress"},{"id":224063919,"url":"https://www.researchgate.net/publication/224063919_Speech_Emotion_Recognition_Using_MFCCs_Extracted_from_a_Mobile_Terminal_based_on_ETSI_Front_End"},{"id":221622229,"url":"https://www.researchgate.net/publication/221622229_A_Systematic_Comparison_of_Different_HMM_Designs_for_Emotion_Recognition_from_Acted_and_Spontaneous_Speech"},{"id":228732912,"url":"https://www.researchgate.net/publication/228732912_Speech_Emotion_Recognition_Comparison_of_Speech_Segmentation_Approaches"},{"id":228774612,"url":"https://www.researchgate.net/publication/228774612_Multimodal_Web_based_system_for_human_emotion_recognition"},{"id":221491299,"url":"https://www.researchgate.net/publication/221491299_An_open-set_detection_evaluation_methodology_applied_to_language_and_emotion_recognition"},{"id":255571974,"url":"https://www.researchgate.net/publication/255571974_AN_INCREMENTAL_ANALYSIS_OF_DIFFERENT_FEATURE_GROUPS_IN_SPEAKER_INDEPENDENT_EMOTION_RECOGNITION"},{"id":220716783,"url":"https://www.researchgate.net/publication/220716783_Exploiting_a_Vowel_Based_Approach_for_Acted_Emotion_Recognition"},{"id":220270278,"url":"https://www.researchgate.net/publication/220270278_Frame_vs_Turn-Level_Emotion_Recognition_from_Speech_Considering_Static_and_Dynamic_Processing"},{"id":220270309,"url":"https://www.researchgate.net/publication/220270309_What_Should_a_Generic_Emotion_Markup_Language_Be_Able_to_Represent"},{"id":221479136,"url":"https://www.researchgate.net/publication/221479136_Combining_frame_and_turn-level_information_for_robust_recognition_of_emotions_within_speech"},{"id":215479092,"url":"https://www.researchgate.net/publication/215479092_Text_Speech_and_Dialogue"},{"id":220716927,"url":"https://www.researchgate.net/publication/220716927_Study_on_Speaker-Independent_Emotion_Recognition_from_Speech_on_Real-World_Data"},{"id":224060440,"url":"https://www.researchgate.net/publication/224060440_Playing_a_different_imitation_game_Interaction_with_an_Empathic_Android_Robot"},{"id":4249221,"url":"https://www.researchgate.net/publication/4249221_The_Relevance_of_Voice_Quality_Features_in_Speaker_Independent_Emotion_Recognition"},{"id":224711608,"url":"https://www.researchgate.net/publication/224711608_Speech_Emotion_Recognition_using_Gaussian_Mixture_Vector_Autoregressive_Models"},{"id":4273330,"url":"https://www.researchgate.net/publication/4273330_Evalutation_of_Performance_of_KNN_MLP_and_RBF_Classifiers_in_Emotion_Detection_Problem"},{"id":221622053,"url":"https://www.researchgate.net/publication/221622053_A_Novel_Feature_for_Emotion_Recognition_in_Voice_Based_Applications"},{"id":226844077,"url":"https://www.researchgate.net/publication/226844077_Emotion_Recognition_from_Speech_Using_Multi-Classifier_Systems_and_RBF-Ensembles"},{"id":224363463,"url":"https://www.researchgate.net/publication/224363463_Combined_Speech-Emotion_Recognition_for_Spoken_Human-Computer_Interfaces"},{"id":200777596,"url":"https://www.researchgate.net/publication/200777596_EmoVoice_-_A_framework_for_online_recognition_of_emotions_from_voice"},{"id":221448779,"url":"https://www.researchgate.net/publication/221448779_Efficient_Speech_Emotion_Recognition_Based_on_Multisurface_Proximal_Support_Vector_Machine"},{"id":241080192,"url":"https://www.researchgate.net/publication/241080192_A_vowel_based_approach_for_acted_emotion_recognition"},{"id":220733194,"url":"https://www.researchgate.net/publication/220733194_Brute-forcing_hierarchical_functionals_for_paralinguistics_A_waste_of_feature_space"},{"id":220716887,"url":"https://www.researchgate.net/publication/220716887_Evaluation_of_Speech_Emotion_Classification_Based_on_GMM_and_Data_Fusion"},{"id":220716904,"url":"https://www.researchgate.net/publication/220716904_Recognition_of_Emotions_in_German_Speech_Using_Gaussian_Mixture_Models"},{"id":221489506,"url":"https://www.researchgate.net/publication/221489506_Detection_of_security_related_affect_and_behaviour_in_passenger_transport"},{"id":220716650,"url":"https://www.researchgate.net/publication/220716650_Polish_Emotional_Speech_Database_-_Recording_and_Preliminary_Validation"},{"id":220746230,"url":"https://www.researchgate.net/publication/220746230_A_Flexible_Wizard_of_Oz_Environment_for_Rapid_Prototyping"},{"id":221070527,"url":"https://www.researchgate.net/publication/221070527_Auditory_mood_detection_for_social_and_educational_robots"},{"id":221009711,"url":"https://www.researchgate.net/publication/221009711_An_Acoustic_Framework_for_Detecting_Fatigue_in_Speech_Based_Human-Computer-Interaction"},{"id":221490391,"url":"https://www.researchgate.net/publication/221490391_Long-term_spectro-temporal_information_for_improved_automatic_speech_emotion_classification"},{"id":4311091,"url":"https://www.researchgate.net/publication/4311091_Comparing_one_and_two-stage_acoustic_modeling_in_the_recognition_of_emotion_in_speech"},{"id":224313021,"url":"https://www.researchgate.net/publication/224313021_Cascaded_emotion_classification_via_psychological_emotion_dimensions_using_a_large_set_of_voice_quality_parameters"},{"id":4372373,"url":"https://www.researchgate.net/publication/4372373_On_the_comparison_of_classifiers'_performance_in_emotion_classification_Critiques_and_suggestions"},{"id":224327600,"url":"https://www.researchgate.net/publication/224327600_Combining_speech_recognition_and_acoustic_word_emotion_models_for_robust_text-independent_emotion_recognition"},{"id":224319854,"url":"https://www.researchgate.net/publication/224319854_Real-time_sensing_and_acoustic_scene_characterization_for_security_applications"},{"id":220726862,"url":"https://www.researchgate.net/publication/220726862_Emotion_Classification_of_Audio_Signals_Using_Ensemble_of_Support_Vector_Machines"},{"id":220726894,"url":"https://www.researchgate.net/publication/220726894_On_the_Influence_of_Phonetic_Content_Variation_for_Acoustic_Emotion_Recognition"},{"id":221588845,"url":"https://www.researchgate.net/publication/221588845_Real-Time_Emotion_Recognition_from_Speech_Using_Echo_State_Networks"},{"id":225127505,"url":"https://www.researchgate.net/publication/225127505_EmoVoice_-_A_Framework_for_Online_Recognition_of_Emotions_from_Voice"},{"id":226681226,"url":"https://www.researchgate.net/publication/226681226_Emotion_Recognition_with_Poincare_Mapping_of_Voiced-Speech_Segments_of_Utterances"},{"id":221406028,"url":"https://www.researchgate.net/publication/221406028_Speech_Emotion_Classification_Using_Machine_Learning_Algorithms"},{"id":4371004,"url":"https://www.researchgate.net/publication/4371004_Integrating_linguistic_cues_into_speech-based_emotion_recognition"},{"id":225125163,"url":"https://www.researchgate.net/publication/225125163_Lecture_Notes_in_Computer_Science"},{"id":224333381,"url":"https://www.researchgate.net/publication/224333381_Automatic_cry_detection_in_early_childhood_education_settings"},{"id":224348464,"url":"https://www.researchgate.net/publication/224348464_A_65_Gbs_backplane_transmitter_with_6-tap_FIR_equalizer_and_variable_tap_spacing"},{"id":221417565,"url":"https://www.researchgate.net/publication/221417565_A_Speaker_Independent_Approach_to_the_Classification_of_Emotional_Vocal_Expressions"},{"id":251873322,"url":"https://www.researchgate.net/publication/251873322_Performance_analysis_of_spectral_and_prosodic_features_and_their_fusion_for_emotion_recognition_in_speech"},{"id":226980034,"url":"https://www.researchgate.net/publication/226980034_A_Methodological_Approach_for_Building_Multimodal_Acted_Affective_Databases"},{"id":232637287,"url":"https://www.researchgate.net/publication/232637287_Feature_Selection_in_Acted_Speech_for_the_Creation_of_an_Emotion_Recognition_Personalization_Service"},{"id":224353442,"url":"https://www.researchgate.net/publication/224353442_ESEDA_A_Tool_for_Enhanced_Speech_Emotion_Detection_and_Analysis"},{"id":221482957,"url":"https://www.researchgate.net/publication/221482957_Processing_affected_speech_within_human_machine_interaction"},{"id":242549367,"url":"https://www.researchgate.net/publication/242549367_Advanced_Authoring_Tools_for_Game-Based_Training"},{"id":251887786,"url":"https://www.researchgate.net/publication/251887786_Automatic_emotion_recognition_for_facial_expression_animation_from_speech"},{"id":238783863,"url":"https://www.researchgate.net/publication/238783863_Preliminary_study_of_stressneutral_detection_on_recordings_of_children_in_the_natural_home_environment"},{"id":251912759,"url":"https://www.researchgate.net/publication/251912759_Emotion_Statuses_Recognition_of_Speech_Signal_Using_Transitive_Closure"},{"id":220166198,"url":"https://www.researchgate.net/publication/220166198_Multi-Modal_Emotional_Database_AvID"},{"id":221162628,"url":"https://www.researchgate.net/publication/221162628_Study_to_speech_emotion_recognition_based_on_TWINsSVM"},{"id":220716622,"url":"https://www.researchgate.net/publication/220716622_Multiple_Feature_Extraction_and_Hierarchical_Classifiers_for_Emotions_Recognition"},{"id":221565462,"url":"https://www.researchgate.net/publication/221565462_Comparison_Of_Different_Classifiers_for_Emotion_Recognition"},{"id":220946983,"url":"https://www.researchgate.net/publication/220946983_Speech_Emotion_Recognition_With_TGI2_Classifier"},{"id":221205312,"url":"https://www.researchgate.net/publication/221205312_Classification_of_Multi-variate_Varying_Length_Time_Series_Using_Descriptive_Statistical_Features"},{"id":221480604,"url":"https://www.researchgate.net/publication/221480604_Rule-based_voice_quality_variation_with_formant_synthesis"},{"id":228998459,"url":"https://www.researchgate.net/publication/228998459_Hilbert-Huang_Transform_for_Non-Linear_Characterization_of_Speech_Rhythm"},{"id":221506287,"url":"https://www.researchgate.net/publication/221506287_Audio-Based_Emotion_Recognition_in_Judicial_Domain_A_Multilayer_Support_Vector_Machines_Approach"},{"id":220716917,"url":"https://www.researchgate.net/publication/220716917_The_New_Italian_Audio_and_Video_Emotional_Database"},{"id":224375374,"url":"https://www.researchgate.net/publication/224375374_Multiple_Classifier_Applied_on_Predicting_Microsleep_from_Speech"},{"id":220781263,"url":"https://www.researchgate.net/publication/220781263_Variational_Gaussian_Mixture_Models_for_Speech_Emotion_Recognition"},{"id":222560026,"url":"https://www.researchgate.net/publication/222560026_Boosting_selection_of_speech_related_features_to_improve_performance_of_multi-class_SVMs_in_emotion_detection"},{"id":224461396,"url":"https://www.researchgate.net/publication/224461396_Speech_emotion_recognition_via_a_max-margin_framework_incorporating_a_loss_function_based_on_the_Watson_and_Tellegen's_emotion_model"},{"id":46294537,"url":"https://www.researchgate.net/publication/46294537_Time-Scale_Feature_Extractions_for_Emotional_Speech_Characterization"},{"id":232629540,"url":"https://www.researchgate.net/publication/232629540_Combination_of_generative_models_and_SVM_based_classifier_for_speech_emotion_recognition"},{"id":224535177,"url":"https://www.researchgate.net/publication/224535177_A_sensor_network_for_real-time_acoustic_scene_analysis"},{"id":232625734,"url":"https://www.researchgate.net/publication/232625734_Statistical_Evaluation_of_Speech_Features_for_Emotion_Recognition"},{"id":224576860,"url":"https://www.researchgate.net/publication/224576860_Heading_toward_to_the_natural_way_of_human-machine_interaction_The_NIMITEK_project"},{"id":224092008,"url":"https://www.researchgate.net/publication/224092008_Application_of_voiced-speech_variability_descriptors_to_emotion_recognition"},{"id":251909556,"url":"https://www.researchgate.net/publication/251909556_Towards_user-independent_classification_of_multimodal_emotional_signals"},{"id":221151783,"url":"https://www.researchgate.net/publication/221151783_Analysis_and_Assessment_of_AvID_Multi-Modal_Emotional_Database"},{"id":221078474,"url":"https://www.researchgate.net/publication/221078474_The_GMM-SVM_Supervector_Approach_for_the_Recognition_of_the_Emotional_Status_from_Speech"},{"id":225118402,"url":"https://www.researchgate.net/publication/225118402_Recognition_of_Emotional_State_in_Polish_Speech_-_Comparison_between_Human_and_Automatic_Efficiency"},{"id":224088060,"url":"https://www.researchgate.net/publication/224088060_OpenEAR_-_Introducing_the_Munich_open-source_emotion_and_affect_recognition_toolkit"},{"id":224088201,"url":"https://www.researchgate.net/publication/224088201_Recognition_of_emotions_in_speech_by_a_hierarchical_approach"},{"id":221031800,"url":"https://www.researchgate.net/publication/221031800_Syntactic_learning_for_ESEDA1_a_tool_for_enhanced_speech_emotion_detection_and_analysis"},{"id":221139021,"url":"https://www.researchgate.net/publication/221139021_Representative_and_Discriminant_Feature_Extraction_Based_on_NMF_for_Emotion_Recognition_in_Speech"},{"id":40755507,"url":"https://www.researchgate.net/publication/40755507_Application_of_Poincare-Mapping_of_Voiced-Speech_Segments_for_Emotion_Sensing"},{"id":224114193,"url":"https://www.researchgate.net/publication/224114193_Emotional_speech_characterization_based_on_multi-features_fusion_for_face-to-face_interaction"},{"id":41460472,"url":"https://www.researchgate.net/publication/41460472_Caracterisation_de_l'environnement_musical_dans_les_documents_audiovisuels"},{"id":261277242,"url":"https://www.researchgate.net/publication/261277242_Real_life_emotion_classification_using_VOP_and_pitch_based_spectral_features"},{"id":220716942,"url":"https://www.researchgate.net/publication/220716942_Designing_a_Hungarian_Multimodal_Database_-_Speech_Recording_and_Annotation"},{"id":251929062,"url":"https://www.researchgate.net/publication/251929062_Changes_in_frequency_spectrum_of_vowels_due_to_psychological_stress"},{"id":251949710,"url":"https://www.researchgate.net/publication/251949710_Classification_of_varying_length_time_series_using_example-specific_adapted_Gaussian_mixture_models_and_support_vector_machines"},{"id":251922397,"url":"https://www.researchgate.net/publication/251922397_Support_vector_regression_based_autoassociative_models_for_time_series_classification"},{"id":220716760,"url":"https://www.researchgate.net/publication/220716760_Automatic_Recognition_of_Emotional_State_in_Polish_Speech"},{"id":220795824,"url":"https://www.researchgate.net/publication/220795824_EmoReSp_an_online_emotion_recognizer_based_on_speech"},{"id":232637142,"url":"https://www.researchgate.net/publication/232637142_A_Study_of_Zero-Crossings_with_Peak-Amplitudes_in_Speech_Emotion_Classification"},{"id":232617307,"url":"https://www.researchgate.net/publication/232617307_Novel_Hilbert_Energy_Spectrum_Based_Features_for_Speech_Emotion_Recognition"},{"id":220497192,"url":"https://www.researchgate.net/publication/220497192_On_the_Impact_of_Children's_Emotional_Speech_on_Acoustic_and_Language_Models"},{"id":224929598,"url":"https://www.researchgate.net/publication/224929598_On_the_Impact_of_Children's_Emotional_Speech_on_Acoustic_and_Language_Models"},{"id":220922934,"url":"https://www.researchgate.net/publication/220922934_Real-Time_Emotional_Speech_Processing_for_Neurorobotics_Applications"},{"id":220930393,"url":"https://www.researchgate.net/publication/220930393_Speech_Emotion_Analysis_in_Noisy_Real-World_Environment"},{"id":221480715,"url":"https://www.researchgate.net/publication/221480715_Analysis_of_excitation_source_information_in_emotional_speech"},{"id":230562927,"url":"https://www.researchgate.net/publication/230562927_The_use_of_affective_and_attentive_cues_in_an_empathic_computer-based_Companions"},{"id":281042381,"url":"https://www.researchgate.net/publication/281042381_Towards_a_standard_set_of_acoustic_features_for_the_processing_of_emotion_in_speech"},{"id":251924316,"url":"https://www.researchgate.net/publication/251924316_An_overview_and_preparation_for_recognition_of_emotion_from_speech_signal_with_multi_modal_fusion"},{"id":225313800,"url":"https://www.researchgate.net/publication/225313800_Emotion_recognition_and_adaptation_in_spoken_dialogue_systems"},{"id":224929634,"url":"https://www.researchgate.net/publication/224929634_On-line_Emotion_Recognition_in_a_3-D_Activation-Valence-Time_Continuum_using_Acoustic_and_Linguistic_Cues"},{"id":225359641,"url":"https://www.researchgate.net/publication/225359641_Towards_Emotion_Recognition_from_Speech_Definition_Problems_and_the_Materials_of_Research"},{"id":42386822,"url":"https://www.researchgate.net/publication/42386822_Segmenting_into_Adequate_Units_for_Automatic_Recognition_of_Emotion-Related_Episodes_A_Speech-Based_Approach"},{"id":226030287,"url":"https://www.researchgate.net/publication/226030287_Emotional_Vocal_Expressions_Recognition_Using_the_COST_2102_Italian_Database_of_Emotional_Speech"},{"id":222612883,"url":"https://www.researchgate.net/publication/222612883_Emotion_recognition_from_speech_signals_using_new_harmony_features"},{"id":274468127,"url":"https://www.researchgate.net/publication/274468127_Temporal_Pattern_Classification_using_Kernel_Methods_for_Speech"},{"id":232638637,"url":"https://www.researchgate.net/publication/232638637_Cross-Corpus_Acoustic_Emotion_Recognition_Variances_and_Strategies"},{"id":224167100,"url":"https://www.researchgate.net/publication/224167100_Driver_Behavior_Analysis_through_Speech_Emotion_Understanding"},{"id":224130052,"url":"https://www.researchgate.net/publication/224130052_Evaluation_of_Expressive_Speech_Synthesis_With_Voice_Conversion_and_Copy_Resynthesis_Techniques"},{"id":222301848,"url":"https://www.researchgate.net/publication/222301848_A_learning_approach_to_hierarchical_feature_selection_and_aggregation_for_audio_classification"},{"id":221152096,"url":"https://www.researchgate.net/publication/221152096_Emotion_Recognition_from_Speech_by_Combining_Databases_and_Fusion_of_Classifiers"},{"id":225247815,"url":"https://www.researchgate.net/publication/225247815_EMD-TEO_Based_Speech_Emotion_Recognition"},{"id":225337165,"url":"https://www.researchgate.net/publication/225337165_Extraction_of_Visual_and_Acoustic_Features_of_the_Driver_for_Monitoring_Driver_Ergonomics_Applied_to_Extended_Driver_Assistance_Systems"},{"id":251973285,"url":"https://www.researchgate.net/publication/251973285_KIsomap-based_feature_extraction_for_spoken_emotion_recognition"},{"id":251993213,"url":"https://www.researchgate.net/publication/251993213_Speech_Emotion_Recognition_using_a_backward_context"},{"id":232614527,"url":"https://www.researchgate.net/publication/232614527_Factor_Analysis_and_Majority_Voting_Based_Speech_Emotion_Recogntion"},{"id":221230232,"url":"https://www.researchgate.net/publication/221230232_Emotions_analysis_of_speech_for_call_classification"},{"id":224174386,"url":"https://www.researchgate.net/publication/224174386_Feature_Analysis_and_Evaluation_for_Automatic_Emotion_Identification_in_Speech"},{"id":224155355,"url":"https://www.researchgate.net/publication/224155355_Combining_Long_Short-Term_Memory_and_Dynamic_Bayesian_Networks_for_Incremental_Emotion-Sensitive_Artificial_Listening"},{"id":220359930,"url":"https://www.researchgate.net/publication/220359930_Phonetic_Segmentation_of_Emotional_Speech_with_HMM-Based_Methods"},{"id":224234161,"url":"https://www.researchgate.net/publication/224234161_Rock_image_segmentation_using_watershed_with_shape_markers"},{"id":216672857,"url":"https://www.researchgate.net/publication/216672857_Relative_Amplitude_based_Features_for_Emotion_Detection_from_Speech"},{"id":252012056,"url":"https://www.researchgate.net/publication/252012056_Turkish_emotional_speech_database"},{"id":241181174,"url":"https://www.researchgate.net/publication/241181174_Feature_diversity_for_emotion_language_and_speaker_verification"},{"id":225716424,"url":"https://www.researchgate.net/publication/225716424_A_survey_of_hierarchical_classification_across_different_application_domains"},{"id":252035236,"url":"https://www.researchgate.net/publication/252035236_A_study_on_emotional_feature_extraction_and_analysis_in_speech"},{"id":216673462,"url":"https://www.researchgate.net/publication/216673462_Multi-algorithm_Fusion_for_Speech_Emotion_Recognition"},{"id":220734318,"url":"https://www.researchgate.net/publication/220734318_A_study_of_the_effect_of_emotional_state_upon_text-independent_speaker_identification"},{"id":236141865,"url":"https://www.researchgate.net/publication/236141865_Segmented-memory_recurrent_neural_networks_versus_hidden_Markov_models_in_emotion_recognition_from_speech"},{"id":224929672,"url":"https://www.researchgate.net/publication/224929672_Selecting_Training_Data_for_Cross-Corpus_Speech_Emotion_Recognition_Prototypicality_vs_Generalization"},{"id":221491825,"url":"https://www.researchgate.net/publication/221491825_Neutral_to_Target_Emotion_Conversion_Using_Source_and_Suprasegmental_Information"},{"id":224929562,"url":"https://www.researchgate.net/publication/224929562_Voice_and_Speech_Analysis_in_Search_of_States_and_Traits"},{"id":241637518,"url":"https://www.researchgate.net/publication/241637518_Model-based_parametric_features_for_emotion_recognition_from_speech"},{"id":254049990,"url":"https://www.researchgate.net/publication/254049990_Improvement_of_Thai_speech_emotion_recognition_using_face_feature_analysis"},{"id":220121040,"url":"https://www.researchgate.net/publication/220121040_Application_of_speaker-_and_language_identification_state-of-the-art_techniques_for_emotion_recognition"},{"id":258533119,"url":"https://www.researchgate.net/publication/258533119_Toward_Autonomous_Adaptive_and_Context-Aware_Multimodal_Interfaces_Theoretical_and_Practical_Issues"},{"id":221523867,"url":"https://www.researchgate.net/publication/221523867_Oscillating_Statistical_Moments_for_Speech_Polarity_Detection"},{"id":268198781,"url":"https://www.researchgate.net/publication/268198781_Improved_Emotion_Recognition_with_Novel_Global_Utterance-level_Features"},{"id":224225269,"url":"https://www.researchgate.net/publication/224225269_Stressed_speech_processing_Human_vs_automatic_in_non-professional_speakers_scenario"},{"id":224238110,"url":"https://www.researchgate.net/publication/224238110_Obtaining_speech_assets_for_judgement_analysis_on_low-pass_filtered_emotional_speech"},{"id":220405644,"url":"https://www.researchgate.net/publication/220405644_Speech_emotion_recognition_using_novel_HHT-TEO_based_features"},{"id":51078494,"url":"https://www.researchgate.net/publication/51078494_Discriminant_Independent_Component_Analysis"},{"id":220629715,"url":"https://www.researchgate.net/publication/220629715_Spoken_emotion_recognition_using_hierarchical_classifiers"},{"id":220633913,"url":"https://www.researchgate.net/publication/220633913_An_Evaluation_of_Emotion_Units_and_Feature_Types_for_Real-Time_Speech_Emotion_Recognition"},{"id":226725999,"url":"https://www.researchgate.net/publication/226725999_Social_Signal_Interpretation_SSI"},{"id":261049109,"url":"https://www.researchgate.net/publication/261049109_Audio-Emotion_Recognition_System_Using_Parallel_Classifiers_and_Audio_Feature_Analyzer"},{"id":257727154,"url":"https://www.researchgate.net/publication/257727154_Extraction_of_novel_features_for_emotion_recognition"},{"id":221621975,"url":"https://www.researchgate.net/publication/221621975_EmoWisconsin_An_Emotional_Children_Speech_Database_in_Mexican_Spanish"},{"id":220119798,"url":"https://www.researchgate.net/publication/220119798_Towards_the_detection_of_social_dominance_in_dialogue"},{"id":220119856,"url":"https://www.researchgate.net/publication/220119856_Recognizing_affect_from_speech_prosody_using_hierarchical_graphics_models"},{"id":222650661,"url":"https://www.researchgate.net/publication/222650661_Recognising_realistic_emotions_and_affect_in_speech_State_of_the_art_and_lessons_learnt_from_the_first_challenge"},{"id":224265350,"url":"https://www.researchgate.net/publication/224265350_Using_an_Automated_Speech_Emotion_Recognition_Technique_to_Explore_the_Impact_of_Bullying_on_Pupils_Social_Life"},{"id":224266277,"url":"https://www.researchgate.net/publication/224266277_Converting_emotional_voice_to_motion_for_robot_telepresence"},{"id":224240902,"url":"https://www.researchgate.net/publication/224240902_Exploring_Fusion_Methods_for_Multimodal_Emotion_Recognition_with_Missing_Data"},{"id":256309363,"url":"https://www.researchgate.net/publication/256309363_A_Generic_Framework_for_the_Inference_of_User_States_in_Human_Computer_Interaction_How_patterns_of_low_level_communicational_cues_support_complex_affective_states"},{"id":255991391,"url":"https://www.researchgate.net/publication/255991391_The_Influence_of_Context_Knowledge_for_Multimodal_Annotation_on_Natural_Material"},{"id":266739508,"url":"https://www.researchgate.net/publication/266739508_Using_Paralingua_database_for_investigation_of_affective_states_and_paralinguistic_features"},{"id":266739521,"url":"https://www.researchgate.net/publication/266739521_Emotional_speech_production_and_perception_in_Polish_A_framework_of_analysis"},{"id":220068793,"url":"https://www.researchgate.net/publication/220068793_Robust_emotion_recognition_by_spectro-temporal_modulation_statistic_features"},{"id":261202351,"url":"https://www.researchgate.net/publication/261202351_HHT_based_long_term_feature_extracting_method_for_speech_emotion_classification"},{"id":261259256,"url":"https://www.researchgate.net/publication/261259256_Towards_an_online_fuzzy_modeling_for_human_internal_states_detection"},{"id":241631144,"url":"https://www.researchgate.net/publication/241631144_Audio_emotion_recognition_by_perceptual_features"},{"id":253301518,"url":"https://www.researchgate.net/publication/253301518_A_Novel_Way_to_Start_Speech_Dialogs_in_Cars_by_Talk-and-Push_TAP"},{"id":269984769,"url":"https://www.researchgate.net/publication/269984769_Pristupy_k_vnimaniu_emocii_v_humanoidnej_robotike"},{"id":224248861,"url":"https://www.researchgate.net/publication/224248861_Recognizing_Affect_from_Linguistic_Information_in_3D_Continuous_Space"},{"id":221776346,"url":"https://www.researchgate.net/publication/221776346_Auditory_Affective_Norms_for_German_Testing_the_Influence_of_Depression_and_Anxiety_on_Valence_and_Arousal_Ratings"},{"id":229272723,"url":"https://www.researchgate.net/publication/229272723_Acoustic_feature_selection_and_classification_of_emotions_in_speech_using_a_3D_continuous_emotion_model"},{"id":257758625,"url":"https://www.researchgate.net/publication/257758625_A_robust_feature_extraction_approach_based_on_an_auditory_model_for_classification_of_speech_and_expressiveness"},{"id":235761693,"url":"https://www.researchgate.net/publication/235761693_A_cross-cultural_multimodal_affective_corpus_for_gesture_expressivity_analysis"},{"id":277194144,"url":"https://www.researchgate.net/publication/277194144_Emotion_recognition_from_speech_signals"},{"id":224855568,"url":"https://www.researchgate.net/publication/224855568_Recognizing_vocal_emotions_in_Mandarin_Chinese_A_validated_database_of_Chinese_vocal_emotional_stimuli"},{"id":261129034,"url":"https://www.researchgate.net/publication/261129034_Best_features_for_emotional_speech_classification_in_the_presence_of_babble_noise"},{"id":257571892,"url":"https://www.researchgate.net/publication/257571892_Emotion_recognition_from_speech_A_review"},{"id":257571796,"url":"https://www.researchgate.net/publication/257571796_Emotion_recognition_from_speech_using_global_and_local_prosodic_features_Int_J_Speech_Technol_15_265-289"},{"id":261125338,"url":"https://www.researchgate.net/publication/261125338_The_Performance_of_the_Speaking_Rate_Parameter_in_Emotion_Recognition_from_Speech"},{"id":261050596,"url":"https://www.researchgate.net/publication/261050596_Evaluation_of_MPEG-7_Descriptors_for_Speech_Emotional_Recognition"},{"id":230633017,"url":"https://www.researchgate.net/publication/230633017_On_the_recognition_of_emotional_vocal_expressions_Motivations_for_a_holistic_approach"},{"id":264040541,"url":"https://www.researchgate.net/publication/264040541_Eco-friendly_Computing_and_Communication_Systems"},{"id":257571785,"url":"https://www.researchgate.net/publication/257571785_Neural_network_based_feature_transformation_for_emotion_independent_speaker_identification"},{"id":257011969,"url":"https://www.researchgate.net/publication/257011969_Classification_of_emotional_speech_using_3DEC_hierarchical_classifier"},{"id":257571910,"url":"https://www.researchgate.net/publication/257571910_Synthesized_speech_for_model_training_in_cross-corpus_recognition_of_human_emotion"},{"id":259889705,"url":"https://www.researchgate.net/publication/259889705_Speech_Emotion_Age_Language_Task_and_Typicality_Trying_to_Disentangle_Performance_and_Feature_Relevance"},{"id":288365145,"url":"https://www.researchgate.net/publication/288365145_A_Hybrid_Neural_Emotion_Recogniser_for_Human-Robotic_Agent_Interaction"},{"id":234057323,"url":"https://www.researchgate.net/publication/234057323_A_generic_framework_for_the_inference_of_user_states_in_human_computer_interaction_How_patterns_of_low_level_behavioral_cues_support_complex_user_states_in_HCI"},{"id":261468891,"url":"https://www.researchgate.net/publication/261468891_Improving_emotion_recognition_from_speech_using_sensor_fusion_techniques"},{"id":262242864,"url":"https://www.researchgate.net/publication/262242864_Towards_IMACA_Intelligent_Multimodal_Affective_Conversational_Agent"},{"id":257571786,"url":"https://www.researchgate.net/publication/257571786_Emotion_recognition_from_speech_using_sub-syllabic_and_pitch_synchronous_spectral_features"},{"id":257597656,"url":"https://www.researchgate.net/publication/257597656_Using_speaker_group_dependent_modelling_to_improve_fusion_of_fragmentary_classifier_decisions"},{"id":260438249,"url":"https://www.researchgate.net/publication/260438249_Emotion_Classification_Using_Inter-and_Intra-Subband_Energy_Variation"},{"id":261273542,"url":"https://www.researchgate.net/publication/261273542_Internet_application_for_collective_realization_of_speech_evaluation_by_listening_tests"},{"id":224929574,"url":"https://www.researchgate.net/publication/224929574_Paralinguistics_in_Speech_and_Language_-_State-of-the-Art_and_the_Challenge"},{"id":261203419,"url":"https://www.researchgate.net/publication/261203419_A_speech_emotion_recognition_framework_based_on_latent_Dirichlet_allocation_Algorithm_and_FPGA_implementation"},{"id":271460842,"url":"https://www.researchgate.net/publication/271460842_Detection_of_affective_states_from_speech_signals_using_ensembles_of_classifiers"},{"id":261280387,"url":"https://www.researchgate.net/publication/261280387_Application_of_dimensional_emotion_model_in_automatic_emotional_speech_recognition"},{"id":261226051,"url":"https://www.researchgate.net/publication/261226051_Speech_based_Emotion_Recognition_based_on_hierarchical_decision_tree_with_SVM_BLG_and_SVR_classifiers"},{"id":263921712,"url":"https://www.researchgate.net/publication/263921712_Determination_of_Formant_Features_in_Czech_and_Slovak_for_GMM_Emotional_Speech_Classifier"},{"id":257734636,"url":"https://www.researchgate.net/publication/257734636_Baza_danych_nagran_mowy_emocjonalnej_Database_of_emotional_speech_recordings"},{"id":261490747,"url":"https://www.researchgate.net/publication/261490747_Speech_emotion_recognition_using_combination_of_features"},{"id":258857413,"url":"https://www.researchgate.net/publication/258857413_Hierarchical_Clustering_and_Classification_of_Emotions_in_Human_Speech_Using_Confusion_Matrices"},{"id":228092550,"url":"https://www.researchgate.net/publication/228092550_A_Review_of_Music_and_Emotion_Studies_Approaches_Emotion_Models_and_Stimuli"},{"id":235741110,"url":"https://www.researchgate.net/publication/235741110_When_voices_get_emotional_A_corpus_of_nonverbal_vocalizations_for_research_on_emotion_processing"},{"id":259636738,"url":"https://www.researchgate.net/publication/259636738_Using_unlabeled_data_to_improve_classification_of_emotional_states_in_human_computer_interaction"},{"id":257626910,"url":"https://www.researchgate.net/publication/257626910_Dimensionality_reduction-based_spoken_emotion_recognition"},{"id":258791987,"url":"https://www.researchgate.net/publication/258791987_Residual_Excitation_Skewness_for_Automatic_Speech_Polarity_Detection"},{"id":257879615,"url":"https://www.researchgate.net/publication/257879615_Evaluation_of_influence_of_spectral_and_prosodic_features_on_GMM_classification_of_Czech_and_Slovak_emotional_speech"},{"id":236615221,"url":"https://www.researchgate.net/publication/236615221_Reward-based_learning_for_virtual_neurorobotics_through_emotional_speech_processing"},{"id":237836274,"url":"https://www.researchgate.net/publication/237836274_Speaker_identification_from_shouted_speech_analysis_and_compensation"},{"id":257571799,"url":"https://www.researchgate.net/publication/257571799_Characterization_and_recognition_of_emotions_from_speech_using_excitation_source_information"},{"id":257571933,"url":"https://www.researchgate.net/publication/257571933_Expressive_speech_synthesis_A_review"},{"id":260701110,"url":"https://www.researchgate.net/publication/260701110_On_Acoustic_Emotion_Recognition_Compensating_for_Covariate_Shift"},{"id":260669322,"url":"https://www.researchgate.net/publication/260669322_Study_of_Wavelet_Packet_Energy_Entropy_for_Emotion_Classification_in_Speech_and_Glottal_Signals"},{"id":256578785,"url":"https://www.researchgate.net/publication/256578785_The_Influence_of_Context_Knowledge_for_Multi-modal_Affective_Annotation"},{"id":258023891,"url":"https://www.researchgate.net/publication/258023891_Gender-Driven_Emotion_Recognition_Through_Speech_Signals_For_Ambient_Intelligence_Applications"},{"id":260862944,"url":"https://www.researchgate.net/publication/260862944_First_Progresses_in_Evaluation_of_Resonance_in_Staff_Selection_through_Speech_Emotion_Recognition"},{"id":263921964,"url":"https://www.researchgate.net/publication/263921964_Evaluation_of_Influence_of_Spectral_and_Prosodic_Features_on_GMM_Classification_of_Czech_and_Slovak_Emotional_Speech"},{"id":255982958,"url":"https://www.researchgate.net/publication/255982958_Emotion-Detection_in_HCI_From_Speech_Features_to_Emotion_Space"},{"id":261995471,"url":"https://www.researchgate.net/publication/261995471_Analysis_of_emotional_speech_at_subsegmental_level"},{"id":259889785,"url":"https://www.researchgate.net/publication/259889785_Sparse_Autoencoder-Based_Feature_Transfer_Learning_for_Speech_Emotion_Recognition"},{"id":261265181,"url":"https://www.researchgate.net/publication/261265181_Parameter_Optimization_Issues_for_Cross-corpora_Emotion_Classification"},{"id":261500879,"url":"https://www.researchgate.net/publication/261500879_Hybrid_Deep_Neural_Network_-_Hidden_Markov_Model_DNN-HMM_based_speech_emotion_recognition"},{"id":263973659,"url":"https://www.researchgate.net/publication/263973659_Internet_Application_for_Collective_Realization_of_Speech_Evaluation_by_Listening_Tests"},{"id":258439617,"url":"https://www.researchgate.net/publication/258439617_Excitation_source_and_low_level_descriptor_features_fusion_for_emotion_recognition_using_SVM_and_ANN"},{"id":266968747,"url":"https://www.researchgate.net/publication/266968747_Review_of_Emotion_Recognition_from_Speech"},{"id":261277197,"url":"https://www.researchgate.net/publication/261277197_Feature_space_dimension_reduction_in_speech_emotion_recognition_using_support_vector_machine"},{"id":261493607,"url":"https://www.researchgate.net/publication/261493607_Cross-lingual_speech_emotion_recognition_system_based_on_a_three-layer_model_for_human_perception"},{"id":261208282,"url":"https://www.researchgate.net/publication/261208282_Comparing_feature_dimension_reduction_algorithms_for_GMM-SVM_based_speech_emotion_recognition"},{"id":261208332,"url":"https://www.researchgate.net/publication/261208332_Emotion_recognition_from_multi-modal_information"},{"id":261277241,"url":"https://www.researchgate.net/publication/261277241_BFI-based_speaker_personality_perception_using_acoustic-prosodic_features"},{"id":269327937,"url":"https://www.researchgate.net/publication/269327937_Valence-arousal_approach_for_speech_emotion_recognition_system"},{"id":257788166,"url":"https://www.researchgate.net/publication/257788166_Detecting_Speech_Polarity_with_High-Order_Statistics"},{"id":269300314,"url":"https://www.researchgate.net/publication/269300314_Measuring_Customer_Perceptions_Index_Using_CMAC_Speech_Emotion_Mapping"},{"id":271469117,"url":"https://www.researchgate.net/publication/271469117_Reduce_the_dimensions_of_emotional_features_by_principal_component_analysis_for_speech_emotion_recognition"},{"id":269304216,"url":"https://www.researchgate.net/publication/269304216_Text_material_design_for_fuzzy_emotional_speech_corpus_based_on_persian_semantic_and_structure"},{"id":271553031,"url":"https://www.researchgate.net/publication/271553031_A_multi-parameter_objective_evaluation_system_for_English_sentence_pronunciation"},{"id":269928011,"url":"https://www.researchgate.net/publication/269928011_Recognizing_emotion_from_Turkish_speech_using_acoustic_features"},{"id":257780509,"url":"https://www.researchgate.net/publication/257780509_A_Survey_on_Perception_Methods_for_Human-Robot_Interaction_in_Social_Robots"},{"id":278708214,"url":"https://www.researchgate.net/publication/278708214_Classification_Methods_Accuracy_for_Speech_Emotion_Recognition_System"},{"id":259011356,"url":"https://www.researchgate.net/publication/259011356_Inter-Rater_Reliability_for_Emotion_Annotation_in_Human-Computer_Interaction_--_Comparison_and_Methodological_Improvements"},{"id":257435889,"url":"https://www.researchgate.net/publication/257435889_Audiovisual_emotion_recognition_using_ANOVA_feature_selection_method_and_multi-classifier_neural_networks"},{"id":259118450,"url":"https://www.researchgate.net/publication/259118450_Continuous_emotion_recognition_with_phonetic_syllables"},{"id":260031023,"url":"https://www.researchgate.net/publication/260031023_Speaker-sensitive_Emotion_Recognition_via_Ranking_Studies_on_Acted_and_Spontaneous_Speech"},{"id":271546717,"url":"https://www.researchgate.net/publication/271546717_An_effective_automatic_speech_emotion_recognition_for_Tamil_language_using_Support_Vector_Machine"},{"id":260947146,"url":"https://www.researchgate.net/publication/260947146_MFCC_Based_Enlargement_of_the_Training_Set_for_Emotion_Recognition_in_Speech"},{"id":269301411,"url":"https://www.researchgate.net/publication/269301411_Automatic_Speech_Emotion_Recognition_A_survey"},{"id":269303471,"url":"https://www.researchgate.net/publication/269303471_Audio-based_gender_and_age_identification"},{"id":264387209,"url":"https://www.researchgate.net/publication/264387209_Robust_Unsupervised_Arousal_RatingA_Rule-Based_Framework_withKnowledge-Inspired_Vocal_Features"},{"id":266143782,"url":"https://www.researchgate.net/publication/266143782_Caller_Identification_by_Voice"},{"id":262936719,"url":"https://www.researchgate.net/publication/262936719_The_MEI_Robot_Towards_Using_Motherese_to_Develop_Multimodal_Emotional_Intelligence"},{"id":268238986,"url":"https://www.researchgate.net/publication/268238986_A_feature_selection_and_feature_fusion_combination_method_for_speaker-independent_speech_emotion_recognition"},{"id":261028625,"url":"https://www.researchgate.net/publication/261028625_Time-Frequency_Feature_and_AMS-GMM_Mask_for_Acoustic_Emotion_Classification"},{"id":260945765,"url":"https://www.researchgate.net/publication/260945765_A_Novel_Speech_Emotion_Recognition_Method_via_Incomplete_Sparse_Least_Square_Regression"},{"id":269297221,"url":"https://www.researchgate.net/publication/269297221_Emotion_recognition_from_speech_based_on_relevant_feature_and_majority_voting"},{"id":262419113,"url":"https://www.researchgate.net/publication/262419113_Emotions_Are_A_Personal_Thing_Towards_Speaker-Adaptive_Emotion_Recognition"},{"id":263287867,"url":"https://www.researchgate.net/publication/263287867_Directed_Acyclic_Graphs_for_Content_Based_Sound_Musical_Genre_and_Speech_Emotion_Classification"},{"id":262608808,"url":"https://www.researchgate.net/publication/262608808_Erratum_to_Recognizing_emotional_speech_in_Persian_A_validated_database_of_Persian_emotional_speech_Persian_ESD"},{"id":271545521,"url":"https://www.researchgate.net/publication/271545521_Gaussian_mixture_models_with_class-dependent_features_for_speech_emotion_recognition"},{"id":259118449,"url":"https://www.researchgate.net/publication/259118449_GMM-Based_Intermediate_Matching_Kernel_for_Classification_of_Varying_Length_Patterns_of_Long_Duration_Speech_Using_Support_Vector_Machines"},{"id":284755533,"url":"https://www.researchgate.net/publication/284755533_Adaptive_Hierarchical_Emotion_Recognition_from_Speech_Signal_for_Human-Robot_Communication"},{"id":263551043,"url":"https://www.researchgate.net/publication/263551043_Evaluation_of_Resonance_in_Staff_Selection_through_Multimedia_Contents"},{"id":264196363,"url":"https://www.researchgate.net/publication/264196363_A_Database_of_Japanese_Emotional_Signals_Elicited_by_Real_Experiences"},{"id":273123956,"url":"https://www.researchgate.net/publication/273123956_Machine_Medical_Ethics"},{"id":272081518,"url":"https://www.researchgate.net/publication/272081518_CREMA-D_Crowd-sourced_emotional_multimodal_actors_dataset"},{"id":269503768,"url":"https://www.researchgate.net/publication/269503768_Using_Audio-Derived_Affective_Offset_to_Enhance_TV_Recommendation"},{"id":289001312,"url":"https://www.researchgate.net/publication/289001312_Automatic_emotion_variation_detection_using_multi-scaled_sliding_window"},{"id":266857516,"url":"https://www.researchgate.net/publication/266857516_A_comparative_analysis_of_classifiers_in_emotion_recognition_through_acoustic_features"},{"id":269108959,"url":"https://www.researchgate.net/publication/269108959_GMM-Based_Evaluation_of_Emotional_Style_Transformation_in_Czech_and_Slovak"},{"id":265035288,"url":"https://www.researchgate.net/publication/265035288_Investigation_of_Speaker_Group-Dependent_Modelling_for_Recognition_of_Affective_States_from_Speech"},{"id":273394198,"url":"https://www.researchgate.net/publication/273394198_Learning_Salient_Features_for_Speech_Emotion_Recognition_Using_Convolutional_Neural_Networks"},{"id":269174908,"url":"https://www.researchgate.net/publication/269174908_The_MPI_Emotional_Body_Expressions_Database_for_Narrative_Scenarios"},{"id":281933003,"url":"https://www.researchgate.net/publication/281933003_Toward_affective_speech-to-speech_translation_Strategy_for_emotional_speech_recognition_and_synthesis_in_multiple_languages"},{"id":274195878,"url":"https://www.researchgate.net/publication/274195878_Floating_to_Fixed-Point_Translation_with_Its_Application_to_Speech-Based_Emotion_Recognition"},{"id":270223053,"url":"https://www.researchgate.net/publication/270223053_Automatic_analysis_of_speech_F0_contour_for_the_characterization_of_mood_changes_in_bipolar_patients"},{"id":276118955,"url":"https://www.researchgate.net/publication/276118955_Inference_of_Human_Beings'_Emotional_States_from_Speech_in_Human-Robot_Interactions"},{"id":281886806,"url":"https://www.researchgate.net/publication/281886806_An_Online_Fuzzy-Based_Approach_for_Human_Emotions_Detection_An_Overview_on_the_Human_Cognitive_Model_of_Understanding_and_Generating_Multimodal_Actions"},{"id":277667061,"url":"https://www.researchgate.net/publication/277667061_Speech_Emotion_Recognition_Using_Adaptive_Ensemble_of_Class_Specific_Classifiers"},{"id":282301283,"url":"https://www.researchgate.net/publication/282301283_Cross_corpus_speech_emotion_recognition_using_semi-supervised_discriminant_analysis"},{"id":282301456,"url":"https://www.researchgate.net/publication/282301456_Spontaneous_emotional_speech_recordings_through_a_cooperative_online_video_game"},{"id":283186011,"url":"https://www.researchgate.net/publication/283186011_A_Robust_Algorithm_for_Speech_Polarity_Detection_Using_Epochs_and_Hilbert_Phase_Information"},{"id":282540984,"url":"https://www.researchgate.net/publication/282540984_The_Geneva_Minimalistic_Acoustic_Parameter_Set_GeMAPS_for_Voice_Research_and_Affective_Computing"},{"id":282242284,"url":"https://www.researchgate.net/publication/282242284_Building_a_Chinese_Natural_Emotional_Audio-Visual_Database"},{"id":272512156,"url":"https://www.researchgate.net/publication/272512156_Sadness_is_unique_Neural_processing_of_emotions_in_speech_prosody_in_musicians_and_non-musicians"},{"id":272029415,"url":"https://www.researchgate.net/publication/272029415_Emotion_recognition_using_semi-supervised_feature_selection_with_speaker_normalization"},{"id":282931369,"url":"https://www.researchgate.net/publication/282931369_Automatic_Emotion_Variation_Detection_in_continuous_speech"},{"id":272624483,"url":"https://www.researchgate.net/publication/272624483_Can_you_hear_what_I_feel_A_validated_prosodic_set_of_angry_happy_and_neutral_Italian_pseudowords"},{"id":273783197,"url":"https://www.researchgate.net/publication/273783197_The_contribution_of_phonation_type_to_the_perception_of_vocal_emotions_in_German_An_articulatory_synthesis_study"},{"id":276489081,"url":"https://www.researchgate.net/publication/276489081_Improved_Emotion_Recognition_Using_Gaussian_Mixture_Model_and_Extreme_Learning_Machine_in_Speech_and_Glottal_Signals"},{"id":277132776,"url":"https://www.researchgate.net/publication/277132776_Particle_Swarm_Optimization_Based_Feature_Enhancement_and_Feature_Selection_for_Improved_Emotion_Recognition_in_Speech_and_Glottal_Signals"},{"id":278300778,"url":"https://www.researchgate.net/publication/278300778_Automatic_Emotion_Recognition_from_Speech_Signals_A_Review"},{"id":285602763,"url":"https://www.researchgate.net/publication/285602763_Emotional_states_discrimination_in_voice_in_secure_environments"},{"id":270345065,"url":"https://www.researchgate.net/publication/270345065_Weighted_spectral_features_based_on_local_Hu_moments_for_speech_emotion_recognition"},{"id":275647713,"url":"https://www.researchgate.net/publication/275647713_Combining_modality-specific_extreme_learning_machines_for_emotion_recognition_in_the_wild"},{"id":282301281,"url":"https://www.researchgate.net/publication/282301281_Automated_recognition_of_paralinguistic_signals_in_spoken_dialogue_systems_Ways_of_improvement"},{"id":278024470,"url":"https://www.researchgate.net/publication/278024470_Evaluation_Criteria_for_Affect-Annotated_Databases"},{"id":277963057,"url":"https://www.researchgate.net/publication/277963057_Adaptive_Wavelet_Packet_Filter-Bank_Based_Acoustic_Feature_for_Speech_Emotion_Recognition"},{"id":285602771,"url":"https://www.researchgate.net/publication/285602771_Speech_emotion_recognition_using_RBF_kernel_of_LIBSVM"},{"id":282696656,"url":"https://www.researchgate.net/publication/282696656_Spectral_emotion_profile"},{"id":281439942,"url":"https://www.researchgate.net/publication/281439942_New_approach_in_quantification_of_emotional_intensity_from_the_speech_signal_Emotional_temperature"},{"id":283258742,"url":"https://www.researchgate.net/publication/283258742_Issues_in_Formant_Analysis_of_Emotive_Speech_Using_Vowel-Like_Region_Onset_Points"},{"id":276834955,"url":"https://www.researchgate.net/publication/276834955_Study_of_feature_combination_using_HMM_and_SVM_for_multilingual_Odiya_speech_emotion_recognition"},{"id":282439934,"url":"https://www.researchgate.net/publication/282439934_Time_Dependent_ARMA_for_Automatic_Recognition_of_Fear-Type_Emotions_in_Speech"},{"id":283015075,"url":"https://www.researchgate.net/publication/283015075_Cross-corpus_analysis_for_acoustic_recognition_of_negative_interactions"},{"id":282602122,"url":"https://www.researchgate.net/publication/282602122_Exploring_Dataset_Similarities_using_PCA-based_Feature_Selection"},{"id":281842757,"url":"https://www.researchgate.net/publication/281842757_Long-term_Statistical_Feature_Extraction_from_Speech_Signal_and_its_Application_in_Emotion_Recognition"},{"id":280734667,"url":"https://www.researchgate.net/publication/280734667_Sentic_Computing_A_Common-Sense-Based_Framework_for_Concept-Level_Sentiment_Analysis"},{"id":284813376,"url":"https://www.researchgate.net/publication/284813376_Audio-visual_emotion_recognition_using_multi-directional_regression_and_Ridgelet_transform"},{"id":280734741,"url":"https://www.researchgate.net/publication/280734741_Sentic_Computing_A_Common-Sense-Based_Framework_for_Concept-Level_Sentiment_Analysis"},{"id":287999670,"url":"https://www.researchgate.net/publication/287999670_Classifier_Subset_Selection_for_the_Stacked_Generalization_Method_Applied_to_Emotion_Recognition_in_Speech"},{"id":291390821,"url":"https://www.researchgate.net/publication/291390821_Efficient_feature_combination_techniques_for_emotional_speech_classification"},{"id":291949666,"url":"https://www.researchgate.net/publication/291949666_Audio-Visual_Emotion_Recognition_Using_Big_Data_Towards_5G"}],"reference":["https://www.researchgate.net/publication/238341999_The_gift_of_speech","https://www.researchgate.net/publication/14353171_Acoustic_Profiles_in_Vocal_Emotion_Expression","https://www.researchgate.net/publication/2953476_A_New_Emotion_Database_Considerations_Sources_And","https://www.researchgate.net/publication/2567555_Verification_of_Acousical_Correlates_of_Emotional_Speech_using_Formant-Synthesis","https://www.researchgate.net/publication/245494159_Articulatory_reduction_in_di_erent_speaking_styles","https://www.researchgate.net/publication/243764709_The_Phonetic_Description_of_Voice_Quality","https://www.researchgate.net/publication/256309637_Akustische_Korrelate_des_stimmlich_emotionalen_Ausdrucks_in_der_Lautsprache","https://www.researchgate.net/publication/34025011_Phonetische_Veranderungen_in_emotionaler_Sprechweise","https://www.researchgate.net/publication/34507305_Prosodische_Analyse_emotionaler_Sprechweise"]}