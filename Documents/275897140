{"id":275897140,"title":"A Linear-Time Particle Gibbs Sampler for Infinite Hidden Markov Models","authors":["Nilesh Tripuraneni","Shane Gu","Hong Ge","Zoubin Ghahramani"],"_abstract":"ABSTRACT Infinite Hidden Markov Models (iHMM's) are an attractive, nonparametric generalization of the classical Hidden Markov Model which automatically `infer' the number of hidden states in the model. This avoids the awkward problem of model selection and provides a parameter-free solution for a wide range of applications. Using the stick-breaking construction for the Hierarchical Dirichlet Process (HDP), we present a scalable, truncation-free Particle Gibbs sampler, leveraging Ancestor Sampling, to efficiently sample state trajectories for the infinite HMM. Our algorithm demonstrates state-of-the-art empirical performance and improved mixing while maintaining linear-time complexity in the number of particles in the sampler.","cited_in":[{"id":276923083,"url":"https://www.researchgate.net/publication/276923083_Sequential_Bayesian_inference_for_implicit_hidden_Markov_models_and_current_limitations"}],"reference":[]}