{"id":221292544,"title":"Painful data: The UNBC-McMaster shoulder pain expression archive database","authors":["Patrick Lucey","Jeffrey F Cohn","Kenneth M Prkachin","Patricia Solomon","Iain Matthews"],"_abstract":"ABSTRACT A major factor hindering the deployment of a fully functional automatic facial expression detection system is the lack of representative data. A solution to this is to narrow the context of the target application, so enough data is available to build robust models so high performance can be gained. Automatic pain detection from a patient's face represents one such application. To facilitate this work, researchers at McMaster University and University of Northern British Columbia captured video of participant's faces (who were suffering from shoulder pain) while they were performing a series of active and passive range-of-motion tests to their affected and unaffected limbs on two separate occasions. Each frame of this data was AU coded by certified FACS coders, and self-report and observer measures at the sequence level were taken as well. This database is called the UNBC-McMaster Shoulder Pain Expression Archive Database. To promote and facilitate research into pain and augment current datasets, we have publicly made available a portion of this database which includes: (1) 200 video sequences containing spontaneous facial expressions, (2) 48,398 FACS coded frames, (3) associated pain frame-by-frame scores and sequence-level self-report and observer measures, and (4) 66-point AAM landmarks. This paper documents this data distribution in addition to describing baseline results of our AAM/SVM system. This data will be available for distribution in March 2011.","cited_in":[{"id":267155572,"url":"https://www.researchgate.net/publication/267155572_Automatic_Behaviour_Understanding_in_Medicine"},{"id":281811172,"url":"https://www.researchgate.net/publication/281811172_Handling_Data_Imbalance_in_Automatic_Facial_Action_Intensity_Estimation"},{"id":277312235,"url":"https://www.researchgate.net/publication/277312235_Ensemble_of_Hankel_Matrices_for_Face_Emotion_Recognition"},{"id":282478275,"url":"https://www.researchgate.net/publication/282478275_The_automatic_detection_of_chronic_pain-related_expression_requirements_challenges_and_a_multimodal_dataset"},{"id":278763516,"url":"https://www.researchgate.net/publication/278763516_Facial_Action_Units_Intensity_Estimation_by_the_Fusion_of_Features_with_Multi-kernel_Support_Vector_Machine"},{"id":281276273,"url":"https://www.researchgate.net/publication/281276273_Facial_Expression_Analysis_for_Estimating_Pain_in_Clinical_Settings"},{"id":262331528,"url":"https://www.researchgate.net/publication/262331528_Context-Sensitive_Conditional_Ordinal_Random_Fields_for_Facial_Action_Intensity_Estimation"},{"id":254257855,"url":"https://www.researchgate.net/publication/254257855_Transfer_Learning_with_One-Class_Data"},{"id":254257602,"url":"https://www.researchgate.net/publication/254257602_Learning_person-specific_models_for_facial_expression_and_action_unit_recognition"},{"id":259972003,"url":"https://www.researchgate.net/publication/259972003_Facing_Imbalanced_Data_-_Recommendations_for_the_Use_of_Performance_Metrics"},{"id":237148069,"url":"https://www.researchgate.net/publication/237148069_Affective_State_Level_Recognition_in_Naturalistic_Facial_and_Vocal_Expressions"},{"id":259714804,"url":"https://www.researchgate.net/publication/259714804_Continuous_AU_Intensity_Estimation_using_Localized_Sparse_Facial_Feature_Space"},{"id":248703363,"url":"https://www.researchgate.net/publication/248703363_DISFA_A_spontaneous_facial_action_intensity_database"},{"id":234689229,"url":"https://www.researchgate.net/publication/234689229_Heteroscedastic_Conditional_Ordinal_Random_Fields_for_Pain_IntensityEstimation_from_Facial_Images"},{"id":259972200,"url":"https://www.researchgate.net/publication/259972200_Robust_Facial_Expression_Recognition_Using_Near_Infrared_Cameras"},{"id":261387182,"url":"https://www.researchgate.net/publication/261387182_Person-specific_expression_recognition_with_transfer_learning"},{"id":221430193,"url":"https://www.researchgate.net/publication/221430193_High_quality_facial_expression_recognition_in_video_streams_using_shape_related_information_only"},{"id":236333646,"url":"https://www.researchgate.net/publication/236333646_Efficient_Pose_Invariant_Facial_Emotion_Classification_using_3D_Constrained_Local_Model_and_2D_Shape_Information"},{"id":281276268,"url":"https://www.researchgate.net/publication/281276268_Exemplar_Hidden_Markov_Models_for_Classification_of_Facial_Expressions_in_Videos"},{"id":265742258,"url":"https://www.researchgate.net/publication/265742258_Exploiting_Unrelated_Tasks_in_Multi-Task_Learning"},{"id":261154876,"url":"https://www.researchgate.net/publication/261154876_Improved_facial_expression_recognition_via_uni-hyperplane_classification"},{"id":261387567,"url":"https://www.researchgate.net/publication/261387567_Fusion_of_static_and_temporal_predictors_for_unconstrained_facial_expression_recognition"},{"id":267843517,"url":"https://www.researchgate.net/publication/267843517_Continuous_Pain_Intensity_Estimation_From_Facial_Expressions"},{"id":224950389,"url":"https://www.researchgate.net/publication/224950389_In_the_Pursuit_of_Effective_Affective_Computing_The_Relationship_Between_Features_and_Registration"},{"id":230554292,"url":"https://www.researchgate.net/publication/230554292_3D_Shape_Estimation_in_Video_Sequences_Provides_High_Precision_Evaluation_of_Facial_Expressions"},{"id":260658411,"url":"https://www.researchgate.net/publication/260658411_Crowdsourcing_Facial_Responses_to_Online_Videos"},{"id":261115617,"url":"https://www.researchgate.net/publication/261115617_Transfer_learning_to_account_for_idiosyncrasy_in_face_and_body_expressions"},{"id":261484972,"url":"https://www.researchgate.net/publication/261484972_Distribution-sensitive_learning_for_imbalanced_datasets"},{"id":261468526,"url":"https://www.researchgate.net/publication/261468526_Affectiva-MIT_Facial_Expression_Dataset_AM-FED_Naturalistic_and_Spontaneous_Facial_Expressions_Collected_In-the-Wild"},{"id":261319546,"url":"https://www.researchgate.net/publication/261319546_A_unified_probabilistic_framework_for_measuring_the_intensity_of_spontaneous_facial_action_units"},{"id":260353896,"url":"https://www.researchgate.net/publication/260353896_Infinite_Hidden_Conditional_Random_Fields_for_Human_Behavior_Analysis"},{"id":262215758,"url":"https://www.researchgate.net/publication/262215758_Recognizing_expressions_from_face_and_body_gesture_by_temporal_normalized_motion_and_appearance_features"},{"id":257093268,"url":"https://www.researchgate.net/publication/257093268_Categorical_and_dimensional_affect_analysis_in_continuous_input_Current_trends_and_future_directions"},{"id":261319549,"url":"https://www.researchgate.net/publication/261319549_Weakly_supervised_pain_localization_using_multiple_instance_learning"},{"id":237148056,"url":"https://www.researchgate.net/publication/237148056_A_Dynamic_Appearance_Descriptor_Approach_to_Facial_Actions_Temporal_Modeling"},{"id":259495667,"url":"https://www.researchgate.net/publication/259495667_A_High-Resolution_Spontaneous_3D_Dynamic_Facial_Expression_Database"},{"id":257692298,"url":"https://www.researchgate.net/publication/257692298_Assessment_of_the_communicative_and_coordination_skills_of_children_with_Autism_Spectrum_Disorders_and_typically_developing_children_using_social_signal_processing"},{"id":259990719,"url":"https://www.researchgate.net/publication/259990719_The_BioVid_Heat_Pain_Database_Data_for_the_Advancement_and_Systematic_Validation_of_an_Automated_Pain_Recognition_System"},{"id":261194617,"url":"https://www.researchgate.net/publication/261194617_Pain_detection_through_shape_and_appearance_features"},{"id":258082273,"url":"https://www.researchgate.net/publication/258082273_Learning_Tensors_in_Reproducing_Kernel_Hilbert_Spaces_with_Multilinear_Spectral_Penalties"},{"id":271456386,"url":"https://www.researchgate.net/publication/271456386_Predicting_movie_ratings_from_audience_behaviors"},{"id":271545529,"url":"https://www.researchgate.net/publication/271545529_Social_signal_processing_for_pain_monitoring_using_a_hidden_conditional_random_field"},{"id":260519620,"url":"https://www.researchgate.net/publication/260519620_Classification_and_Weakly_Supervised_Pain_Localization_using_Multiple_Segment_Representation"},{"id":283023938,"url":"https://www.researchgate.net/publication/283023938_Performing_facial_expression_synthesis_on_robot_faces_A_real-time_software_system"},{"id":272741013,"url":"https://www.researchgate.net/publication/272741013_EEVEE_the_Empathy-Enhancing_Virtual_Evolving_Environment"},{"id":274094896,"url":"https://www.researchgate.net/publication/274094896_Pain_Intensity_Estimation_by_a_Self--Taught_Selection_of_Histograms_of_Topographical_Features"},{"id":274721882,"url":"https://www.researchgate.net/publication/274721882_Intensity_Estimation_of_Spontaneous_Facial_Action_Units_Based_on_Their_Sparsity_Properties"},{"id":275355521,"url":"https://www.researchgate.net/publication/275355521_Time-Delay_Neural_Network_for_Continuous_Emotional_Dimension_Prediction_From_Facial_Expression_Sequences"},{"id":274461344,"url":"https://www.researchgate.net/publication/274461344_Context-Sensitive_Dynamic_Ordinal_Regression_for_Intensity_Estimation_of_Facial_Action_Units"},{"id":277311895,"url":"https://www.researchgate.net/publication/277311895_Using_Hankel_Matrices_for_Dynamics-based_Facial_Emotion_Recognition_and_Pain_Detection"},{"id":280098467,"url":"https://www.researchgate.net/publication/280098467_Learning_Appearance_Features_for_Pain_Detection_Using_the_UNBC-McMaster_Shoulder_Pain_Expression_Archive_Database"},{"id":273488773,"url":"https://www.researchgate.net/publication/273488773_Variational_Infinite_Hidden_Conditional_Random_Fields"},{"id":283854672,"url":"https://www.researchgate.net/publication/283854672_3D_Dynamic_Facial_Sequences_Analysis_for_Face_Recognition_and_Emotion_Detection"}],"reference":["https://www.researchgate.net/publication/49628576_Automatically_Detecting_Pain_in_Video_Through_Facial_Action_Units","https://www.researchgate.net/publication/21663578_The_Consistency_of_Facial_Expressions_of_Pain_A_Comparison_Across_Modalities","https://www.researchgate.net/publication/223065452_A_validation_model_for_verbal_descriptor_scaling_of_human_clinical_pain","https://www.researchgate.net/publication/221259802_Comparing_Active_Shape_Models_with_Active_Appearance_Models","https://www.researchgate.net/publication/200085999_A_Practical_Guide_to_Support_Vector_Classication","https://www.researchgate.net/publication/230574153_The_Painful_Face_-_Pain_Expression_Recognition_Using_Active_Appearance_Models","https://www.researchgate.net/publication/3193633_The_CMU_Pose_Illumination_and_Expression_Database","https://www.researchgate.net/publication/225940935_Facial_Expression_Analysis","https://www.researchgate.net/publication/49796150_Automatically_Detecting_Pain_Using_Facial_Actions","https://www.researchgate.net/publication/215992302_Confidence_Intervals_for_the_Area_under_the_ROC_Curve","https://www.researchgate.net/publication/243773603_Measuring_facial_movement_with_the_facial_action_coding_system","https://www.researchgate.net/publication/228715647_LIBSVM_A_library_for_support_vector_machines","https://www.researchgate.net/publication/4194011_Layered_active_appearance_models","https://www.researchgate.net/publication/246700567_The_Checklist_Manifesto-How_to_Get_Things_Right","https://www.researchgate.net/publication/6139644_Facial_Action_Unit_Recognition_by_Exploiting_Their_Dynamic_and_Semantic_Relationships","https://www.researchgate.net/publication/5348301_The_structure_reliability_and_validity_of_pain_expression_Evidence_from_patients_with_shoulder_pain","https://www.researchgate.net/publication/224401018_A_high-resolution_3D_dynamic_facial_expression_database","https://www.researchgate.net/publication/221052632_The_painful_face_-_Pain_expression_recognition_using_active_appearance_models","https://www.researchgate.net/publication/26820517_Toward_Practical_Smile_Detection","https://www.researchgate.net/publication/221786192_Investigating_Spontaneous_Facial_Action_Recognition_through_AAM_Representations_of_the_Face","https://www.researchgate.net/publication/3948108_The_CMU_Pose_Illumination_and_Expression_PIE_database","https://www.researchgate.net/publication/42803851_Automatic_Recognition_of_Facial_Actions_in_Spontaneous_Expressions","https://www.researchgate.net/publication/2900541_Active_appearance_models_revisited_IJCV_602_135-164","https://www.researchgate.net/publication/3193260_Active_Appearance_Models","https://www.researchgate.net/publication/23493444_A_Survey_of_Affect_Recognition_Methods_Audio_Visual_and_Spontaneous_Expressions","https://www.researchgate.net/publication/4082379_Real-time_combined_2D3D_active_appearance_models","https://www.researchgate.net/publication/233894838_In_Statistical_Power_Analysis_for_the_Behavior_Sciences_Revised_Edition","https://www.researchgate.net/publication/20540394_Pain_expression_in_patients_with_shoulder_pathology_Validity_properties_and_relationship_to_sickness_impact"]}