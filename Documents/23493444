{"id":23493444,"title":"A Survey of Affect Recognition Methods: Audio, Visual, and Spontaneous Expressions","authors":["Zhihong Zeng","Maja Pantic","Glenn I Roisman","Thomas S Huang"],"_abstract":"ABSTRACT Automated analysis of human affective behavior has attracted increasing attention from researchers in psychology, computer science, linguistics, neuroscience, and related disciplines. However, the existing methods typically handle only deliberately displayed and exaggerated expressions of prototypical emotions despite the fact that deliberate behaviour differs in visual appearance, audio profile, and timing from spontaneously occurring behaviour. To address this problem, efforts to develop algorithms that can process naturally occurring human affective behaviour have recently emerged. Moreover, an increasing number of efforts are reported toward multimodal fusion for human affect analysis including audiovisual fusion, linguistic and paralinguistic fusion, and multi-cue visual fusion based on facial expressions, head movements, and body gestures. This paper introduces and surveys these recent advances. We first discuss human emotion perception from a psychological perspective. Next we examine available approaches to solving the problem of machine understanding of human affective behavior, and discuss important issues like the collection and availability of training and test data. We finally outline some of the scientific and engineering challenges to advancing human affect sensing technology.","cited_in":[{"id":290786839,"url":"https://www.researchgate.net/publication/290786839_Wavelet-threshold_based_Bit_Intensity_Measurement_On_Facial_Expression_Recognition"},{"id":282847424,"url":"https://www.researchgate.net/publication/282847424_FaceCept3D_Real_Time_3D_Face_Tracking_and_Analysis"},{"id":283698316,"url":"https://www.researchgate.net/publication/283698316_The_Indian_Spontaneous_Expression_Database_for_Emotion_Recognition"},{"id":281829158,"url":"https://www.researchgate.net/publication/281829158_Transductive_Transfer_LDA_with_Riesz-based_Volume_LBP_for_Emotion_Recognition_in_The_Wild"},{"id":283441400,"url":"https://www.researchgate.net/publication/283441400_Reading_Hidden_Emotions_Spontaneous_Micro-expression_Spotting_and_Recognition"},{"id":283315956,"url":"https://www.researchgate.net/publication/283315956_ICMI2015_SEU"},{"id":284492404,"url":"https://www.researchgate.net/publication/284492404_Recognising_Emotional_Evolution_from_Speech"},{"id":282294560,"url":"https://www.researchgate.net/publication/282294560_Multi-modal_Emotion_Analysis_from_Facial_Expressions_and_Electroencephalogram"},{"id":282964996,"url":"https://www.researchgate.net/publication/282964996_Lightweight_Adaptation_of_Classifiers_to_Users_and_Contexts_Trends_of_the_Emerging_Domain"},{"id":286938148,"url":"https://www.researchgate.net/publication/286938148_Analysis_of_Excitation_Source_Features_of_Speech_for_Emotion_Recognition"},{"id":283624647,"url":"https://www.researchgate.net/publication/283624647_Measuring_mimicry_in_task-oriented_conversations_degree_of_mimicry_is_related_to_task_difficulty"},{"id":283295509,"url":"https://www.researchgate.net/publication/283295509_Discrimination_Between_Native_and_Non-Native_Speech_Using_Visual_Features_Only"},{"id":282251791,"url":"https://www.researchgate.net/publication/282251791_Comparison_of_Single-model_and_Multiple-model_Prediction-based_Audiovisual_Fusion"},{"id":277312235,"url":"https://www.researchgate.net/publication/277312235_Ensemble_of_Hankel_Matrices_for_Face_Emotion_Recognition"},{"id":282478275,"url":"https://www.researchgate.net/publication/282478275_The_automatic_detection_of_chronic_pain-related_expression_requirements_challenges_and_a_multimodal_dataset"},{"id":278783929,"url":"https://www.researchgate.net/publication/278783929_Using_the_Startle_Eye-Blink_to_Measure_Affect_in_Players"},{"id":281241468,"url":"https://www.researchgate.net/publication/281241468_Prediction-based_Audiovisual_Fusion_for_Classification_of_Non-Linguistic_Vocalisations"},{"id":277942841,"url":"https://www.researchgate.net/publication/277942841_Beyond_usability_designing_for_consumers'_product_experience_using_the_Rasch_model"},{"id":278763516,"url":"https://www.researchgate.net/publication/278763516_Facial_Action_Units_Intensity_Estimation_by_the_Fusion_of_Features_with_Multi-kernel_Support_Vector_Machine"},{"id":279955502,"url":"https://www.researchgate.net/publication/279955502_A_Survey_on_Mouth_Modeling_and_Analysis_for_Sign_Language_Recognition"},{"id":277076533,"url":"https://www.researchgate.net/publication/277076533_FERA_2015_-_Second_Facial_Expression_Recognition_and_Analysis_Challenge"},{"id":277668057,"url":"https://www.researchgate.net/publication/277668057_Towards_Real-Life_Facial_Expression_Recognition_Systems"},{"id":276133356,"url":"https://www.researchgate.net/publication/276133356_Connecting_Brains_and_Bodies_Applying_Physiological_Computing_to_Support_Social_Interaction"},{"id":275367484,"url":"https://www.researchgate.net/publication/275367484_The_MAHNOB_Mimicry_Database_A_database_of_naturalistic_human_interactions"},{"id":282912550,"url":"https://www.researchgate.net/publication/282912550_Magic_mirror_in_my_hand_what_is_the_sentiment_in_the_lens_An_action_unit_based_approach_for_mining_sentiments_from_multimedia_contents"},{"id":281276339,"url":"https://www.researchgate.net/publication/281276339_The_More_the_Merrier_Analysing_the_Affect_of_a_Group_of_People_in_Images"},{"id":273481171,"url":"https://www.researchgate.net/publication/273481171_Recognition_of_Genuine_Smiles"},{"id":271503454,"url":"https://www.researchgate.net/publication/271503454_12"},{"id":271503292,"url":"https://www.researchgate.net/publication/271503292_11"},{"id":281893549,"url":"https://www.researchgate.net/publication/281893549_Mining_Cursor_Motions_to_Find_the_Gender_Experience_and_Feelings_of_Computer_Users"},{"id":281004592,"url":"https://www.researchgate.net/publication/281004592_Influence_of_verbal_content_on_acoustics_of_speech_emotions"},{"id":280877014,"url":"https://www.researchgate.net/publication/280877014_Human_Capacities_for_Emotion_Recognition_and_their_Implications_for_Computer_Vision"},{"id":275208397,"url":"https://www.researchgate.net/publication/275208397_Speaker-Independent_Speech_Emotion_Recognition_using_Gaussian_and_SVM_Classifiers"},{"id":281507978,"url":"https://www.researchgate.net/publication/281507978_Differential_Evolution_to_Optimize_Hidden_Markov_Models_Training_Application_to_Facial_Expression_Recognition"},{"id":282174112,"url":"https://www.researchgate.net/publication/282174112_Say_Cheese_vs_Smile_Reducing_speech-related_variability_for_facial_emotion_recognition"},{"id":266084125,"url":"https://www.researchgate.net/publication/266084125_Improved_Spatiotemporal_Local_Monogenic_Binary_Pattern_for_Emotion_Recognition_in_The_Wild"},{"id":266852822,"url":"https://www.researchgate.net/publication/266852822_Spontaneous_facial_expression_in_unscripted_social_interactions_can_be_measured_automatically"},{"id":267502070,"url":"https://www.researchgate.net/publication/267502070_Automatic_Analysis_of_Facial_Affect_A_Survey_of_Registration_Representation_and_Recognition"},{"id":268503755,"url":"https://www.researchgate.net/publication/268503755_Affective_facial_expression_processing_via_simulation_A_probabilistic_model"},{"id":264295959,"url":"https://www.researchgate.net/publication/264295959_An_automatic_facial_expression_recognition_system_evaluated_with_different_classifiers"},{"id":262491324,"url":"https://www.researchgate.net/publication/262491324_Multi-task_and_multi-view_learning_of_user_state"},{"id":262806356,"url":"https://www.researchgate.net/publication/262806356_Gaussian_mixture_model_based_estimation_of_the_neutral_face_shape_for_emotion_recognition"},{"id":259512434,"url":"https://www.researchgate.net/publication/259512434_Nonverbal_Social_Withdrawal_in_Depression_Evidence_from_manual_and_automatic_analyses"},{"id":281235386,"url":"https://www.researchgate.net/publication/281235386_Robust_Facial_Expression_Recognition_Using_Revised_Canonical_Correlation"},{"id":263319583,"url":"https://www.researchgate.net/publication/263319583_Dynamic_Probabilistic_CCA_for_Analysis_of_Affective_Behavior_and_Fusion_of_Continuous_Annotations"},{"id":263354466,"url":"https://www.researchgate.net/publication/263354466_Structure-Preserving_Sparse_Decomposition_for_Facial_Expression_Analysis"},{"id":263050976,"url":"https://www.researchgate.net/publication/263050976_Attentional_Mechanisms_for_Socially_Interactive_Robots-A_Survey"},{"id":264348304,"url":"https://www.researchgate.net/publication/264348304_BP4D-Spontaneous_A_high-resolution_spontaneous_3D_dynamic_facial_expression_database"},{"id":259093285,"url":"https://www.researchgate.net/publication/259093285_Facial_expression_recognition_in_dynamic_sequences_An_integrated_approach"},{"id":259132266,"url":"https://www.researchgate.net/publication/259132266_Understanding_of_computers_and_procrastination_A_philosophical_approach"},{"id":258642621,"url":"https://www.researchgate.net/publication/258642621_How_affective_technologies_can_influence_intimate_interactions_and_improve_social_connectedness"},{"id":261286311,"url":"https://www.researchgate.net/publication/261286311_Evaluation_of_Vision-based_Real-Time_Measures_for_Emotions_Discrimination_under_Uncontrolled_Conditions"},{"id":262326450,"url":"https://www.researchgate.net/publication/262326450_Learning_a_sparse_codebook_of_facial_and_body_microexpressions_for_emotion_recognition"},{"id":292127412,"url":"https://www.researchgate.net/publication/292127412_Issues_and_Dependencies_on_Affect_Data_Models_For_Assessment_of_Disorders-A_Survey"},{"id":262424980,"url":"https://www.researchgate.net/publication/262424980_Valence_arousal_and_dominance_in_the_EEG_during_game_play"},{"id":262348648,"url":"https://www.researchgate.net/publication/262348648_In_situ_affect_detection_in_mobile_devices_a_multimodal_approach_for_advertisement_using_social_network"},{"id":253261535,"url":"https://www.researchgate.net/publication/253261535_A_Real_Time_and_Robust_Facial_Expression_Recognition_and_Imitation_approach_for_Affective_Human-Robot_Interaction_Using_Gabor_filtering"},{"id":258695281,"url":"https://www.researchgate.net/publication/258695281_Machines_Outperform_Laypersons_in_Recognizing_Emotions_Elicited_by_Autobiographical_Recollection"},{"id":254257602,"url":"https://www.researchgate.net/publication/254257602_Learning_person-specific_models_for_facial_expression_and_action_unit_recognition"},{"id":266654355,"url":"https://www.researchgate.net/publication/266654355_Correlated-spaces_regression_for_learning_continuous_emotion_dimensions"},{"id":260945512,"url":"https://www.researchgate.net/publication/260945512_Nonlinear_Appraisal_Modeling_An_Application_of_Machine_Learning_to_the_Study_of_Emotion_Production"},{"id":259105619,"url":"https://www.researchgate.net/publication/259105619_Towards_In_Situ_Affect_Detection_in_Mobile_Devices_A_Multimodal_Approach"},{"id":262233880,"url":"https://www.researchgate.net/publication/262233880_Towards_in_situ_affect_detection_in_mobile_devices_A_multimodal_approach"},{"id":256822547,"url":"https://www.researchgate.net/publication/256822547_Eye_localization_from_thermal_infrared_images"},{"id":260349596,"url":"https://www.researchgate.net/publication/260349596_Quantitative_Study_of_Music_Listening_Behavior_in_a_Social_and_Affective_Context"},{"id":260712629,"url":"https://www.researchgate.net/publication/260712629_A_Theory-Driven_Approach_to_Predict_Frustration_in_an_ITS"},{"id":280446313,"url":"https://www.researchgate.net/publication/280446313_A_Novel_Real_Time_Facial_Expression_Recognition_system_based_on_Candide-3_Reconstruction_Model"},{"id":259990721,"url":"https://www.researchgate.net/publication/259990721_Towards_Pain_Monitoring_Facial_Expression_Head_Pose_a_new_Database_an_Automatic_System_and_Remaining_Challenges"},{"id":259972003,"url":"https://www.researchgate.net/publication/259972003_Facing_Imbalanced_Data_-_Recommendations_for_the_Use_of_Performance_Metrics"},{"id":261271660,"url":"https://www.researchgate.net/publication/261271660_Measuring_Affect_for_the_Study_and_Enhancement_of_Co-Present_Creative_Collaboration"},{"id":261206959,"url":"https://www.researchgate.net/publication/261206959_Local_Gabor_Binary_Patterns_from_Three_Orthogonal_Planes_for_Automatic_Facial_Expression_Recognition"},{"id":265284566,"url":"https://www.researchgate.net/publication/265284566_Local_Zernike_Moment_Representation_for_Facial_Affect_Recognition"},{"id":271940739,"url":"https://www.researchgate.net/publication/271940739_Emerging_application_areas_and_challenges_of_automatic_face_analysis"},{"id":236585499,"url":"https://www.researchgate.net/publication/236585499_MoodScope_Building_a_Mood_Sensor_from_Smartphone_Usage_Patterns"},{"id":261167793,"url":"https://www.researchgate.net/publication/261167793_A_dynamic_geometry-based_approach_for_4D_facial_expressions_recognition"},{"id":260564474,"url":"https://www.researchgate.net/publication/260564474_Cardiff_Conversation_Database_CCDb_A_Database_of_Natural_Dyadic_Conversations"},{"id":261480222,"url":"https://www.researchgate.net/publication/261480222_Emotion_recognition_and_its_application_in_software_engineering"},{"id":259932018,"url":"https://www.researchgate.net/publication/259932018_A_Comparative_Study_of_Different_Classifiers_for_Detecting_Depression_from_Spontaneous_Speech"},{"id":259495667,"url":"https://www.researchgate.net/publication/259495667_A_High-Resolution_Spontaneous_3D_Dynamic_Facial_Expression_Database"},{"id":237148056,"url":"https://www.researchgate.net/publication/237148056_A_Dynamic_Appearance_Descriptor_Approach_to_Facial_Actions_Temporal_Modeling"},{"id":248703363,"url":"https://www.researchgate.net/publication/248703363_DISFA_A_spontaneous_facial_action_intensity_database"},{"id":257091792,"url":"https://www.researchgate.net/publication/257091792_Hierarchical_On-line_Appearance-Based_Tracking_for_3D_head_pose_eyebrows_lips_eyelids_and_irises"},{"id":261115385,"url":"https://www.researchgate.net/publication/261115385_Dimensional_affect_recognition_using_Continuous_Conditional_Random_Fields"},{"id":255710742,"url":"https://www.researchgate.net/publication/255710742_A_unified_probabilistic_framework_for_automatic_3D_facial_expression_analysis_based_on_a_Bayesian_belief_inference_and_statistical_feature_models"},{"id":260349300,"url":"https://www.researchgate.net/publication/260349300_Affective_Labeling_in_a_Content-Based_Recommender_System_for_Images"},{"id":257093268,"url":"https://www.researchgate.net/publication/257093268_Categorical_and_dimensional_affect_analysis_in_continuous_input_Current_trends_and_future_directions"},{"id":257392756,"url":"https://www.researchgate.net/publication/257392756_Facial_expression_recognition_using_tracked_facial_actions_Classifier_performance_analysis"},{"id":235887169,"url":"https://www.researchgate.net/publication/235887169_Imitation_system_for_humanoid_robotics_heads"},{"id":259065800,"url":"https://www.researchgate.net/publication/259065800_Modeling_phonetic_pattern_variability_in_favor_of_the_creation_of_robust_emotion_classifiers_for_real-life_applications"},{"id":260658386,"url":"https://www.researchgate.net/publication/260658386_Analyses_of_a_Multimodal_Spontaneous_Facial_Expression_Database"},{"id":260658387,"url":"https://www.researchgate.net/publication/260658387_Classifier-Based_Learning_of_Nonlinear_Feature_Manifold_for_Visualization_of_Emotional_Speech_Prosody"},{"id":261265035,"url":"https://www.researchgate.net/publication/261265035_Bayesian_Inference_Based_Temporal_Modeling_for_Naturalistic_Affective_Expression_Classification"},{"id":261391604,"url":"https://www.researchgate.net/publication/261391604_Facial_communicative_signal_interpretation_in_human-robot_interaction_by_discriminative_video_subsequence_selection"},{"id":258807129,"url":"https://www.researchgate.net/publication/258807129_Towards_a_dynamic_expression_recognition_system_under_facial_occlusion"},{"id":266653224,"url":"https://www.researchgate.net/publication/266653224_Comparison_of_prediction-based_fusion_and_feature-level_fusion_across_different_learning_models"},{"id":232739301,"url":"https://www.researchgate.net/publication/232739301_Coupled_Gaussian_Processes_for_Pose-Invariant_Facial_Expression_Recognition"},{"id":262401925,"url":"https://www.researchgate.net/publication/262401925_Combining_Video_Audio_and_Lexical_Indicators_of_Affect_in_Spontaneous_Conversation_via_Particle_Filtering"},{"id":257392405,"url":"https://www.researchgate.net/publication/257392405_State_of_the_art_of_smart_homes"},{"id":264122181,"url":"https://www.researchgate.net/publication/264122181_Classification_of_Affects_Using_Head_Movement_Skin_Color_Features_and_Physiological_Signals"},{"id":257093260,"url":"https://www.researchgate.net/publication/257093260_Static_and_dynamic_3D_facial_expression_recognition_A_comprehensive_survey"},{"id":260355522,"url":"https://www.researchgate.net/publication/260355522_Language_and_Discourse_Are_Powerful_Signals_of_Student_Emotions_during_Tutoring"},{"id":257571910,"url":"https://www.researchgate.net/publication/257571910_Synthesized_speech_for_model_training_in_cross-corpus_recognition_of_human_emotion"},{"id":234112828,"url":"https://www.researchgate.net/publication/234112828_Towards_the_automatic_detection_of_spontaneous_agreement_and_disagreement_based_on_nonverbal_behavior_A_survey_of_related_cues_databases_and_tools"},{"id":225157625,"url":"https://www.researchgate.net/publication/225157625_Tune_in_to_your_emotions_A_robust_personalized_affective_music_player"},{"id":261154751,"url":"https://www.researchgate.net/publication/261154751_Multi-output_Laplacian_dynamic_ordinal_regression_for_facial_expression_recognition_and_intensity_estimation"},{"id":228071481,"url":"https://www.researchgate.net/publication/228071481_Meta-Analysis_of_the_First_Facial_Expression_Recognition_Challenge"},{"id":228513346,"url":"https://www.researchgate.net/publication/228513346_Speaker-independent_emotion_recognition_exploiting_a_psychologically-inspired_binary_cascade_classification_schema"},{"id":261280145,"url":"https://www.researchgate.net/publication/261280145_Comparison_between_decision-level_and_feature-level_fusion_of_acoustic_and_linguistic_features_for_spontaneous_emotion_recognition"},{"id":242070946,"url":"https://www.researchgate.net/publication/242070946_3D_Constrained_Local_Model_for_rigid_and_non-rigid_facial_tracking"},{"id":235899018,"url":"https://www.researchgate.net/publication/235899018_Applying_multiple_classifiers_and_non-linear_dynamics_features_for_detecting_sleepiness_from_speech"},{"id":229033753,"url":"https://www.researchgate.net/publication/229033753_Expressive_Copying_Behavior_for_Social_Agents_A_Perceptual_Analysis"},{"id":257393064,"url":"https://www.researchgate.net/publication/257393064_A_survey_of_methods_for_data_fusion_and_system_adaptation_using_autonomic_nervous_system_responses_in_physiological_computing"},{"id":261303023,"url":"https://www.researchgate.net/publication/261303023_A_hybrid_facial_expression_recognition_method_based_on_neutral_face_shape_estimation"},{"id":222091820,"url":"https://www.researchgate.net/publication/222091820_Face_Expression_Recognition_and_Analysis_The_State_of_the_Art"},{"id":224861740,"url":"https://www.researchgate.net/publication/224861740_Intraindividual_and_interindividual_multimodal_emotion_analyses_in_human-machine-interaction"},{"id":224258566,"url":"https://www.researchgate.net/publication/224258566_Fully_Automatic_Recognition_of_the_Temporal_Phases_of_Facial_Actions"},{"id":259972200,"url":"https://www.researchgate.net/publication/259972200_Robust_Facial_Expression_Recognition_Using_Near_Infrared_Cameras"},{"id":236879509,"url":"https://www.researchgate.net/publication/236879509_Feedback_in_Adaptive_Interactive_Storytelling"},{"id":235887168,"url":"https://www.researchgate.net/publication/235887168_Development_of_a_Facial_Expression_Recognition_and_Imitation_Method_for_Affective_HRI"},{"id":261387182,"url":"https://www.researchgate.net/publication/261387182_Person-specific_expression_recognition_with_transfer_learning"},{"id":261309603,"url":"https://www.researchgate.net/publication/261309603_How_Many_Frames_Does_Facial_Expression_Recognition_Require"},{"id":265797240,"url":"https://www.researchgate.net/publication/265797240_Personality_traits_detection_using_a_parallelized_modified_SFFS_algorithm"},{"id":264855441,"url":"https://www.researchgate.net/publication/264855441_Enhancing_Automatic_Detection_of_Frustration_Induced_During_HCI_with_Moment-based_Biosignal_Features"},{"id":258995867,"url":"https://www.researchgate.net/publication/258995867_Facial_Expression_Recognition_Using_Temporal_Templates"},{"id":252067954,"url":"https://www.researchgate.net/publication/252067954_Analyzing_Posture_and_Affect_in_Task-Oriented_Tutoring"},{"id":256309258,"url":"https://www.researchgate.net/publication/256309258_Detecting_Depression_Severity_from_Vocal_Prosody"},{"id":232906565,"url":"https://www.researchgate.net/publication/232906565_Affective_labeling_in_a_content-based_recommender_system_for_images"},{"id":232651717,"url":"https://www.researchgate.net/publication/232651717_DEAP_A_Database_for_Emotion_Analysis_Using_Physiological_Signals"},{"id":221292530,"url":"https://www.researchgate.net/publication/221292530_Acume_A_New_Visualization_Tool_for_Understanding_Facial_Expression_and_Gesture_Data"},{"id":252026943,"url":"https://www.researchgate.net/publication/252026943_Frontal_Facial_Pose_Recognition_Using_a_Discriminant_Splitting_Feature_Extraction_Procedure"},{"id":221209808,"url":"https://www.researchgate.net/publication/221209808_Evaluation_of_Texture_and_Geometry_for_Dimensional_Facial_Expression_Recognition"},{"id":224266277,"url":"https://www.researchgate.net/publication/224266277_Converting_emotional_voice_to_motion_for_robot_telepresence"},{"id":51840757,"url":"https://www.researchgate.net/publication/51840757_Neuro-Fuzzy_Quantification_of_Personal_Perceptions_of_Facial_Images_Based_on_a_Limited_Data_Set"},{"id":222650661,"url":"https://www.researchgate.net/publication/222650661_Recognising_realistic_emotions_and_affect_in_speech_State_of_the_art_and_lessons_learnt_from_the_first_challenge"},{"id":254017909,"url":"https://www.researchgate.net/publication/254017909_A_Learning_Social_Network_with_Multi-modal_Affect"},{"id":221429947,"url":"https://www.researchgate.net/publication/221429947_Static_facial_expression_analysis_in_tough_conditions_Data_evaluation_protocol_and_benchmark"},{"id":221111102,"url":"https://www.researchgate.net/publication/221111102_Recognising_spontaneous_facial_micro-expressions"},{"id":220121059,"url":"https://www.researchgate.net/publication/220121059_Formant_position_based_weighted_spectral_features_for_emotion_recognition"},{"id":224256277,"url":"https://www.researchgate.net/publication/224256277_A_study_of_human_performance_in_recognizing_expressive_hand_movements"},{"id":224262180,"url":"https://www.researchgate.net/publication/224262180_Building_Autonomous_Sensitive_Artificial_Listeners"},{"id":224257559,"url":"https://www.researchgate.net/publication/224257559_Toward_a_more_robust_facial_expression_recognition_in_occluded_images_using_randomly_sampled_Gabor_based_templates"},{"id":220611907,"url":"https://www.researchgate.net/publication/220611907_Facial_expression_recognition_from_near-infrared_videos"},{"id":224177560,"url":"https://www.researchgate.net/publication/224177560_A_Framework_for_Automatic_Human_Emotion_Classification_Using_Emotion_Profiles"},{"id":224251543,"url":"https://www.researchgate.net/publication/224251543_Spontaneous_children's_emotion_recognition_by_categorical_classification_of_acoustic_features"},{"id":51501156,"url":"https://www.researchgate.net/publication/51501156_Smile_detection_by_boosting_pixel_differences"},{"id":224226954,"url":"https://www.researchgate.net/publication/224226954_Continuous_Prediction_of_Spontaneous_Affect_from_Multiple_Cues_and_Modalities_in_Valence-Arousal_Space"},{"id":224246423,"url":"https://www.researchgate.net/publication/224246423_Sentence_level_emotion_recognition_based_on_decisions_from_subsentence_segments"},{"id":224242925,"url":"https://www.researchgate.net/publication/224242925_EEG-based_emotion_recognition_during_watching_movies"},{"id":224929577,"url":"https://www.researchgate.net/publication/224929577_Affective_Speaker_State_Analysis_in_the_Presence_of_Reverberation"},{"id":224247397,"url":"https://www.researchgate.net/publication/224247397_Extracting_coherent_emotion_elicited_segments_from_physiological_signals"},{"id":228652848,"url":"https://www.researchgate.net/publication/228652848_Affective-centered_design_for_interactive_robots"},{"id":44958249,"url":"https://www.researchgate.net/publication/44958249_Multimodal_Recognition_of_Social_Behaviors_and_Personality_Traits_in_Small_Group_Interaction"},{"id":225155130,"url":"https://www.researchgate.net/publication/225155130_Affect_recognition_for_interactive_companions_Challenges_and_design_in_real_world_scenarios"},{"id":227296392,"url":"https://www.researchgate.net/publication/227296392_Multimodal_Emotion_Recognition_in_Speech-based_Interaction_Using_Facial_Expression_Body_Gesture_and_Acoustic_Analysis"},{"id":228891935,"url":"https://www.researchgate.net/publication/228891935_String-based_Audiovisual_Fusion_of_Behavioural_Events_for_the_Assessment_of_Dimensional_Affect"},{"id":234794085,"url":"https://www.researchgate.net/publication/234794085_Reconnaissance_d'Emotions_un_point_de_vue_interaction_multimodale"},{"id":228421431,"url":"https://www.researchgate.net/publication/228421431_Affective_Educational_Technology_First_steps_on_the_introduction_of_the_affective_dimension_in_the_core_of_online_design"},{"id":251764330,"url":"https://www.researchgate.net/publication/251764330_Long-term_affect_sensitive_and_socially_interactive_companions"},{"id":247927679,"url":"https://www.researchgate.net/publication/247927679_Analyse_des_interactions_en_utilisant_le_suivi_oculaire_le_suivi_physiologique_et_les_structures_d'actions"},{"id":228970738,"url":"https://www.researchgate.net/publication/228970738_Affect_recognition_for_interactive_companions"},{"id":241875427,"url":"https://www.researchgate.net/publication/241875427_Toward_affective_dialogue_management_using_partially_observable_Markov_decision_processes"},{"id":237328233,"url":"https://www.researchgate.net/publication/237328233_Encyclopedia_of_Multimedia_Technology_and_Networking"},{"id":47760425,"url":"https://www.researchgate.net/publication/47760425_eMotion_un_outil_pour_personnaliser_la_reconnaissance_d'emotions"},{"id":237607629,"url":"https://www.researchgate.net/publication/237607629_Analysis_of_Facial_Feature_Movements"},{"id":228376974,"url":"https://www.researchgate.net/publication/228376974_3D_Vision_Technology_for_Capturing_Multimodal_Corpora_Chances_and_Challenges"},{"id":257773836,"url":"https://www.researchgate.net/publication/257773836_A_three-component_framework_for_empathic_technologies_to_augment_human_interaction"},{"id":257792672,"url":"https://www.researchgate.net/publication/257792672_Human_emotion_and_cognition_recognition_from_body_language_of_the_head_using_soft_computing_techniques"},{"id":257471989,"url":"https://www.researchgate.net/publication/257471989_Facial_expression_recognition_based_on_meta_probability_codes"},{"id":257884643,"url":"https://www.researchgate.net/publication/257884643_Detecting_interpreting_self-manipulating_hand_movements_for_student's_affect_prediction"},{"id":257513015,"url":"https://www.researchgate.net/publication/257513015_An_insight_into_multimodal_databases_for_social_signal_processing_acquisition_efforts_and_directions"},{"id":257627528,"url":"https://www.researchgate.net/publication/257627528_Utilizing_3D_flow_of_points_for_facial_expression_recognition"},{"id":257879661,"url":"https://www.researchgate.net/publication/257879661_Multimedia_content_analysis_for_emotional_characterization_of_music_video_clips"},{"id":257627227,"url":"https://www.researchgate.net/publication/257627227_Affective_social_network_-_Happiness_inducing_social_media_platform"},{"id":257780511,"url":"https://www.researchgate.net/publication/257780511_Teleoperated_Android_Robot_as_Emotion_Regulation_Media"},{"id":257879674,"url":"https://www.researchgate.net/publication/257879674_Automatic_landmark_point_detection_and_tracking_for_human_facial_expressions"},{"id":257797886,"url":"https://www.researchgate.net/publication/257797886_A_model_for_inference_of_emotional_state_based_on_facial_expressions"},{"id":257879539,"url":"https://www.researchgate.net/publication/257879539_Towards_expressive_musical_robots_A_cross-modal_framework_for_emotional_gesture_voice_and_music"},{"id":257627743,"url":"https://www.researchgate.net/publication/257627743_HiMotion_a_new_research_resource_for_the_study_of_behavior_cognition_and_emotion"},{"id":267947183,"url":"https://www.researchgate.net/publication/267947183_Using_Physical_Objects_to_Capture_Childrens_Affective_States_in_User-centered_Evaluations"},{"id":228695729,"url":"https://www.researchgate.net/publication/228695729_Music_emotion_recognition_A_state_of_the_art_review"},{"id":228401907,"url":"https://www.researchgate.net/publication/228401907_Reconnaissance_de_la_semantique_emotionnelle_portee_par_les_images_basee_sur_la_theorie_de_l'evidence"},{"id":224929701,"url":"https://www.researchgate.net/publication/224929701_Towards_responsive_Sensitive_Artificial_Listeners"},{"id":266523495,"url":"https://www.researchgate.net/publication/266523495_Affective_recommender_systems_The_role_of_emotions_in_recommender_systems"},{"id":266415512,"url":"https://www.researchgate.net/publication/266415512_AUTOMATIC_RECOGNITION_OF_NON-_ACTED_AFFECTIVE_POSTURES_A_VIDEO_GAME_SCENARIO"},{"id":267255326,"url":"https://www.researchgate.net/publication/267255326_Communication_and_automatic_interpretation_of_affect_from_facial_expressions"},{"id":265047266,"url":"https://www.researchgate.net/publication/265047266_Creating_Human-centric_Expressive_Interfaces_Linking_Perceptual_evaluations_and_Engineering_Design_of_Synthetic_Multimodal_Communication"},{"id":3550060,"url":"https://www.researchgate.net/publication/3550060_Planar_doped_barrier_mixer_and_detector_diodes_as_alternatives_to_Schottky_diodes_for_both_microwave_and_millimetre_wave_applications"},{"id":251759896,"url":"https://www.researchgate.net/publication/251759896_Integrated_access_and_cross-connect_system_trail_results"},{"id":3712341,"url":"https://www.researchgate.net/publication/3712341_Acoustic_seabed_classification_and_correlation_analysis_of_sediment_properties_by_QTC_VIEW"},{"id":264817866,"url":"https://www.researchgate.net/publication/264817866_Options_for_transport_energy_conservation_in_Pakistan"},{"id":13477950,"url":"https://www.researchgate.net/publication/13477950_Formation_of_cytotoxins_by_enteric_Campylobacter_in_humans_and_animals"},{"id":3845464,"url":"https://www.researchgate.net/publication/3845464_Bimodal_emotion_recognition"},{"id":229137476,"url":"https://www.researchgate.net/publication/229137476_New_e'e_results"},{"id":251457821,"url":"https://www.researchgate.net/publication/251457821_Microcrystal_X-ray_diffraction_and_NMR_studies_of_thermal_expansion_properties_of_pure_silica_zeolites_FER_and_a_comparison_with_IFR"},{"id":41387083,"url":"https://www.researchgate.net/publication/41387083_Social_Signal_Processing_State-of-the-Art_and_Future_Perspectives_of_an_Emerging_Domain"},{"id":220847907,"url":"https://www.researchgate.net/publication/220847907_Spontaneous_Pain_Expression_Recognition_in_Video_Sequences"},{"id":221364565,"url":"https://www.researchgate.net/publication/221364565_Facial_Expression_Recognition_using_Encoded_Dynamic_Features"},{"id":221410739,"url":"https://www.researchgate.net/publication/221410739_A_Face-House_Paradigm_for_Architectural_Scene_Analysis"},{"id":221368673,"url":"https://www.researchgate.net/publication/221368673_Fusion_of_audio_and_visual_cues_for_laughter_detection"},{"id":221052199,"url":"https://www.researchgate.net/publication/221052199_Audiovisual_Laughter_Detection_Based_on_Temporal_Features"},{"id":221786977,"url":"https://www.researchgate.net/publication/221786977_From_the_Lab_to_the_Real_World_Affect_Recognition_Using_Multiple_Cues_and_Modalities"},{"id":221786971,"url":"https://www.researchgate.net/publication/221786971_A_Physiological_Approach_to_Affective_Computing"},{"id":3424754,"url":"https://www.researchgate.net/publication/3424754_Audio-Visual_Affective_Expression_Recognition_Through_Multistream_Fused_HMM"},{"id":262405793,"url":"https://www.researchgate.net/publication/262405793_Human-Centred_Intelligent_Human-Computer_Interaction_HCI2_How_far_are_we_from_attaining_it"},{"id":221292250,"url":"https://www.researchgate.net/publication/221292250_Recognizing_partial_facial_action_units_based_on_3D_dynamic_range_data_for_facial_expression_recognition"},{"id":280568578,"url":"https://www.researchgate.net/publication/280568578_Toward_affective_dialogue_management_using_partially_observable_Markov_decision_processes"},{"id":221304074,"url":"https://www.researchgate.net/publication/221304074_Similarity_Features_for_Facial_Event_Analysis"},{"id":224401018,"url":"https://www.researchgate.net/publication/224401018_A_high-resolution_3D_dynamic_facial_expression_database"},{"id":224401102,"url":"https://www.researchgate.net/publication/224401102_Meeting_Behavior_Detection_in_Smart_Environments_Nonverbal_Cues_that_Help_to_Obtain_Natural_Interaction"},{"id":224401115,"url":"https://www.researchgate.net/publication/224401115_Multi-view_facial_expression_recognition"},{"id":224401047,"url":"https://www.researchgate.net/publication/224401047_Pantic_M_Non-rigid_registration_using_free-form_deformations_for_recognition_of_facial_actions_and_their_temporal_dynamics_In_AFGR"},{"id":220517313,"url":"https://www.researchgate.net/publication/220517313_Discriminant_Graph_Structures_for_Facial_Expression_Recognition"},{"id":224370211,"url":"https://www.researchgate.net/publication/224370211_Mobile_education_Towards_affective_bi-modal_interaction_for_adaptivity"},{"id":226699568,"url":"https://www.researchgate.net/publication/226699568_Emotion_Recognition_Based_on_Multimodal_Information"},{"id":26596841,"url":"https://www.researchgate.net/publication/26596841_Mobile_Education_Towards_Affective_Bi-modal_Interaction_for_Adaptivity"},{"id":228950040,"url":"https://www.researchgate.net/publication/228950040_Do_Affect-Sensitive_Machines_Influence_User_Behavior"},{"id":221052546,"url":"https://www.researchgate.net/publication/221052546_Detecting_user_engagement_with_a_robot_companion_using_task_and_social_interaction-based_features"},{"id":224929671,"url":"https://www.researchgate.net/publication/224929671_The_Interspeech_2009_Emotion_Challenge"},{"id":221473504,"url":"https://www.researchgate.net/publication/221473504_How_people_talk_when_teaching_a_robot"},{"id":224354989,"url":"https://www.researchgate.net/publication/224354989_Discriminant_Graph_Structures_for_Facial_Expression_Recognition"},{"id":23643769,"url":"https://www.researchgate.net/publication/23643769_Novel_Multiclass_Classifiers_Based_on_the_Minimization_of_the_Within-Class_Variance"},{"id":220497546,"url":"https://www.researchgate.net/publication/220497546_Unobtrusive_Sensing_of_Emotions_USE"},{"id":221506178,"url":"https://www.researchgate.net/publication/221506178_A_Two-fold_PCA-Approach_for_Inter-Individual_Recognition_of_Emotions_in_Natural_Walking"},{"id":234811472,"url":"https://www.researchgate.net/publication/234811472_Designing_a_game_companion_for_long-term_social_interaction"},{"id":221335101,"url":"https://www.researchgate.net/publication/221335101_Prerequisites_for_Affective_Signal_Processing_ASP"},{"id":221052334,"url":"https://www.researchgate.net/publication/221052334_Recognizing_communicative_facial_expressions_for_discovering_interpersonal_emotions_in_group_meetings"},{"id":221052475,"url":"https://www.researchgate.net/publication/221052475_Static_vs_dynamic_modeling_of_human_nonverbal_behavior_from_multiple_cues_and_modalities"},{"id":41387085,"url":"https://www.researchgate.net/publication/41387085_Implicit_Human_Centered_Tagging"},{"id":234790309,"url":"https://www.researchgate.net/publication/234790309_Toward_environment-to-environment_E2E_affective_sensitive_communication_systems"},{"id":221412304,"url":"https://www.researchgate.net/publication/221412304_Manifold_Analysis_for_Subject_Independent_Dynamic_Emotion_Recognition_in_Video_Sequences"},{"id":228735838,"url":"https://www.researchgate.net/publication/228735838_Simulating_Pareidolia_of_Faces_for_Architectural_Image_Analysis"},{"id":220795053,"url":"https://www.researchgate.net/publication/220795053_Affective_game_engines_Motivation_and_requirements"},{"id":222399376,"url":"https://www.researchgate.net/publication/222399376_Boosting_encoded_dynamic_features_for_facial_expression_recognition_Pattern_Recogn_Lett_30_132-139"},{"id":234810884,"url":"https://www.researchgate.net/publication/234810884_Probabilistic_semantic_classifier"},{"id":260731502,"url":"https://www.researchgate.net/publication/260731502_How_people_talk_when_teaching_a_robot"},{"id":224374923,"url":"https://www.researchgate.net/publication/224374923_A_study_of_non-frontal-view_facial_expressions_recognition"},{"id":224566969,"url":"https://www.researchgate.net/publication/224566969_Semantic_Classifier_for_Affective_Computing"},{"id":23951796,"url":"https://www.researchgate.net/publication/23951796_Special_issue_on_human_computing"},{"id":224354563,"url":"https://www.researchgate.net/publication/224354563_Special_Issue_on_Human_Computing"},{"id":228930411,"url":"https://www.researchgate.net/publication/228930411_Social_Signal_Processing_Understanding_social_interactions_through_nonverbal_behavior_analysis_PDF"},{"id":220535517,"url":"https://www.researchgate.net/publication/220535517_A_3_HCI_Coding_Guideline_for_Research_Using_Video_Annotation_to_Assess_Behavior_of_Nonverbal_Subjects_with_Computer-Based_Intervention_8"},{"id":224490553,"url":"https://www.researchgate.net/publication/224490553_Analysis_of_affective_cues_in_human-robot_interaction_A_multi-level_approach"},{"id":224562481,"url":"https://www.researchgate.net/publication/224562481_Multimodal_estimation_of_a_driver's_spontaneous_irritation"},{"id":224577781,"url":"https://www.researchgate.net/publication/224577781_Evaluation_of_spatio-temporal_regional_features_For_3D_face_analysis"},{"id":224567819,"url":"https://www.researchgate.net/publication/224567819_Sensitive_Talking_Heads_Applications_Corner"},{"id":224576956,"url":"https://www.researchgate.net/publication/224576956_Is_this_joke_really_funny_Judging_the_mirth_by_audiovisual_laughter_analysis"},{"id":221111531,"url":"https://www.researchgate.net/publication/221111531_A_Novel_Approach_to_Expression_Recognition_from_Non-frontal_Face_Images"},{"id":235779351,"url":"https://www.researchgate.net/publication/235779351_Spotting_Agreement_and_Disagreement_A_Survey_of_Nonverbal_Audiovisual_Cues_and_Tools"},{"id":229034321,"url":"https://www.researchgate.net/publication/229034321_Hybrid_feature_and_decision_level_fusion_of_face_and_speech_information_for_bimodal_emotion_recognition"},{"id":224088177,"url":"https://www.researchgate.net/publication/224088177_It's_all_in_the_game_Towards_an_affect_sensitive_and_context_aware_game_companion"},{"id":224088108,"url":"https://www.researchgate.net/publication/224088108_Cross-modal_elicitation_of_affective_experience"},{"id":224088131,"url":"https://www.researchgate.net/publication/224088131_Guidelines_for_affective_signal_processing_ASP_From_lab_to_life"},{"id":224088170,"url":"https://www.researchgate.net/publication/224088170_Perception_of_emotional_expressions_in_different_representations_using_facial_feature_points"},{"id":224088060,"url":"https://www.researchgate.net/publication/224088060_OpenEAR_-_Introducing_the_Munich_open-source_emotion_and_affect_recognition_toolkit"},{"id":224088082,"url":"https://www.researchgate.net/publication/224088082_Requirements_and_software_framework_for_adaptive_multimodal_affect_recognition"},{"id":224088171,"url":"https://www.researchgate.net/publication/224088171_Understanding_affective_interaction_Emotion_engagement_and_internet_videos"},{"id":26820517,"url":"https://www.researchgate.net/publication/26820517_Toward_Practical_Smile_Detection"},{"id":41452754,"url":"https://www.researchgate.net/publication/41452754_Visual_and_Multimodal_Analysis_of_Human_Spontaneous_Behavior_Introduction_to_the_Special_Issue_of_Image_Vision_Computing_Journal"},{"id":222430190,"url":"https://www.researchgate.net/publication/222430190_Social_Signal_Processing_Survey_of_an_Emerging_Domain"},{"id":222421400,"url":"https://www.researchgate.net/publication/222421400_Being_bored_Recognising_natural_interest_by_extensive_audiovisual_integration_for_real-life_application"},{"id":228870694,"url":"https://www.researchgate.net/publication/228870694_Automatic_coding_of_facial_expressions_displayed_during_posed_and_genuine_pain"},{"id":224079195,"url":"https://www.researchgate.net/publication/224079195_A_Dynamic_Model_and_System-Theoretic_Analysis_of_Affect_based_on_a_Piecewise_Linear_System"},{"id":224606906,"url":"https://www.researchgate.net/publication/224606906_A_multimedia_corpus_of_driving_behaviors"},{"id":224606796,"url":"https://www.researchgate.net/publication/224606796_Automatic_fiducial_points_detection_for_facial_expressions_using_scale_invariant_feature"},{"id":224086674,"url":"https://www.researchgate.net/publication/224086674_A_Software_Framework_for_Multimodal_Human-Computer_Interaction_Systems"},{"id":226298347,"url":"https://www.researchgate.net/publication/226298347_Modelling_user-centric_pervasive_adaptive_systems_-_The_REFLECT_ontology"},{"id":38062243,"url":"https://www.researchgate.net/publication/38062243_Machine_analysis_of_facial_behaviour_Naturalistic_and_dynamic_behaviour"},{"id":224586599,"url":"https://www.researchgate.net/publication/224586599_Implicit_Human-Centered_Tagging"},{"id":40893586,"url":"https://www.researchgate.net/publication/40893586_Dynamic_information_for_the_recognition_of_conversational_expressions"},{"id":224586598,"url":"https://www.researchgate.net/publication/224586598_Multiscale_Genomic_Imaging_Informatics"},{"id":232620032,"url":"https://www.researchgate.net/publication/232620032_Evaluation_and_Discussion_of_Multi-modal_Emotion_Recognition"},{"id":251449290,"url":"https://www.researchgate.net/publication/251449290_Chapter_3_Playing_with_All_Senses"},{"id":226282755,"url":"https://www.researchgate.net/publication/226282755_Affective_Man-Machine_Interface_Unveiling_Human_Emotions_through_Biosignals"},{"id":220931154,"url":"https://www.researchgate.net/publication/220931154_Spatiotemporal-Boosted_DCT_Features_for_Head_and_Face_Gesture_Analysis"},{"id":221368776,"url":"https://www.researchgate.net/publication/221368776_Towards_multimodal_emotion_recognition_A_new_approach"},{"id":220058743,"url":"https://www.researchgate.net/publication/220058743_Facial_Affect_Recognition_Using_Regularized_Discriminant_Analysis-Based_Algorithms"},{"id":221573877,"url":"https://www.researchgate.net/publication/221573877_Eyes_do_not_lie_Spontaneous_versus_posed_smiles"},{"id":221532031,"url":"https://www.researchgate.net/publication/221532031_A_Component_Based_Approach_Improves_Classification_of_Discrete_Facial_Expressions_Over_a_Holistic_Approach"},{"id":228756702,"url":"https://www.researchgate.net/publication/228756702_Ubiquitous_social_perception_abilities_for_interaction_initiation_in_human-robot_interaction"},{"id":228568343,"url":"https://www.researchgate.net/publication/228568343_Spatiotemporal_Features_for_Effective_Facial_Expression_Recognition"},{"id":48340641,"url":"https://www.researchgate.net/publication/48340641_Implicit_Image_Tagging_via_Facial_Information"},{"id":228941477,"url":"https://www.researchgate.net/publication/228941477_Closing_the_loop_from_affect_recognition_to_empathic_interaction"},{"id":234798373,"url":"https://www.researchgate.net/publication/234798373_Automatic_Detection_of_Dominance_and_Expected_Interest"},{"id":43170331,"url":"https://www.researchgate.net/publication/43170331_Determination_of_Nonprototypical_Valence_and_Arousal_in_Popular_Music_Features_and_Performances"},{"id":49461037,"url":"https://www.researchgate.net/publication/49461037_Mobile_Social_Signal_Processing_Vision_and_Research_Issues"},{"id":228687325,"url":"https://www.researchgate.net/publication/228687325_Socially_perceptive_robots_Challenges_and_concerns"},{"id":228981519,"url":"https://www.researchgate.net/publication/228981519_Hough_Forest-Based_Facial_Expression_Recognition_from_Video_Sequences"},{"id":220928050,"url":"https://www.researchgate.net/publication/220928050_Audio-Visual_Classification_and_Fusion_of_Spontaneous_Affective_Data_in_Likelihood_Space"},{"id":221334952,"url":"https://www.researchgate.net/publication/221334952_Biometrics_for_Emotion_Detection_BED_Exploring_the_Combination_of_Speech_and_ECG"},{"id":221334098,"url":"https://www.researchgate.net/publication/221334098_The_Smart_Sensor_Integration_Framework_and_its_Application_in_EU_Projects"},{"id":220395386,"url":"https://www.researchgate.net/publication/220395386_Broadening_the_Scope_of_Affect_Detection_Research"},{"id":220735898,"url":"https://www.researchgate.net/publication/220735898_Learning_with_synthesized_speech_for_automatic_emotion_recognition"},{"id":221263192,"url":"https://www.researchgate.net/publication/221263192_Expression-driven_salient_features_Bubble-based_facial_expression_study_by_human_and_machine"},{"id":251969295,"url":"https://www.researchgate.net/publication/251969295_An_emotional_voice_generation_and_extraction_system_using_soft_computing_technique"},{"id":221413812,"url":"https://www.researchgate.net/publication/221413812_Facial_Expressions_and_Politeness_Effect_in_Foreign_Language_Training_System"},{"id":221545124,"url":"https://www.researchgate.net/publication/221545124_Saliency_distinguishing_and_applications_to_semantics_extraction_and_retrieval_of_natural_image"},{"id":221571512,"url":"https://www.researchgate.net/publication/221571512_3rd_international_workshop_on_affective_interaction_in_natural_environments_AFFINE"},{"id":221162042,"url":"https://www.researchgate.net/publication/221162042_Emotional_talking_agent_System_and_evaluation"},{"id":250199385,"url":"https://www.researchgate.net/publication/250199385_A_Method_for_Measuring_Emotion_of_Facial_Expression_Images_by_Using_CCA_and_Gazing_Property"},{"id":251975486,"url":"https://www.researchgate.net/publication/251975486_Human_emotion_recognition_using_real_3D_visual_features_from_Gabor_library"},{"id":251951992,"url":"https://www.researchgate.net/publication/251951992_Discovering_Emotions_in_Filipino_Laughter_Using_Audio_Features"},{"id":251982046,"url":"https://www.researchgate.net/publication/251982046_Human-centered_Video_Analysis_for_Multimedia_Postproduction"},{"id":233810386,"url":"https://www.researchgate.net/publication/233810386_Facial_expression_classification_based_on_local_spatiotemporal_edge_and_texture_descriptors"},{"id":241173135,"url":"https://www.researchgate.net/publication/241173135_The_TALA_Empathic_Space_Integrating_Affect_and_Activity_Recognition_into_a_Smart_Space"},{"id":241180612,"url":"https://www.researchgate.net/publication/241180612_Facial_expression_recognition_based_on_a_weighted_Local_Binary_Pattern"},{"id":220395370,"url":"https://www.researchgate.net/publication/220395370_Affect_Detection_An_Interdisciplinary_Review_of_Models_Methods_and_Their_Applications"},{"id":238518923,"url":"https://www.researchgate.net/publication/238518923_Automatic_landmarking_and_alignment_for_facial_expression_analysis"},{"id":228742941,"url":"https://www.researchgate.net/publication/228742941_Pattern_recognition_methods_-_A_novel_analysis_for_the_pupillographic_sleepiness_test"},{"id":221573424,"url":"https://www.researchgate.net/publication/221573424_Inter-ACT_an_affective_and_contextually_rich_multimodal_video_corpus_for_studying_interaction_with_robots"},{"id":45499883,"url":"https://www.researchgate.net/publication/45499883_Robot_nannies_Future_or_fiction"},{"id":224828035,"url":"https://www.researchgate.net/publication/224828035_Bimodal_Emotion_Recognition"},{"id":221260092,"url":"https://www.researchgate.net/publication/221260092_Automatic_Facial_Expression_Recognition_using_Bags_of_Motion_Words"},{"id":221570473,"url":"https://www.researchgate.net/publication/221570473_Mining_Bodily_Patterns_of_Affective_Experience_during_Learning"},{"id":220395374,"url":"https://www.researchgate.net/publication/220395374_Cross-Corpus_Acoustic_Emotion_Recognition_Variances_and_Strategies"},{"id":232048135,"url":"https://www.researchgate.net/publication/232048135_Classifiation_multilingue_et_multimedia_pour_la_recherche_d'images_dans_le_projet_OMNIA"},{"id":48907920,"url":"https://www.researchgate.net/publication/48907920_Analyse_Reconstruction_3D_Animation_du_Visage"},{"id":220930393,"url":"https://www.researchgate.net/publication/220930393_Speech_Emotion_Analysis_in_Noisy_Real-World_Environment"},{"id":220517037,"url":"https://www.researchgate.net/publication/220517037_Speech_Emotion_Analysis_Exploring_the_Role_of_Context"},{"id":228509199,"url":"https://www.researchgate.net/publication/228509199_Real_time_labeling_of_affect_in_music_using_the_affectbutton"},{"id":221001457,"url":"https://www.researchgate.net/publication/221001457_Recognizing_affect_from_non-stylized_body_motion_using_shape_of_Gaussian_descriptors"},{"id":220497574,"url":"https://www.researchgate.net/publication/220497574_Affective_negotiation_support_systems"},{"id":220716948,"url":"https://www.researchgate.net/publication/220716948_People's_Active_Emotion_Vocabulary_Free_Listing_of_Emotion_Labels_and_Their_Association_to_Salient_Psychological_Variables"},{"id":49461039,"url":"https://www.researchgate.net/publication/49461039_Human_Behavior_Understanding"},{"id":258407534,"url":"https://www.researchgate.net/publication/258407534_Ethics_and_Policy_of_Biometrics"},{"id":279641127,"url":"https://www.researchgate.net/publication/279641127_Multimodal_Emotion_Recognition"},{"id":235962496,"url":"https://www.researchgate.net/publication/235962496_Anthropocentric_Biocybernetic_Approaches_to_Architectural_Analysis_New_Methods_for_Investigating_the_Built_Environment"},{"id":251981003,"url":"https://www.researchgate.net/publication/251981003_Natural_user_interface_-_Next_mainstream_product_user_interface"},{"id":289655080,"url":"https://www.researchgate.net/publication/289655080_Analysis_of_the_interactions_using_eye_tracking_physiological_tracking_and_the_structures_of_actions"},{"id":224194259,"url":"https://www.researchgate.net/publication/224194259_Facial_Expression_Recognition_by_Automatic_Facial_Parts_Position_Detection_with_Boosted-LBP"},{"id":215835909,"url":"https://www.researchgate.net/publication/215835909_The_SEMAINE_API_Towards_a_standards-based_framework_for_building_emotion-oriented_systems"},{"id":225518184,"url":"https://www.researchgate.net/publication/225518184_Bimodal_Emotion_Recognition"},{"id":42638745,"url":"https://www.researchgate.net/publication/42638745_Recognition_of_Affect_Based_on_Gait_Patterns"},{"id":228651286,"url":"https://www.researchgate.net/publication/228651286_Multimodal_user's_affective_state_analysis_in_naturalistic_interaction"},{"id":45365441,"url":"https://www.researchgate.net/publication/45365441_A_Novel_Middleware_Solution_to_Improve_Ubiquitous_Healthcare_Systems_Aided_by_Affective_Information"},{"id":224929634,"url":"https://www.researchgate.net/publication/224929634_On-line_Emotion_Recognition_in_a_3-D_Activation-Valence-Time_Continuum_using_Acoustic_and_Linguistic_Cues"},{"id":42386822,"url":"https://www.researchgate.net/publication/42386822_Segmenting_into_Adequate_Units_for_Automatic_Recognition_of_Emotion-Related_Episodes_A_Speech-Based_Approach"},{"id":224122138,"url":"https://www.researchgate.net/publication/224122138_Facial_expression_recognition_based_on_discriminative_scale_invariant_feature_transform"},{"id":225457249,"url":"https://www.researchgate.net/publication/225457249_Using_affective_parameters_in_a_content-based_recommender_system_for_images"},{"id":226433553,"url":"https://www.researchgate.net/publication/226433553_Human_Face_Analysis_From_Identity_to_Emotion_and_Intention_Recognition"},{"id":224187946,"url":"https://www.researchgate.net/publication/224187946_The_MUG_facial_expression_database"},{"id":224125181,"url":"https://www.researchgate.net/publication/224125181_Tracking_Vertex_Flow_and_Model_Adaptation_for_Three-Dimensional_Spatiotemporal_Face_Analysis"},{"id":220045150,"url":"https://www.researchgate.net/publication/220045150_Speaker-independent_negative_emotion_recognition"},{"id":221364524,"url":"https://www.researchgate.net/publication/221364524_Exploring_facial_expressions_with_compositional_features"},{"id":220116358,"url":"https://www.researchgate.net/publication/220116358_Multimodal_semi-automated_affect_detection_from_conversational_cues_gross_body_language_and_facial_features"},{"id":226488121,"url":"https://www.researchgate.net/publication/226488121_Facial_Expression_Synthesis_Based_on_Emotion_Dimensions_for_Affective_Talking_Avatar"},{"id":228706652,"url":"https://www.researchgate.net/publication/228706652_Statistical_analysis_of_human_facial_expressions"},{"id":221424106,"url":"https://www.researchgate.net/publication/221424106_The_Emotional_Machine_A_Machine_Learning_Approach_to_Online_Prediction_of_User's_Emotion_and_Intensity"},{"id":220395371,"url":"https://www.researchgate.net/publication/220395371_Optimal_Arousal_Identification_and_Classification_for_Affective_Computing_Using_Physiological_Signals_Virtual_Reality_Stroop_Task"},{"id":221423264,"url":"https://www.researchgate.net/publication/221423264_Modelling_Affect_in_Learning_Environments_Motivation_and_Methods"},{"id":232638637,"url":"https://www.researchgate.net/publication/232638637_Cross-Corpus_Acoustic_Emotion_Recognition_Variances_and_Strategies"},{"id":224164308,"url":"https://www.researchgate.net/publication/224164308_Action_Unit_Detection_with_Segment-based_SVMs"},{"id":224165248,"url":"https://www.researchgate.net/publication/224165248_Facial_expressions_as_feedback_cue_in_human-robot_interaction-a_comparison_between_human_and_automatic_recognition_performances"},{"id":224165200,"url":"https://www.researchgate.net/publication/224165200_Socially_intelligent_surveillance_and_monitoring_Analysing_social_dimensions_of_physical_space"},{"id":224165246,"url":"https://www.researchgate.net/publication/224165246_The_Extended_Cohn-Kanade_Dataset_CK_A_complete_dataset_for_action_unit_and_emotion-specified_expression"},{"id":224165251,"url":"https://www.researchgate.net/publication/224165251_Facial_Expression_Recognition_Using_Gabor_Motion_Energy_Filters"},{"id":224165181,"url":"https://www.researchgate.net/publication/224165181_Sparse_representations_for_facial_expressions_recognition_via_l1_optimization"},{"id":224165490,"url":"https://www.researchgate.net/publication/224165490_Viewing_direction_estimation_based_on_3D_eyeball_construction_for_HRI"},{"id":224166971,"url":"https://www.researchgate.net/publication/224166971_Speech_Based_Emotion_Classification_Framework_for_Driver_Assistance_System"},{"id":224161662,"url":"https://www.researchgate.net/publication/224161662_Classification_of_affective_semantics_in_images_based_on_discrete_and_dimensional_models_of_emotions"},{"id":224159130,"url":"https://www.researchgate.net/publication/224159130_Features_for_multimodal_emotion_recognition_An_extensive_study"},{"id":220929463,"url":"https://www.researchgate.net/publication/220929463_Comparing_Multiple_Classifiers_for_Speech-Based_Detection_of_Self-Confidence_-_A_Pilot_Study"},{"id":220664245,"url":"https://www.researchgate.net/publication/220664245_Multimodal_information_fusion_application_to_human_emotion_recognition_from_face_and_speech"},{"id":224178173,"url":"https://www.researchgate.net/publication/224178173_Augmented_Reality_Issues_Trends_and_Challenges"},{"id":224176679,"url":"https://www.researchgate.net/publication/224176679_Pointing_with_the_eyes_Gaze_estimation_using_a_staticactive_camera_system_and_3D_iris_disk_model"},{"id":224177254,"url":"https://www.researchgate.net/publication/224177254_Fuzzy_functional_inference_method"},{"id":221303921,"url":"https://www.researchgate.net/publication/221303921_Coupled_Gaussian_Process_Regression_for_Pose-Invariant_Facial_Expression_Recognition"},{"id":262408452,"url":"https://www.researchgate.net/publication/262408452_Influence_of_visual_stimuli_on_evaluation_of_converted_emotional_speech_by_listening_tests"},{"id":224172418,"url":"https://www.researchgate.net/publication/224172418_Multimodal_Emotion_Recognition_Using_a_Spontaneous_Filipino_Emotion_Database"},{"id":221078660,"url":"https://www.researchgate.net/publication/221078660_Improving_the_Robustness_of_Subspace_Learning_Techniques_for_Facial_Expression_Recognition"},{"id":47760415,"url":"https://www.researchgate.net/publication/47760415_Reconnaissance_d'emotions_un_Point_de_Vue_Interaction_Multimodale"},{"id":221588620,"url":"https://www.researchgate.net/publication/221588620_Dimensional_Emotion_Prediction_from_Spontaneous_Head_Gestures_for_Interaction_with_Sensitive_Artificial_Listeners"},{"id":47382509,"url":"https://www.researchgate.net/publication/47382509_Gene_expression_of_monodehydroascorbate_reductase_and_dehydroascorbate_reductase_during_fruit_ripening_and_in_response_to_environmental_stresses_in_acerola_Malpighia_glabra"},{"id":220235009,"url":"https://www.researchgate.net/publication/220235009_A_Hybrid_Speech_Emotion_Recognition_System_Based_on_Spectral_and_Prosodic_Features"},{"id":269700848,"url":"https://www.researchgate.net/publication/269700848_Multi-modal_emotion_recognition_-_more_cognitive_machines"},{"id":46288565,"url":"https://www.researchgate.net/publication/46288565_Features_versus_Context_An_Approach_for_Precise_and_Detailed_Detection_and_Delineation_of_Faces_and_Facial_Features"},{"id":224174389,"url":"https://www.researchgate.net/publication/224174389_Robust_Symbolic_Dual-View_Facial_Expression_Recognition_With_Skin_Wrinkles_Local_Versus_Global_Approach"},{"id":224174390,"url":"https://www.researchgate.net/publication/224174390_A_3-D_Audio-Visual_Corpus_of_Affective_Communication"},{"id":224155355,"url":"https://www.researchgate.net/publication/224155355_Combining_Long_Short-Term_Memory_and_Dynamic_Bayesian_Networks_for_Incremental_Emotion-Sensitive_Artificial_Listening"},{"id":241113196,"url":"https://www.researchgate.net/publication/241113196_209_Monoclonal_antibody_targeting_of_the_anaplastic_lymphoma_kinase_ALK_receptor"},{"id":49628576,"url":"https://www.researchgate.net/publication/49628576_Automatically_Detecting_Pain_in_Video_Through_Facial_Action_Units"},{"id":224174385,"url":"https://www.researchgate.net/publication/224174385_Speech_Emotion_Analysis_Exploring_the_Role_of_Context"},{"id":46288560,"url":"https://www.researchgate.net/publication/46288560_A_Dynamic_Texture-Based_Approach_to_Recognition_of_Facial_Actions_and_Their_Temporal_Models"},{"id":241113203,"url":"https://www.researchgate.net/publication/241113203_221_DISCUSSION_89Zr-bevacizumab_PET_imaging_in_renal_cell_carcinoma_patients_feasibility_of_tumor_VEGF_quantification"},{"id":224196992,"url":"https://www.researchgate.net/publication/224196992_Sensing_facial_emotions_in_a_continuous_2D_affective_space"},{"id":221303979,"url":"https://www.researchgate.net/publication/221303979_Emotion_Recognition_from_Arbitrary_View_Facial_Images"},{"id":224202519,"url":"https://www.researchgate.net/publication/224202519_Facial_Expression_Recognition_from_Image_Sequences_Based_on_Feature_Points_and_Canonical_Correlations"},{"id":224205201,"url":"https://www.researchgate.net/publication/224205201_Pervasive_Social_Computing_Augmenting_Five_Facets_of_Human_Intelligence"},{"id":224160702,"url":"https://www.researchgate.net/publication/224160702_A_Natural_Visible_and_Infrared_Facial_Expression_Database_for_Expression_Recognition_and_Emotion_Inference"},{"id":220929459,"url":"https://www.researchgate.net/publication/220929459_Challenges_of_Human_Behavior_Understanding"},{"id":220785262,"url":"https://www.researchgate.net/publication/220785262_Dynamic_Facial_Expression_Recognition_Using_Boosted_Component-Based_Spatiotemporal_Features_and_Multi-classifier_Fusion"},{"id":227031714,"url":"https://www.researchgate.net/publication/227031714_Facial_Expression_Recognition"},{"id":225932919,"url":"https://www.researchgate.net/publication/225932919_Significant_Accomplishments_New_Challenges_and_New_Perspectives"},{"id":226483706,"url":"https://www.researchgate.net/publication/226483706_Multimodal_Emotion_Recognition_from_Low-Level_Cues"},{"id":226527110,"url":"https://www.researchgate.net/publication/226527110_Actionable_Affective_Processing_for_Automatic_Tutor_Interventions"},{"id":227113754,"url":"https://www.researchgate.net/publication/227113754_Integrating_Cognitive_Metacognitive_and_Affective_Regulatory_Processes_with_MetaTutor"},{"id":235013466,"url":"https://www.researchgate.net/publication/235013466_Real_Time_Eye_Tracking_and_Hand_Tracking_Using_Regular_Video_Cameras_for_Human_Computer_Interaction"},{"id":220664651,"url":"https://www.researchgate.net/publication/220664651_Personalization_in_multimedia_retrieval_A_survey"},{"id":227322039,"url":"https://www.researchgate.net/publication/227322039_Utterance_independent_bimodal_emotion_recognition_in_spontaneous_communication"},{"id":221032445,"url":"https://www.researchgate.net/publication/221032445_Smart_Phone_Sensing_to_Examine_Effects_of_Social_Interactions_and_Non-sedentary_Work_Time_on_Mood_Changes"},{"id":221622059,"url":"https://www.researchgate.net/publication/221622059_Lecture_Notes_in_Computer_Science"},{"id":221622140,"url":"https://www.researchgate.net/publication/221622140_3D_Corpus_of_Spontaneous_Complex_Mental_States"},{"id":221622106,"url":"https://www.researchgate.net/publication/221622106_Inductive_Transfer_Learning_for_Handling_Individual_Differences_in_Affective_Computing"},{"id":233996789,"url":"https://www.researchgate.net/publication/233996789_Enabling_Social_Software-Based_Musical_Content_for_Computer_Games_and_Virtual_Worlds"},{"id":221622091,"url":"https://www.researchgate.net/publication/221622091_Recognizing_Bodily_Expression_of_Affect_in_User_Tests"},{"id":226328925,"url":"https://www.researchgate.net/publication/226328925_Fundamentals_of_Agent_Perception_and_Attention_Modelling"},{"id":221291990,"url":"https://www.researchgate.net/publication/221291990_3D_facial_expression_recognition_A_perspective_on_promises_and_challenges"},{"id":220756242,"url":"https://www.researchgate.net/publication/220756242_Recent_developments_in_social_signal_processing"},{"id":221473553,"url":"https://www.researchgate.net/publication/221473553_Automatic_analysis_of_affective_postures_and_body_motion_to_detect_engagement_with_a_game_companion"},{"id":223918335,"url":"https://www.researchgate.net/publication/223918335_Expression_of_affect_in_spontaneous_speech_Acoustic_correlates_and_automatic_detection_of_irritation_and_resignation"},{"id":243971079,"url":"https://www.researchgate.net/publication/243971079_Augmenting_Virtual-Reality_Environments_with_Social-Signal_Based_Music_Content"},{"id":252038964,"url":"https://www.researchgate.net/publication/252038964_Spontaneous_Facial_Expression_Recognition_Based_on_Feature_Point_Tracking"},{"id":221292440,"url":"https://www.researchgate.net/publication/221292440_Reshaping_3D_facial_scans_for_facial_appearance_modeling_and_3D_facial_expression_analysis"},{"id":252056179,"url":"https://www.researchgate.net/publication/252056179_Spontaneous_facial_expression_recognition_by_using_feature-level_fusion_of_visible_and_thermal_infrared_images"},{"id":221292560,"url":"https://www.researchgate.net/publication/221292560_Analyzing_empathetic_interactions_based_on_the_probabilistic_modeling_of_the_co-occurrence_patterns_of_facial_expressions_in_group_meetings"},{"id":224929599,"url":"https://www.researchgate.net/publication/224929599_The_Automatic_Recognition_of_Emotions_in_Speech"},{"id":221292243,"url":"https://www.researchgate.net/publication/221292243_Accumulated_motion_images_for_facial_expression_recognition_in_videos"},{"id":241184582,"url":"https://www.researchgate.net/publication/241184582_Classification_of_spontaneous_and_posed_smiles"},{"id":47508039,"url":"https://www.researchgate.net/publication/47508039_Towards_a_Technology_of_Nonverbal_Communication_Vocal_Behavior_in_Social_and_Affective_Phenomena"},{"id":221159890,"url":"https://www.researchgate.net/publication/221159890_LIRIS-Imagine_at_image_CLEF_2011_photo_annotation_task"},{"id":221052627,"url":"https://www.researchgate.net/publication/221052627_Long-term_socially_perceptive_and_interactive_robot_companions_Challenges_and_future_perspectives"},{"id":220874722,"url":"https://www.researchgate.net/publication/220874722_An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue"},{"id":221054022,"url":"https://www.researchgate.net/publication/221054022_Culture_and_Facial_Expressions_A_Case_Study_with_a_Speech_Interface"},{"id":232237798,"url":"https://www.researchgate.net/publication/232237798_Realtime_Expressive_Movement_Detection_Using_the_EyesWeb_XMI_Platform"},{"id":220267259,"url":"https://www.researchgate.net/publication/220267259_Quality_of_experience_evaluation_of_voice_communication_an_affect-based_approach"},{"id":221052561,"url":"https://www.researchgate.net/publication/221052561_A_systematic_discussion_of_fusion_techniques_for_multi-modal_affect_recognition_tasks"},{"id":254900623,"url":"https://www.researchgate.net/publication/254900623_Social_Signal_Processing_The_Research_Agenda"},{"id":221411696,"url":"https://www.researchgate.net/publication/221411696_Spatial_Feature_Interdependence_Matrix_SFIM_A_Robust_Descriptor_for_Face_Recognition"},{"id":221430094,"url":"https://www.researchgate.net/publication/221430094_4D_facial_expression_recognition"},{"id":221052273,"url":"https://www.researchgate.net/publication/221052273_Towards_Multimodal_Sentiment_Analysis_Harvesting_Opinions_from_the_Web"},{"id":220270269,"url":"https://www.researchgate.net/publication/220270269_Modeling_Latent_Discriminative_Dynamic_of_Multi-dimensional_Affective_Signals"},{"id":221622195,"url":"https://www.researchgate.net/publication/221622195_A_Psychologically-Inspired_Match-Score_Fusion_Model_for_Video-Based_Facial_Expression_Recognition"},{"id":220270306,"url":"https://www.researchgate.net/publication/220270306_A_Regression_Approach_to_Affective_Rating_of_Chinese_Words_from_ANEW"},{"id":221430162,"url":"https://www.researchgate.net/publication/221430162_Facial_action_unit_detection_using_kernel_partial_least_squares"},{"id":252011712,"url":"https://www.researchgate.net/publication/252011712_Sleep_apnea_detection_for_prephase_diagnosis_using_third_level_Holter_recording_device"},{"id":221622110,"url":"https://www.researchgate.net/publication/221622110_Naturalistic_Affective_Expression_Classification_by_a_Multi-stage_Approach_Based_on_Hidden_Markov_Models"},{"id":224204221,"url":"https://www.researchgate.net/publication/224204221_The_Age_of_Avatar_Realism"},{"id":221622122,"url":"https://www.researchgate.net/publication/221622122_Using_Facial_Emotional_Signals_for_Communication_between_Emotionally_Expressive_Avatars_in_Virtual_Worlds"},{"id":221113425,"url":"https://www.researchgate.net/publication/221113425_Fusion_of_Audio-_and_Visual_Cues_for_Real-Life_Emotional_Human_Robot_Interaction"},{"id":221292330,"url":"https://www.researchgate.net/publication/221292330_Expression_recognition_from_3D_dynamic_faces_using_robust_spatio-temporal_shape_features"},{"id":254007032,"url":"https://www.researchgate.net/publication/254007032_Estimation_of_user_conversational_states_based_on_combination_of_user_actions_and_feature_normalization"},{"id":221430187,"url":"https://www.researchgate.net/publication/221430187_Criteria_and_metrics_for_thresholded_AU_detection"},{"id":235761687,"url":"https://www.researchgate.net/publication/235761687_Detecting_human_behavior_emotional_cues_in_Natural_Interaction"},{"id":220845140,"url":"https://www.researchgate.net/publication/220845140_Efficient_Detection_of_Consecutive_Facial_Expression_Apices_Using_Biologically_Based_Log-Normal_Filters"},{"id":263921091,"url":"https://www.researchgate.net/publication/263921091_Influence_of_Visual_Stimuli_on_Evaluation_of_Converted_Emotional_Speech_by_Listening_Tests"},{"id":221052641,"url":"https://www.researchgate.net/publication/221052641_Crowdsourced_data_collection_of_facial_responses"},{"id":252020492,"url":"https://www.researchgate.net/publication/252020492_Towards_3D_Communications_Real_Time_Emotion_Driven_3D_Virtual_Facial_Animation"},{"id":241184645,"url":"https://www.researchgate.net/publication/241184645_Automatic_3D_segmentation_of_facial_soft_tissues_using_unlabelled_prior_information"},{"id":220106799,"url":"https://www.researchgate.net/publication/220106799_Affect_prediction_from_physiological_measures_via_visual_stimuli"},{"id":220374438,"url":"https://www.researchgate.net/publication/220374438_Computer-mediated_Counter-Arguments_and_Individual_Learning"},{"id":267332394,"url":"https://www.researchgate.net/publication/267332394_Inductive_Transfer_Learning_for_Handling_Individual_Differences_in_Affective_Computing"},{"id":241627893,"url":"https://www.researchgate.net/publication/241627893_Person_independent_facial_expression_analysis_using_Gabor_features_and_Genetic_Algorithm"},{"id":289774773,"url":"https://www.researchgate.net/publication/289774773_Emotional_Robot_Competence_and_Its_Use_in_Robot_Behavior_Control"},{"id":224219900,"url":"https://www.researchgate.net/publication/224219900_A_spontaneous_facial_expression_recognition_method_using_head_motion_and_AAM_features"},{"id":43201168,"url":"https://www.researchgate.net/publication/43201168_Graph-Preserving_Sparse_Nonnegative_Matrix_Factorization_With_Application_to_Facial_Expression_Recognition"},{"id":258403256,"url":"https://www.researchgate.net/publication/258403256_Classification_of_Emotional_Speech_Based_on_an_Automatically_Elaborated_Hierarchical_Classifier"},{"id":224167890,"url":"https://www.researchgate.net/publication/224167890_Online_Sparse_Gaussian_Process_Regression_and_Its_Applications"},{"id":221292325,"url":"https://www.researchgate.net/publication/221292325_Action_unit_detection_using_sparse_appearance_descriptors_in_space-time_video_volumes"},{"id":221292142,"url":"https://www.researchgate.net/publication/221292142_The_first_facial_expression_recognition_and_analysis_challenge"},{"id":221292323,"url":"https://www.researchgate.net/publication/221292323_String-based_audiovisual_fusion_of_behavioural_events_for_the_assessment_of_dimensional_affect"},{"id":221292581,"url":"https://www.researchgate.net/publication/221292581_Emotion_recognition_by_two_view_SVM-2K_classifier_on_dynamic_facial_expression_features"},{"id":221292416,"url":"https://www.researchgate.net/publication/221292416_Improved_SIFT_matching_for_pose_robust_facial_expression_recognition"},{"id":220135732,"url":"https://www.researchgate.net/publication/220135732_Dynamic_soft_encoded_patterns_for_facial_event_analysis"},{"id":233847078,"url":"https://www.researchgate.net/publication/233847078_Speech_Emotion_Recognition_Approaches_in_Human_Computer_Interaction"},{"id":221292666,"url":"https://www.researchgate.net/publication/221292666_An_efficient_approach_to_smile_detection"},{"id":257351308,"url":"https://www.researchgate.net/publication/257351308_Differential_optical_flow_applied_to_automatic_facial_expression_recognition"},{"id":221292544,"url":"https://www.researchgate.net/publication/221292544_Painful_data_The_UNBC-McMaster_shoulder_pain_expression_archive_database"},{"id":224144294,"url":"https://www.researchgate.net/publication/224144294_Emotional_Audio-Visual_Speech_Synthesis_Based_on_PAD"},{"id":224175889,"url":"https://www.researchgate.net/publication/224175889_Analysis_of_Real-World_Driver's_Frustration"},{"id":220395375,"url":"https://www.researchgate.net/publication/220395375_Dynamic_Cascades_with_Bidirectional_Bootstrapping_for_Action_Unit_Detection_in_Spontaneous_Facial_Behavior"},{"id":232933974,"url":"https://www.researchgate.net/publication/232933974_Personalized_Health_Monitoring_Personalization_and_Personality"},{"id":221911529,"url":"https://www.researchgate.net/publication/221911529_Facial_Expression_Recognition"},{"id":220590846,"url":"https://www.researchgate.net/publication/220590846_Emerging_Technologies_and_Applications_on_Interactive_Entertainments"},{"id":261237360,"url":"https://www.researchgate.net/publication/261237360_A_comparison_of_geometrical_facial_features_for_affect_recognition"},{"id":224238099,"url":"https://www.researchgate.net/publication/224238099_HCI2_Workbench_A_development_tool_for_multimodal_human-computer_interaction_systems"},{"id":224238135,"url":"https://www.researchgate.net/publication/224238135_Output-associative_RVM_regression_for_dimensional_and_continuous_emotion_prediction"},{"id":224238115,"url":"https://www.researchgate.net/publication/224238115_Emotion_recognition_from_an_ensemble_of_features"},{"id":224238109,"url":"https://www.researchgate.net/publication/224238109_Emotion_representation_analysis_and_synthesis_in_continuous_space_A_survey"},{"id":224238180,"url":"https://www.researchgate.net/publication/224238180_Effect_of_illumination_on_automatic_expression_recognition_A_novel_3D_relightable_facial_database"},{"id":224207538,"url":"https://www.researchgate.net/publication/224207538_Audiovisual_Discrimination_Between_Speech_and_Laughter_Why_and_When_Visual_Information_Might_Help"},{"id":220809280,"url":"https://www.researchgate.net/publication/220809280_Expression_Recognition_in_Videos_Using_a_Weighted_Component-Based_Feature_Descriptor"},{"id":261421350,"url":"https://www.researchgate.net/publication/261421350_A_common_framework_for_real-time_emotion_recognition_and_facial_action_unit_detection"},{"id":225122788,"url":"https://www.researchgate.net/publication/225122788_Biometrics_in_ambient_intelligence"},{"id":221912621,"url":"https://www.researchgate.net/publication/221912621_Adaptive_Human-Aware_Robot_Navigation_in_Close_Proximity_to_Humans"},{"id":220612592,"url":"https://www.researchgate.net/publication/220612592_Robust_classification_of_face_and_head_gestures_in_video"},{"id":224252286,"url":"https://www.researchgate.net/publication/224252286_Cross-dataset_facial_expression_recognition"},{"id":224252396,"url":"https://www.researchgate.net/publication/224252396_Weighted_biased_linear_discriminant_analysis_for_misalignment-robust_facial_expression_recognition"},{"id":224203452,"url":"https://www.researchgate.net/publication/224203452_An_Ensemble_Method_for_Classifying_Startle_Eyeblink_Modulation_from_High-Speed_Video_Records"},{"id":229031081,"url":"https://www.researchgate.net/publication/229031081_Design_and_implementation_of_an_affect-responsive_interactive_photo_frame"},{"id":260658514,"url":"https://www.researchgate.net/publication/260658514_Experience-Driven_Procedural_Content_Generation"},{"id":224221961,"url":"https://www.researchgate.net/publication/224221961_A_Multi-Gesture_Interaction_System_Using_a_3-D_Iris_Disk_Model_for_Gaze_Estimation_and_an_Active_Appearance_Model_for_3-D_Hand_Pointing"},{"id":220054573,"url":"https://www.researchgate.net/publication/220054573_Affective_responses_to_system_messages_in_human-computer-interaction_Effects_of_modality_and_message_type"},{"id":221094985,"url":"https://www.researchgate.net/publication/221094985_Emotional_Human-Machine_Interaction_Cues_from_Facial_Expressions"},{"id":221260747,"url":"https://www.researchgate.net/publication/221260747_Motivating_People_in_Smart_Environments"},{"id":221260848,"url":"https://www.researchgate.net/publication/221260848_Impact_of_Implicit_and_Explicit_Affective_Labeling_on_a_Recommender_System's_Performance"},{"id":226387747,"url":"https://www.researchgate.net/publication/226387747_Computational_Assessment_of_Interest_in_Speech-Facing_the_Real-Life_Challenge"},{"id":49795362,"url":"https://www.researchgate.net/publication/49795362_Automatic_Recognition_of_Non-Acted_Affective_Postures"},{"id":267824769,"url":"https://www.researchgate.net/publication/267824769_A_multi-core_processor_based_real-time_multi-modal_emotion_extraction_system_employing_fuzzy_inference"},{"id":262354418,"url":"https://www.researchgate.net/publication/262354418_Subject-independent_emotion_recognition_from_facial_expressions_using_a_gabor_feature_RBF_neural_classifier_trained_with_virtual_samples_generated_by_Concurrent_Self-Organizing_Maps"},{"id":225730925,"url":"https://www.researchgate.net/publication/225730925_Human_Centered_Interfaces_for_Assisted_Living"},{"id":261049109,"url":"https://www.researchgate.net/publication/261049109_Audio-Emotion_Recognition_System_Using_Parallel_Classifiers_and_Audio_Feature_Analyzer"},{"id":261019372,"url":"https://www.researchgate.net/publication/261019372_Facial_expression_anlysis_using_eye_gaze_information"},{"id":251493986,"url":"https://www.researchgate.net/publication/251493986_Les_effets_de_l'ingestion_aigue_d'alcool_sur_le_jugement_d'expressions_faciales_emotionnelles_spontanees_et_dynamiques"},{"id":221127178,"url":"https://www.researchgate.net/publication/221127178_3D_facial_expression_recognition_using_Zernike_moments_on_depth_images"},{"id":258885038,"url":"https://www.researchgate.net/publication/258885038_What_to_detect_Analyzing_Factor_Structures_of_Affect_in_Driving_Contexts_for_an_Emotion_Detection_and_Regulation_System"},{"id":240085011,"url":"https://www.researchgate.net/publication/240085011_Analysis_of_Verbal_and_Nonverbal_Communication_and_Enactment_The_Processing_Issues"},{"id":224256572,"url":"https://www.researchgate.net/publication/224256572_Smile_Expression_Classification_Using_the_Improved_BIF_Feature"},{"id":260067708,"url":"https://www.researchgate.net/publication/260067708_Modeling_and_Using_Context"},{"id":229049764,"url":"https://www.researchgate.net/publication/229049764_Acted_Facial_Expressions_In_The_Wild_Database"},{"id":224222825,"url":"https://www.researchgate.net/publication/224222825_Automatic_Recognition_of_Boredom_in_Video_Games_Using_Novel_Biosignal_Moment-Based_Features"},{"id":220395388,"url":"https://www.researchgate.net/publication/220395388_Facial_Expression_Recognition_Using_Facial_Movement_Features"},{"id":51551359,"url":"https://www.researchgate.net/publication/51551359_Improving_subspace_learning_for_facial_expression_recognition_using_person_dependent_and_geometrically_enriched_training_sets"},{"id":221622246,"url":"https://www.researchgate.net/publication/221622246_Multi-score_Learning_for_Affect_Recognition_The_Case_of_Body_Postures"},{"id":221622162,"url":"https://www.researchgate.net/publication/221622162_Multi-modal_Affect_Induction_for_Affective_Brain-Computer_Interfaces"},{"id":220270318,"url":"https://www.researchgate.net/publication/220270318_Associating_Textual_Features_with_Visual_Ones_to_Improve_Affective_Image_Classification"},{"id":264071409,"url":"https://www.researchgate.net/publication/264071409_A_Study_on_Visual_Perception_based_Emotion_Recognition_using_Body-Activity_Posture"},{"id":226351088,"url":"https://www.researchgate.net/publication/226351088_Determination_of_emotional_content_of_video_clips_by_low-level_audiovisual_features_A_dimensional_and_categorial_experimental_approach"},{"id":220508716,"url":"https://www.researchgate.net/publication/220508716_Local_Binary_Patterns_and_Its_Application_to_Facial_Image_Analysis_A_Survey"},{"id":220593106,"url":"https://www.researchgate.net/publication/220593106_Application_of_NSGA-II_to_feature_selection_for_facial_expression_recognition"},{"id":221141958,"url":"https://www.researchgate.net/publication/221141958_Bimodal_System_for_Emotion_Recognition_from_Facial_Expressions_and_Physiological_Signals_Using_Feature-Level_Fusion"},{"id":258884611,"url":"https://www.researchgate.net/publication/258884611_An_angry_driver_is_not_the_same_as_a_fearful_driver_Different_effects_of_specific_negative_emotions_on_risk_perception_driving_performance_and_workload"},{"id":221523887,"url":"https://www.researchgate.net/publication/221523887_Improving_Spontaneous_Children's_Emotion_Recognition_by_Acoustic_Feature_Selection_and_Feature-Level_Fusion_of_Acoustic_and_Linguistic_Parameters"},{"id":221620697,"url":"https://www.researchgate.net/publication/221620697_Analyzing_Facial_Behavioral_Features_from_Videos"},{"id":224265024,"url":"https://www.researchgate.net/publication/224265024_Audiovisual_Affect_Recognition_in_Spontaneous_Filipino_Laughter"},{"id":254048922,"url":"https://www.researchgate.net/publication/254048922_Weighted_Local_Directional_Pattern_for_Robust_Facial_Expression_Recognition"},{"id":254029113,"url":"https://www.researchgate.net/publication/254029113_Research_on_Speech_Recognition_Technology_and_Its_Application"},{"id":235834264,"url":"https://www.researchgate.net/publication/235834264_A_Survey_on_Measuring_Happiness_with_Smart_Phones"},{"id":226025186,"url":"https://www.researchgate.net/publication/226025186_Ubiquitous_emotion-aware_computing"},{"id":230793132,"url":"https://www.researchgate.net/publication/230793132_Comparative_Study_on_Feature_Selection_and_Fusion_Schemes_for_Emotion_Recognition_from_Speech"},{"id":220068803,"url":"https://www.researchgate.net/publication/220068803_Emotional_facial_sensing_and_multimodal_fusion_in_a_continuous_2D_affective_space"},{"id":263372693,"url":"https://www.researchgate.net/publication/263372693_Facial_Communicative_Signals_Valence_Recognition_in_Task-Oriented_Human-Robot_Interaction"},{"id":220068793,"url":"https://www.researchgate.net/publication/220068793_Robust_emotion_recognition_by_spectro-temporal_modulation_statistic_features"},{"id":229038870,"url":"https://www.researchgate.net/publication/229038870_Bridging_the_Gap_Between_Social_Animal_and_Unsocial_Machine_A_Survey_of_Social_Signal_Processing"},{"id":235911192,"url":"https://www.researchgate.net/publication/235911192_Group_Decision_Support_for_Requirements_Negotiation"},{"id":261353650,"url":"https://www.researchgate.net/publication/261353650_An_NARX-based_approach_for_human_emotion_identification"},{"id":261168403,"url":"https://www.researchgate.net/publication/261168403_Bias_analyses_of_spontaneous_facial_expression_database"},{"id":261387453,"url":"https://www.researchgate.net/publication/261387453_Audio-visual_emotion_recognition_using_Boltzmann_Zippers"},{"id":261344004,"url":"https://www.researchgate.net/publication/261344004_Emotion-inspired_age_and_gender_recognition_systems"},{"id":257388404,"url":"https://www.researchgate.net/publication/257388404_The_influence_of_empathy_in_humanrobot_relations_Int_J_Hum-Comput_Stud"},{"id":257388409,"url":"https://www.researchgate.net/publication/257388409_Detecting_engagement_in_HRI_An_exploration_of_social_and_task-based_context"},{"id":261466210,"url":"https://www.researchgate.net/publication/261466210_Fast_emotion_detection_from_EEG_using_asymmetric_spatial_filtering"},{"id":260658413,"url":"https://www.researchgate.net/publication/260658413_Representative_Segment-Based_Emotion_Analysis_and_Classification_with_Automatic_Respiration_Signal_Segmentation"},{"id":261496213,"url":"https://www.researchgate.net/publication/261496213_A_dynamic_curvature_based_approach_for_facial_activity_analysis_in_3D_space"},{"id":261111064,"url":"https://www.researchgate.net/publication/261111064_Exploiting_implicit_affective_labeling_for_image_recommendations"},{"id":261351065,"url":"https://www.researchgate.net/publication/261351065_Affect_detection_from_body_language_during_social_HRI"},{"id":261387567,"url":"https://www.researchgate.net/publication/261387567_Fusion_of_static_and_temporal_predictors_for_unconstrained_facial_expression_recognition"},{"id":254005011,"url":"https://www.researchgate.net/publication/254005011_Game_AI_revisited"},{"id":261281721,"url":"https://www.researchgate.net/publication/261281721_Audio-visual_emotion_recognition_with_boosted_coupled_HMM"},{"id":224251573,"url":"https://www.researchgate.net/publication/224251573_A_Multi-Modal_Affective_Database_for_Affect_Recognition_and_Implicit_Tagging"},{"id":261147223,"url":"https://www.researchgate.net/publication/261147223_Mouth_area_analysis_by_the_use_of_selected_spectral_energies"},{"id":254032728,"url":"https://www.researchgate.net/publication/254032728_A_survey_of_ground-truth_in_emotion_data_annotation"},{"id":261267337,"url":"https://www.researchgate.net/publication/261267337_Multimodal_affect_recognition_in_spontaneous_HCI_environment"},{"id":261349090,"url":"https://www.researchgate.net/publication/261349090_Multi-view_facial_expression_recognition_using_local_appearance_features"},{"id":254056741,"url":"https://www.researchgate.net/publication/254056741_Face_typing_Vision-based_perceptual_interface_for_hands-free_text_entry_with_a_scrollable_virtual_keyboard"},{"id":261168594,"url":"https://www.researchgate.net/publication/261168594_Face_analysis_of_aggressive_moods_in_automobile_driving_using_mutual_subspace_method"},{"id":261279398,"url":"https://www.researchgate.net/publication/261279398_Ambient_sensing_chairs_for_audience_emotion_recognition_by_finding_synchrony_of_body_sway"},{"id":261421349,"url":"https://www.researchgate.net/publication/261421349_Features_and_fusion_for_expression_recognition_-_A_comparative_analysis"},{"id":233910078,"url":"https://www.researchgate.net/publication/233910078_Akhtar_Hussain_Abdul_Rehman_Abbasi_Nitin_V_Afzulpurkar_Detecting_Interpreting_Self-Manipulating_Hand_Movements_for_Students_Affect_Prediction_Human_Centric_Computing_and_Information_Sciences_SpringerO"},{"id":261035776,"url":"https://www.researchgate.net/publication/261035776_Expressions_invariant_face_recognition_using_SURF_and_Gabor_features"},{"id":270890520,"url":"https://www.researchgate.net/publication/270890520_Tassinary_L_G_Hess_U_Carcoba_L_2012_Peripheral_physiological_measures_of_psychological_constructs_In_Cooper_H_APA_Handbook_of_Research_Methods_in_Psychology_Vol_1_Foundations_Planning_Measures_and_Psy"},{"id":261154749,"url":"https://www.researchgate.net/publication/261154749_Learning_Multiscale_Active_Facial_Patches_for_Expression_Analysis"},{"id":284567857,"url":"https://www.researchgate.net/publication/284567857_Dynamic_Facial_Expression_Recognition_Using_Longitudinal_Facial_Expression_Atlases"},{"id":263962519,"url":"https://www.researchgate.net/publication/263962519_Wildlife_Communication"},{"id":278715571,"url":"https://www.researchgate.net/publication/278715571_Investigating_the_Effects_of_Robotic_Displays_of_Protest_and_Distress"},{"id":221922548,"url":"https://www.researchgate.net/publication/221922548_Affective_Human-Humanoid_Interaction_Through_Cognitive_Architecture"},{"id":257513035,"url":"https://www.researchgate.net/publication/257513035_Features_and_classifiers_for_emotion_recognition_from_speech_a_survey_from_2000_to_2011"},{"id":224250189,"url":"https://www.researchgate.net/publication/224250189_A_Statistical_Method_for_2-D_Facial_Landmarking"},{"id":220517127,"url":"https://www.researchgate.net/publication/220517127_Error_Weighted_Semi-Coupled_Hidden_Markov_Model_for_Audio-Visual_Emotion_Recognition"},{"id":258713575,"url":"https://www.researchgate.net/publication/258713575_Automated_Detection_of_Pain_from_Facial_Expressions_A_Rule-Based_Approach_Using_AAM"},{"id":236017279,"url":"https://www.researchgate.net/publication/236017279_Room-temperature_wide-range_photoluminescence_and_semiconducting_characteristics_of_two-dimensional_pure_metallic_Zn_nanoplates"},{"id":221828597,"url":"https://www.researchgate.net/publication/221828597_Emotional_sweating_across_the_body_Comparing_16_different_skin_conductance_measurement_locations"},{"id":221817316,"url":"https://www.researchgate.net/publication/221817316_Imagination_and_society_The_role_of_visual_sociology"},{"id":232906550,"url":"https://www.researchgate.net/publication/232906550_The_LDOS-PerAff-1_corpus_of_facial-_expression_video_clips_with_affective_personality_and_user-interaction_metadata"},{"id":235761693,"url":"https://www.researchgate.net/publication/235761693_A_cross-cultural_multimodal_affective_corpus_for_gesture_expressivity_analysis"},{"id":241623850,"url":"https://www.researchgate.net/publication/241623850_Affect_Recognition_Based_on_Physiological_Changes_During_the_Watching_of_Music_Video"},{"id":224929590,"url":"https://www.researchgate.net/publication/224929590_A_Multi-Task_Approach_to_Continuous_Five-Dimensional_Affect_Sensing_in_Natural_Speech"},{"id":221928369,"url":"https://www.researchgate.net/publication/221928369_Recognition_of_Emotion_from_Speech_A_Review"},{"id":221967771,"url":"https://www.researchgate.net/publication/221967771_The_MPI_Facial_Expression_Database_-_A_Validated_Database_of_Emotional_and_Conversational_Facial_Expressions"},{"id":236204505,"url":"https://www.researchgate.net/publication/236204505_Estimation_of_the_Neutral_Face_Shape_Using_Gaussian_Mixture_Models"},{"id":262392661,"url":"https://www.researchgate.net/publication/262392661_Spontaneous_facial_expression_recognition_automatic_aggression_detection"},{"id":234163741,"url":"https://www.researchgate.net/publication/234163741_Measuring_learners'_unfolding_discrete_emotional_responses_to_different_pedagogical_agents_scaffolding_strategies"},{"id":254035754,"url":"https://www.researchgate.net/publication/254035754_Feature_extraction_for_facial_expression_recognition_by_canonical_correlation_analysis"},{"id":220603882,"url":"https://www.researchgate.net/publication/220603882_Pain_monitoring_A_dynamic_and_context-sensitive_system"},{"id":224256697,"url":"https://www.researchgate.net/publication/224256697_The_Role_of_Nonlinear_Dynamics_in_Affective_Valence_and_Arousal_Recognition"},{"id":227187768,"url":"https://www.researchgate.net/publication/227187768_Special_issue_on_real-time_affect_analysis_and_interpretation_Closing_the_affective_loop_in_virtual_agents_and_robots"},{"id":262270860,"url":"https://www.researchgate.net/publication/262270860_Facial_expression_recognition_for_detecting_human_aggression"},{"id":254056953,"url":"https://www.researchgate.net/publication/254056953_Spatiotemporal_Local_Monogenic_Binary_Patterns_for_Facial_Expression_Recognition"},{"id":262288655,"url":"https://www.researchgate.net/publication/262288655_Video-driven_state-aware_facial_animation"},{"id":254041098,"url":"https://www.researchgate.net/publication/254041098_Real-time_emotion_identification_for_socially_intelligent_robots"},{"id":261229129,"url":"https://www.researchgate.net/publication/261229129_Human_emotion_recognition_using_a_deformable_3D_facial_expression_model"},{"id":224938998,"url":"https://www.researchgate.net/publication/224938998_Recognizing_Emotions_From_an_Ensemble_of_Features"},{"id":254004425,"url":"https://www.researchgate.net/publication/254004425_Understanding_communicative_emotions_from_collective_external_observations"},{"id":225042550,"url":"https://www.researchgate.net/publication/225042550_Facial_Action_Recognition_Combining_Heterogeneous_Features_via_Multi-Kernel_Learning"},{"id":235899186,"url":"https://www.researchgate.net/publication/235899186_Semi-supervised_context_adaptation_Case_study_of_audience_excitement_recognition"},{"id":261087088,"url":"https://www.researchgate.net/publication/261087088_Measuring_human_comprehension_from_nonverbal_behaviour_using_Artificial_Neural_Networks"},{"id":254059343,"url":"https://www.researchgate.net/publication/254059343_Kernel_Cross-Modal_Factor_Analysis_for_Information_Fusion_With_Application_to_Bimodal_Emotion_Recognition"},{"id":277892570,"url":"https://www.researchgate.net/publication/277892570_Facial_Expression_Recognition_from_Infrared_Thermal_Videos"},{"id":263636874,"url":"https://www.researchgate.net/publication/263636874_Emotion_Recognition_using_Facial_Thermal_Images"},{"id":260658405,"url":"https://www.researchgate.net/publication/260658405_Detecting_Naturalistic_Expressions_of_Nonbasic_Affect_Using_Physiological_Signals"},{"id":262271899,"url":"https://www.researchgate.net/publication/262271899_Automatic_Detection_of_Unconscious_Reactions_to_Illuminance_Changes_in_Illumination"},{"id":262326878,"url":"https://www.researchgate.net/publication/262326878_Computer_recognition_of_facial_expressions_of_emotion"},{"id":257014940,"url":"https://www.researchgate.net/publication/257014940_Automatic_facial_expression_recognition_based_on_spatiotemporal_descriptors"},{"id":277186551,"url":"https://www.researchgate.net/publication/277186551_Anaptyxe_Programmatistikes_Epharmoges_Gia_Ten_Ektimese_Tou_Synaisthematos_Apo_Ekphraseis_Prosopou_Se_Kare_Binteo"},{"id":236152929,"url":"https://www.researchgate.net/publication/236152929_Localized_discriminative_scale_invariant_feature_transform_based_facial_expression_recognition"},{"id":257351937,"url":"https://www.researchgate.net/publication/257351937_Learning_spatiotemporal_features_by_using_independent_component_analysis_with_application_to_facial_expression_recognition"},{"id":260664388,"url":"https://www.researchgate.net/publication/260664388_Adaptive_discriminative_metric_learning_for_facial_expression_recognition"},{"id":275769532,"url":"https://www.researchgate.net/publication/275769532_AUTOMATIC_AFFECT_DETECTION_FROM_PHYSIOLOGICAL_SIGNALS_PRACTICAL_ISSUES"},{"id":262169061,"url":"https://www.researchgate.net/publication/262169061_Facial_expression_recognition_using_geometric_and_appearance_features"},{"id":231743070,"url":"https://www.researchgate.net/publication/231743070_Using_Activity-Related_Behavioural_Features_towards_More_Effective_Automatic_Stress_Detection"},{"id":261503047,"url":"https://www.researchgate.net/publication/261503047_A_New_Invariant_Representation_of_Facial_Expressions_Definition_and_Application_to_Blended_Expression_Recognition"},{"id":260348142,"url":"https://www.researchgate.net/publication/260348142_Combining_Face_and_Eye_Detectors_in_a_High-_Performance_Face-Detection_System"},{"id":260658410,"url":"https://www.researchgate.net/publication/260658410_The_Good_Our_Field_Can_Hope_to_Do_the_Harm_It_Should_Avoid"},{"id":260658411,"url":"https://www.researchgate.net/publication/260658411_Crowdsourcing_Facial_Responses_to_Online_Videos"},{"id":235822473,"url":"https://www.researchgate.net/publication/235822473_Regulating_Emotion_by_Facial_Feedback_from_Teleoperated_Android_Robot"},{"id":257093278,"url":"https://www.researchgate.net/publication/257093278_3D4D_facial_expression_analysis_An_advanced_annotated_face_model_approach"},{"id":257093330,"url":"https://www.researchgate.net/publication/257093330_Exploring_the_effect_of_illumination_on_automatic_expression_recognition_using_the_ICT-3DRFE_database"},{"id":257014931,"url":"https://www.researchgate.net/publication/257014931_On_the_simultaneous_recognition_of_identity_and_expression_from_BU-3DFE_datasets"},{"id":271494277,"url":"https://www.researchgate.net/publication/271494277_Facial_expression_recognition_from_infrared_thermal_images_using_temperature_difference_by_voting"},{"id":262175864,"url":"https://www.researchgate.net/publication/262175864_Multi-view_Facial_Expression_Recognition_Analysis_with_Generic_Sparse_Coding_Feature"},{"id":262219671,"url":"https://www.researchgate.net/publication/262219671_Computing_and_Evaluating_the_Body_Laughter_Index"},{"id":262208440,"url":"https://www.researchgate.net/publication/262208440_Dynamic_Probabilistic_CCA_for_Analysis_of_Affective_Behaviour"},{"id":266652990,"url":"https://www.researchgate.net/publication/266652990_Consistent_but_modest_A_meta-analysis_on_unimodal_and_multimodal_affect_detection_accuracies_from_30_studies"},{"id":262389947,"url":"https://www.researchgate.net/publication/262389947_Multimodal_analysis_of_the_implicit_affective_channel_in_computer-mediated_textual_communication"},{"id":262330415,"url":"https://www.researchgate.net/publication/262330415_Towards_sensing_the_influence_of_visual_narratives_on_human_affect"},{"id":262360415,"url":"https://www.researchgate.net/publication/262360415_Depression_analysis_A_multimodal_approach"},{"id":263998810,"url":"https://www.researchgate.net/publication/263998810_Classification_and_Intensity_Assessment_of_Korean_Emotion_Expressing_Idioms_for_Human_Emotion_Recognition"},{"id":261272083,"url":"https://www.researchgate.net/publication/261272083_Bidirectional_warping_of_Active_Appearance_Model"},{"id":260584743,"url":"https://www.researchgate.net/publication/260584743_Non-linear_factorised_dynamic_shape_and_appearance_models_for_facial_expression_analysis_and_tracking"},{"id":262394106,"url":"https://www.researchgate.net/publication/262394106_Boosting_with_Side_Information"},{"id":262320400,"url":"https://www.researchgate.net/publication/262320400_Enhancing_Expression_Recognition_in_the_Wild_with_Unlabeled_Reference_Data"},{"id":262240084,"url":"https://www.researchgate.net/publication/262240084_Emotion_Recognition_Using_the_Emotiv_EPOC_Device"},{"id":233753130,"url":"https://www.researchgate.net/publication/233753130_Corpus_Development_for_Affective_Video_Indexing"},{"id":228071847,"url":"https://www.researchgate.net/publication/228071847_A_Vocal-Based_Analytical_Method_for_Goose_Behaviour_Recognition"},{"id":261082721,"url":"https://www.researchgate.net/publication/261082721_Multimodal_Information_Fusion_of_Audio_Emotion_Recognition_Based_on_Kernel_Entropy_Component_Analysis"},{"id":262775652,"url":"https://www.researchgate.net/publication/262775652_Facial_emotional_recognition_in_schizophrenia_Preliminary_results_of_the_Virtual_Reality_Program_for_Facial_Emotional_Recognition"},{"id":264048367,"url":"https://www.researchgate.net/publication/264048367_Proceedings_of_the_First_International_Conference_on_Advanced_Information_Technologies_Applications_ICAITA-2012_Dubai_UAE"},{"id":258769479,"url":"https://www.researchgate.net/publication/258769479_A_Dynamic_Approach_for_Detecting_Naturalistic_Affective_States_from_Facial_Videos_during_HCI"},{"id":223134705,"url":"https://www.researchgate.net/publication/223134705_Human_Behavior_Analysis_in_Video_Surveillance_a_Social_Signal_Processing_Perspective"},{"id":259512435,"url":"https://www.researchgate.net/publication/259512435_Facial_expression_recognition_experiments_with_data_from_television_broadcasts_and_the_World_Wide_Web"},{"id":256309236,"url":"https://www.researchgate.net/publication/256309236_Multi-Modal_Classifier-Fusion_for_the_Recognition_of_Emotions"},{"id":257597656,"url":"https://www.researchgate.net/publication/257597656_Using_speaker_group_dependent_modelling_to_improve_fusion_of_fragmentary_classifier_decisions"},{"id":260035604,"url":"https://www.researchgate.net/publication/260035604_Sequential_Emotion_Recognition_using_Latent-Dynamic_Conditional_Neural_Fields"},{"id":261056504,"url":"https://www.researchgate.net/publication/261056504_A_Turkish_audio-visual_emotional_database"},{"id":261319404,"url":"https://www.researchgate.net/publication/261319404_Nebula_feature_A_space-time_feature_for_posed_and_spontaneous_4D_facial_behavior_analysis"},{"id":261121555,"url":"https://www.researchgate.net/publication/261121555_A_facial_expression_based_continuous_emotional_state_monitoring_system_with_GPU_acceleration"},{"id":261121556,"url":"https://www.researchgate.net/publication/261121556_Analyzing_Perceived_Empathy_Based_on_Reaction_Time_in_Behavioral_Mimicry"},{"id":261115513,"url":"https://www.researchgate.net/publication/261115513_Improving_facial_expression_analysis_using_histograms_of_Log-Transformed_Nonnegative_Sparse_Representation_with_a_Spatial_Pyramid_Structure"},{"id":261160113,"url":"https://www.researchgate.net/publication/261160113_Detection_of_changes_in_human_affect_dimensions_using_an_Adaptive_Temporal_Topic_model"},{"id":261096919,"url":"https://www.researchgate.net/publication/261096919_A_probabilistic_fusion_strategy_for_audiovisual_emotion_recognition_of_sparse_and_noisy_data"},{"id":261480223,"url":"https://www.researchgate.net/publication/261480223_Affect-awareness_framework_for_intelligent_tutoring_systems"},{"id":256578825,"url":"https://www.researchgate.net/publication/256578825_Fusion_of_Fragmentary_Classifier_Decisions_for_Affective_State_Recognition"},{"id":261056631,"url":"https://www.researchgate.net/publication/261056631_A_method_for_extraction_of_affective_audio-visual_facial_clips_from_movies"},{"id":256575279,"url":"https://www.researchgate.net/publication/256575279_Finding_Happiest_Moments_in_a_Social_Context"},{"id":260480079,"url":"https://www.researchgate.net/publication/260480079_Crowdsourcing_facial_expressions_using_popular_gameplay"},{"id":261844033,"url":"https://www.researchgate.net/publication/261844033_Towards_affect_sensitive_and_socially_perceptive_companions"},{"id":235962485,"url":"https://www.researchgate.net/publication/235962485_A_Component_Based_Approach_for_Classifying_the_Seven_Universal_Facial_Expressions_of_Emotion"},{"id":260665240,"url":"https://www.researchgate.net/publication/260665240_A_Deformable_3-D_Facial_Expression_Model_for_Dynamic_Human_Emotional_State_Recognition"},{"id":261398290,"url":"https://www.researchgate.net/publication/261398290_A_comparative_analysis_of_facial_expression_recognition_techniques"},{"id":261273542,"url":"https://www.researchgate.net/publication/261273542_Internet_application_for_collective_realization_of_speech_evaluation_by_listening_tests"},{"id":236153240,"url":"https://www.researchgate.net/publication/236153240_Detecting_Boredom_and_Engagement_During_Writing_With_Keystroke_Analysis_Task_Appraisals_and_Stable_Traits"},{"id":261319544,"url":"https://www.researchgate.net/publication/261319544_Predicting_Online_Media_Effectiveness_Based_on_Smile_Responses_Gathered_Over_the_Internet"},{"id":261271700,"url":"https://www.researchgate.net/publication/261271700_Using_A_Probabilistic_Topic_Model_to_Link_Observers'_Perception_Tendency_to_Personality"},{"id":261264867,"url":"https://www.researchgate.net/publication/261264867_Continuous_Emotion_Recognition_Another_Look_at_the_Regression_Problem"},{"id":261265045,"url":"https://www.researchgate.net/publication/261265045_Facial_Expression_Recognition_Using_Deep_Boltzmann_Machine_from_Thermal_Infrared_Images"},{"id":261264968,"url":"https://www.researchgate.net/publication/261264968_EEG-Based_Emotion-Adaptive_Advertising"},{"id":261169954,"url":"https://www.researchgate.net/publication/261169954_Emotion_recognition_in_Romanian_language_using_LPC_features"},{"id":261115617,"url":"https://www.researchgate.net/publication/261115617_Transfer_learning_to_account_for_idiosyncrasy_in_face_and_body_expressions"},{"id":261117134,"url":"https://www.researchgate.net/publication/261117134_Geometrical_facial_modeling_for_emotion_recognition"},{"id":261052486,"url":"https://www.researchgate.net/publication/261052486_A_touch_based_affective_user_interface_for_smartphone"},{"id":261206965,"url":"https://www.researchgate.net/publication/261206965_Mouse_Trajectories_and_State_Anxiety_Feature_Selection_with_Random_Forest"},{"id":261083969,"url":"https://www.researchgate.net/publication/261083969_EVS_An_EEG-Video_Synchronization_System_Using_High_Performance_Counter"},{"id":261264964,"url":"https://www.researchgate.net/publication/261264964_Estimation_of_Attentiveness_of_People_Watching_TV_Based_on_Their_Emotional_Behaviors"},{"id":261492458,"url":"https://www.researchgate.net/publication/261492458_Facial_action_unit_prediction_under_partial_occlusion_based_on_Error_Weighted_Cross-Correlation_Model"},{"id":261121114,"url":"https://www.researchgate.net/publication/261121114_Recognizing_intensity_degrees_from_expressions_in_3D_facial_meshes"},{"id":261480224,"url":"https://www.researchgate.net/publication/261480224_A_review_of_emotion_recognition_methods_based_on_keystroke_dynamics_and_mouse_movements"},{"id":261240382,"url":"https://www.researchgate.net/publication/261240382_Combining_emotional_history_through_multimodal_fusion_methods"},{"id":261478438,"url":"https://www.researchgate.net/publication/261478438_Latent_Facial_Topics_for_affect_analysis"},{"id":278647372,"url":"https://www.researchgate.net/publication/278647372_Emotion-Aware_Recommender_Systems_-_A_Framework_and_a_Case_Study"},{"id":269558899,"url":"https://www.researchgate.net/publication/269558899_Sensing_of_Audience_Excitation_and_Boredom_Emotion_Based_on_the_Synchrony_of_Sitting_Body_Sway"},{"id":290110121,"url":"https://www.researchgate.net/publication/290110121_Highlight_Detection_in_Movie_Scenes_Through_Inter-users_Physiological_Linkage"},{"id":278696440,"url":"https://www.researchgate.net/publication/278696440_Towards_Emotion_Recognition_in_Human_Computer_Interaction"},{"id":290097131,"url":"https://www.researchgate.net/publication/290097131_A_dense_deformation_field_for_facial_expression_analysis_in_dynamic_sequences_of_3D_scans"},{"id":273262692,"url":"https://www.researchgate.net/publication/273262692_Speech_Emotion_Recognition_under_White_Noise"},{"id":235908000,"url":"https://www.researchgate.net/publication/235908000_Facial_emotional_classification_From_a_discrete_perspective_to_a_continuous_emotional_space"},{"id":262215758,"url":"https://www.researchgate.net/publication/262215758_Recognizing_expressions_from_face_and_body_gesture_by_temporal_normalized_motion_and_appearance_features"},{"id":257091783,"url":"https://www.researchgate.net/publication/257091783_Fusion_of_facial_expressions_and_EEG_for_implicit_affective_tagging"},{"id":257093335,"url":"https://www.researchgate.net/publication/257093335_Tracking_continuous_emotional_trends_of_participants_during_affective_dyadic_interactions_using_body_language_and_speech_information"},{"id":262161027,"url":"https://www.researchgate.net/publication/262161027_Drag_and_drop_the_apple_The_semantic_weight_of_words_and_images_in_touch-based_interaction"},{"id":261091824,"url":"https://www.researchgate.net/publication/261091824_LMA_based_emotional_motion_representation_using_RGB-D_camera"},{"id":257388636,"url":"https://www.researchgate.net/publication/257388636_Multimodal_affect_modeling_and_recognition_for_empathic_robot_companions_Int_J_Hum_Robotics_101"},{"id":262329960,"url":"https://www.researchgate.net/publication/262329960_A_comparative_study_of_user-defined_handheld_vs_freehand_gestures_for_home_entertainment_environments"},{"id":236080803,"url":"https://www.researchgate.net/publication/236080803_Simultaneous_Facial_Feature_Tracking_and_Facial_Expression_Recognition"},{"id":261495060,"url":"https://www.researchgate.net/publication/261495060_An_automatic_3D_expression_recognition_framework_based_on_sparse_representation_of_conformal_images"},{"id":262364211,"url":"https://www.researchgate.net/publication/262364211_Detecting_Facial_Expressions_for_Monitoring_Patterns_of_Emotional_Behavior"},{"id":261395138,"url":"https://www.researchgate.net/publication/261395138_FATHOMing_out_interdisciplinary_research_transfer"},{"id":234163748,"url":"https://www.researchgate.net/publication/234163748_Using_Trace_Data_to_Examine_the_Complex_Roles_of_Cognitive_Metacognitive_and_Emotional_Self-Regulatory_Processes_During_Learning_with_Multi-agent_Systems"},{"id":260658393,"url":"https://www.researchgate.net/publication/260658393_Data-Free_Prior_Model_for_Facial_Action_Unit_Recognition"},{"id":261121554,"url":"https://www.researchgate.net/publication/261121554_Margin-constrained_multiple_kernel_learning_based_multi-modal_fusion_for_affect_recognition"},{"id":261121296,"url":"https://www.researchgate.net/publication/261121296_Maximum_margin_GMM_learning_for_facial_expression_recognition"},{"id":272807618,"url":"https://www.researchgate.net/publication/272807618_Emotion_Recognition_System_by_a_Neural_Network_Based_Facial_Expression_Analysis"},{"id":259714804,"url":"https://www.researchgate.net/publication/259714804_Continuous_AU_Intensity_Estimation_using_Localized_Sparse_Facial_Feature_Space"},{"id":237148069,"url":"https://www.researchgate.net/publication/237148069_Affective_State_Level_Recognition_in_Naturalistic_Facial_and_Vocal_Expressions"},{"id":262401614,"url":"https://www.researchgate.net/publication/262401614_Beyond_the_basic_emotions_what_should_affective_computing_compute"},{"id":236152874,"url":"https://www.researchgate.net/publication/236152874_Towards_an_affect_sensitive_interactive_companion"},{"id":260304858,"url":"https://www.researchgate.net/publication/260304858_YouTube_Movie_Reviews_Sentiment_Analysis_in_an_Audio-Visual_Context"},{"id":260304857,"url":"https://www.researchgate.net/publication/260304857_Multimodal_Sentiment_Analysis_of_Spanish_Online_Videos"},{"id":255982791,"url":"https://www.researchgate.net/publication/255982791_Investigating_the_Form-Function-Relation_of_the_Discourse_Particle_hm_in_a_Naturalistic_Human-Computer_Interaction"},{"id":262310610,"url":"https://www.researchgate.net/publication/262310610_Thermal_imaging_for_affect_detection"},{"id":251571212,"url":"https://www.researchgate.net/publication/251571212_AffectButton_A_method_for_reliable_and_valid_affective_self-report"},{"id":257091799,"url":"https://www.researchgate.net/publication/257091799_A_review_of_motion_analysis_methods_for_human_Nonverbal_Communication_Computing"},{"id":261480000,"url":"https://www.researchgate.net/publication/261480000_FEEDB_A_multimodal_database_of_facial_expressions_and_emotions"},{"id":261259061,"url":"https://www.researchgate.net/publication/261259061_Capturing_Complex_Spatio-Temporal_Relations_among_Facial_Muscles_for_Facial_Expression_Recognition"},{"id":261523739,"url":"https://www.researchgate.net/publication/261523739_CS-3DLBP_and_geometry_based_person_independent_3D_facial_action_unit_detection"},{"id":263556026,"url":"https://www.researchgate.net/publication/263556026_Facial_emotion_recognition_towards_affective_computing-based_learning"},{"id":262905151,"url":"https://www.researchgate.net/publication/262905151_Inclusive_Personalized_e-Learning_Based_on_Affective_Adaptive_Support"},{"id":245252286,"url":"https://www.researchgate.net/publication/245252286_Modelling_Users'_Affect_in_Job_Interviews_Technological_Demo"},{"id":261199485,"url":"https://www.researchgate.net/publication/261199485_Learning_collaborative_decision-making_parameters_for_multimodal_emotion_recognition"},{"id":261045436,"url":"https://www.researchgate.net/publication/261045436_Facial_Expression_Recognition_Influenced_by_Human_Aging"},{"id":261432617,"url":"https://www.researchgate.net/publication/261432617_Audio-Visual_Emotion_Recognition_Using_Neural_Networks_Learned_with_Hints"},{"id":271738880,"url":"https://www.researchgate.net/publication/271738880_Recognition_of_emotions_from_video_using_acoustic_and_facial_features"},{"id":269327087,"url":"https://www.researchgate.net/publication/269327087_Inpatient_facial_expression_recognition_with_SMS_alert"},{"id":262905455,"url":"https://www.researchgate.net/publication/262905455_Emotions_Detection_from_Math_Exercises_by_Combining_Several_Data_Sources"},{"id":262425134,"url":"https://www.researchgate.net/publication/262425134_Challenges_for_Inclusive_Affective_Detection_in_Educational_Scenarios"},{"id":256578785,"url":"https://www.researchgate.net/publication/256578785_The_Influence_of_Context_Knowledge_for_Multi-modal_Affective_Annotation"},{"id":258023891,"url":"https://www.researchgate.net/publication/258023891_Gender-Driven_Emotion_Recognition_Through_Speech_Signals_For_Ambient_Intelligence_Applications"},{"id":256822757,"url":"https://www.researchgate.net/publication/256822757_Learning_realistic_facial_expressions_from_web_images"},{"id":261265916,"url":"https://www.researchgate.net/publication/261265916_Design_of_a_Mobile_Telephony_System_for_Social_Interaction"},{"id":261271488,"url":"https://www.researchgate.net/publication/261271488_Context_Based_Facial_Expression_Analysis_in_the_Wild"},{"id":261450647,"url":"https://www.researchgate.net/publication/261450647_Active_Labeling_of_Facial_Feature_Points"},{"id":261450646,"url":"https://www.researchgate.net/publication/261450646_Action_Unit_Models_of_Facial_Expression_of_Emotion_in_the_Presence_of_Speech"},{"id":269326270,"url":"https://www.researchgate.net/publication/269326270_Continuous_mobile_authentication_using_a_novel_Graphic_Touch_Gesture_Feature"},{"id":261264864,"url":"https://www.researchgate.net/publication/261264864_Automatically_Recognizing_Facial_Indicators_of_Frustration_A_Learning-Centric_Analysis"},{"id":261302498,"url":"https://www.researchgate.net/publication/261302498_Towards_Robust_Real-Time_Valence_Recognition_from_Facial_Expressions_for_Market_Research_Applications"},{"id":269327061,"url":"https://www.researchgate.net/publication/269327061_Multimodal_Engagement_Classification_for_Affective_Cinema"},{"id":261271487,"url":"https://www.researchgate.net/publication/261271487_An_Automated_Framework_for_Depression_Analysis"},{"id":256094499,"url":"https://www.researchgate.net/publication/256094499_Laughter_Type_Recognition_from_Whole_Body_Motion"},{"id":257652062,"url":"https://www.researchgate.net/publication/257652062_A_Job_Interview_Simulation_Social_Cue-Based_Interaction_with_a_Virtual_Character"},{"id":263973659,"url":"https://www.researchgate.net/publication/263973659_Internet_Application_for_Collective_Realization_of_Speech_Evaluation_by_Listening_Tests"},{"id":256763314,"url":"https://www.researchgate.net/publication/256763314_Speech_Emotional_Features_Extraction_Based_on_Electroglottograph"},{"id":260310843,"url":"https://www.researchgate.net/publication/260310843_Audio-Visual_Recognition_of_Goose_Flocking_Behavior"},{"id":257247374,"url":"https://www.researchgate.net/publication/257247374_Reading_People's_Minds_From_Emotion_Expressions_in_Interdependent_Decision_Making"},{"id":257405050,"url":"https://www.researchgate.net/publication/257405050_Intelligent_facial_emotion_recognition_and_semantic-based_topic_detection_for_a_humanoid_robot"},{"id":260946141,"url":"https://www.researchgate.net/publication/260946141_Body_Movements_for_Affective_Expression_A_Survey_of_Automatic_Recognition_and_Generation"},{"id":260945507,"url":"https://www.researchgate.net/publication/260945507_Component-Based_Recognition_of_Facesand_Facial_Expressions"},{"id":271657427,"url":"https://www.researchgate.net/publication/271657427_A_framework_for_implicit_human-centered_image_tagging_inspired_by_attributed_affect"},{"id":261208332,"url":"https://www.researchgate.net/publication/261208332_Emotion_recognition_from_multi-modal_information"},{"id":269332203,"url":"https://www.researchgate.net/publication/269332203_Detection_of_driver_visual_field_narrowing"},{"id":258255370,"url":"https://www.researchgate.net/publication/258255370_Unimodal_and_Multimodal_Human_Perception_of_Naturalistic_Non-Basic_Affective_States_during_Human-Computer_Interactions"},{"id":262202110,"url":"https://www.researchgate.net/publication/262202110_Intensity_Rank_Estimation_of_Facial_Expressions_Based_on_A_Single_Image"},{"id":258530276,"url":"https://www.researchgate.net/publication/258530276_HCI2_Framework_A_Software_Framework_for_Multimodal_Human-Computer_Interaction_Systems"},{"id":257067128,"url":"https://www.researchgate.net/publication/257067128_Audiovisual_Three-Level_Fusion_for_Continuous_Estimation_of_Russell's_Emotion_Circumplex"},{"id":257652279,"url":"https://www.researchgate.net/publication/257652279_NovA_Automated_Analysis_of_Nonverbal_Signals_in_Social_Interactions"},{"id":258038782,"url":"https://www.researchgate.net/publication/258038782_Tools_for_advancing_research_into_social_networks_and_cognitive_function_in_older_adults"},{"id":236960677,"url":"https://www.researchgate.net/publication/236960677_Induction_recording_and_recognition_of_natural_emotions_from_facial_expressions_and_speech_prosody"},{"id":258636276,"url":"https://www.researchgate.net/publication/258636276_A_Multimodal_Emotion_Detection_System_during_Human-Robot_Interaction"},{"id":259142595,"url":"https://www.researchgate.net/publication/259142595_Invariant_Representation_of_Facial_Expressions_for_Blended_Expression_Recognition_on_Unknown_Subjects"},{"id":260349469,"url":"https://www.researchgate.net/publication/260349469_Face_Expression_Recognition_by_Cross_Modal_Data_Association"},{"id":263372823,"url":"https://www.researchgate.net/publication/263372823_Imitating_Human_Emotions_with_Artificial_Facial_Expressions"},{"id":259932023,"url":"https://www.researchgate.net/publication/259932023_Multimodal_Assistive_Technologies_for_Depression_Diagnosis_and_Monitoring"},{"id":263936558,"url":"https://www.researchgate.net/publication/263936558_A_Selective_Meta-Analysis_on_the_Relative_Incidence_of_Discrete_Affective_States_During_Learning_With_Technology"},{"id":275603611,"url":"https://www.researchgate.net/publication/275603611_Multimodal_Affect_Recognition_Using_Boltzmann_Zippers"},{"id":280681332,"url":"https://www.researchgate.net/publication/280681332_Detection_of_emotions_from_video_in_non-controlled_environment"},{"id":262066494,"url":"https://www.researchgate.net/publication/262066494_A_Thermal_Facial_Emotion_Database_and_Its_Analysis"},{"id":230662368,"url":"https://www.researchgate.net/publication/230662368_Children's_Emotion_Recognition_from_Spontaneous_Speech_Using_a_Reduced_Set_of_Acoustic_and_Linguistic_Features"},{"id":258845267,"url":"https://www.researchgate.net/publication/258845267_Automatic_facial_expression_recognition_in_real-time_from_dynamic_sequences_of_3D_face_scans"},{"id":260350025,"url":"https://www.researchgate.net/publication/260350025_Two-Level_Hierarchical_Alignment_for_Semi-Coupled_HMM-Based_Audiovisual_Emotion_Recognition_With_Temporal_Course"},{"id":271481937,"url":"https://www.researchgate.net/publication/271481937_Extracting_Features_Using_Computational_Cerebellar_Model_for_Emotion_Classification"},{"id":262204118,"url":"https://www.researchgate.net/publication/262204118_Distribution-based_iterative_pairwise_classification_of_emotions_in_the_wild_using_LGBP-TOP"},{"id":262252843,"url":"https://www.researchgate.net/publication/262252843_Facing_reality_an_industrial_view_on_large_scale_use_of_facial_expression_analysis"},{"id":262156244,"url":"https://www.researchgate.net/publication/262156244_Why_is_facial_expression_analysis_in_the_wild_challenging"},{"id":259588928,"url":"https://www.researchgate.net/publication/259588928_Affective_Video_Retrieval_Violence_Detection_in_Hollywood_Movies_by_Large-Scale_Segmental_Feature_Extraction"},{"id":261017004,"url":"https://www.researchgate.net/publication/261017004_Estimation_of_Human_Emotions_Using_Thermal_Facial_Information"},{"id":261764545,"url":"https://www.researchgate.net/publication/261764545_Effective_and_precise_face_detection_based_on_both_grey-level_image_and_depth_map"},{"id":259973754,"url":"https://www.researchgate.net/publication/259973754_Exploring_Eye_Activity_as_an_Indication_of_Emotional_States_Using_an_Eye-Tracking_Sensor"},{"id":262904996,"url":"https://www.researchgate.net/publication/262904996_Recommender_Systems_for_Technology_Enhanced_Learning_Research_Trends_Applications"},{"id":259133418,"url":"https://www.researchgate.net/publication/259133418_Shape-based_modeling_of_the_fundamental_frequency_contour_for_emotion_detection_in_speech"},{"id":262150492,"url":"https://www.researchgate.net/publication/262150492_Multi-View_Facial_Expression_Recognition_Based_on_Group_Sparse_Reduced-Rank_Regression"},{"id":272018166,"url":"https://www.researchgate.net/publication/272018166_Max-margin_adaptive_model_for_complex_video_pattern_recognition"},{"id":262150528,"url":"https://www.researchgate.net/publication/262150528_Making_Tactile_Textures_with_Predefined_Affective_Properties"},{"id":278402796,"url":"https://www.researchgate.net/publication/278402796_Cooperative_Learning_and_its_Application_to_Emotion_Recognition_from_Speech"},{"id":262905261,"url":"https://www.researchgate.net/publication/262905261_An_Approach_for_an_Affective_Educational_Recommendation_Model"},{"id":278657479,"url":"https://www.researchgate.net/publication/278657479_Automatic_Analysis_of_Affective_States_Visual_Attention_Based_Approach"},{"id":289858761,"url":"https://www.researchgate.net/publication/289858761_Towards_smartphone-based_assessment_of_burnout"},{"id":259778752,"url":"https://www.researchgate.net/publication/259778752_Affect_Recognition_Using_Magnitude_Models_of_Motion"},{"id":257627757,"url":"https://www.researchgate.net/publication/257627757_STIMONT_a_core_ontology_for_multimedia_stimuli_description"},{"id":276087737,"url":"https://www.researchgate.net/publication/276087737_A_social_learning_formalism_for_learners_trying_to_figure_out_what_a_teacher_wants_them_to_do"},{"id":259011356,"url":"https://www.researchgate.net/publication/259011356_Inter-Rater_Reliability_for_Emotion_Annotation_in_Human-Computer_Interaction_--_Comparison_and_Methodological_Improvements"},{"id":259845643,"url":"https://www.researchgate.net/publication/259845643_Impaired_Decoding_of_Fear_and_Disgust_Predicts_Utilitarian_Moral_Judgment_in_Alcohol-Dependent_Individuals"},{"id":257435889,"url":"https://www.researchgate.net/publication/257435889_Audiovisual_emotion_recognition_using_ANOVA_feature_selection_method_and_multi-classifier_neural_networks"},{"id":259929938,"url":"https://www.researchgate.net/publication/259929938_Interpreting_Social_Cues_to_Generate_Credible_Affective_Reactions_of_Virtual_Job_Interviewers"},{"id":271917704,"url":"https://www.researchgate.net/publication/271917704_A_social_interaction_system_based_on_cloud_computing_for_mobile_video_telephony"},{"id":271547514,"url":"https://www.researchgate.net/publication/271547514_Gender_specific_emotion_recognition_through_speech_signals"},{"id":264051105,"url":"https://www.researchgate.net/publication/264051105_Anger_Effects_on_Driver_Situation_Awareness_and_Driving_Performance"},{"id":260226318,"url":"https://www.researchgate.net/publication/260226318_4D_Facial_Expression_Recognition_by_Learning_Geometric_Deformations"},{"id":264187953,"url":"https://www.researchgate.net/publication/264187953_Local_Feature_Based_Facial_Expression_Recognition_Using_Adaptive_Decision_Tree"},{"id":271916593,"url":"https://www.researchgate.net/publication/271916593_Recognizing_signals_of_social_attitude_in_interacting_with_Ambient_Conversational_Systems"},{"id":264348884,"url":"https://www.researchgate.net/publication/264348884_From_multimodal_analysis_to_real-time_interactions_with_virtual_agents"},{"id":271456386,"url":"https://www.researchgate.net/publication/271456386_Predicting_movie_ratings_from_audience_behaviors"},{"id":285405229,"url":"https://www.researchgate.net/publication/285405229_Emotion_in_Games"},{"id":260111893,"url":"https://www.researchgate.net/publication/260111893_Spectral_embedding_based_facial_expression_recognition_with_multiple_features"},{"id":265163053,"url":"https://www.researchgate.net/publication/265163053_Emotional_Facial_Expressions_Eye_Behaviors_Lips_Synchronization_Current_and_Future_Direction"},{"id":259636838,"url":"https://www.researchgate.net/publication/259636838_Recognizing_Emotional_Body_Language_Displayed_by_a_Human-like_Social_Robot"},{"id":264387505,"url":"https://www.researchgate.net/publication/264387505_Fully_Automated_Recognition_of_Spontaneous_Facial_Expressions_in_Videos_Using_Random_Forest_Classifiers"},{"id":264387207,"url":"https://www.researchgate.net/publication/264387207_Interpersonal_Coordination_of_HeadMotion_in_Distressed_Couples"},{"id":264387384,"url":"https://www.researchgate.net/publication/264387384_Linking_Recognition_Accuracy_and_User_Experience_in_an_Affective_Feedback_Loop"},{"id":271741588,"url":"https://www.researchgate.net/publication/271741588_Fusion_of_visible_and_thermal_images_for_facial_expression_recognition"},{"id":271834118,"url":"https://www.researchgate.net/publication/271834118_Observational_approaches_to_the_measurement_of_emotions"},{"id":276091649,"url":"https://www.researchgate.net/publication/276091649_A_Methodology_for_Recognition_of_Emotions_Based_on_Speech_Analysis_for_Applications_to_Human-Robot_Interaction_An_Exploratory_Study"},{"id":261673217,"url":"https://www.researchgate.net/publication/261673217_Virtual_Reflexes"},{"id":263518292,"url":"https://www.researchgate.net/publication/263518292_Thermal_spatio-temporal_data_for_stress_recognition"},{"id":260031850,"url":"https://www.researchgate.net/publication/260031850_Spontaneous_facial_expression_recognition_A_robust_metric_learning_approach"},{"id":262023935,"url":"https://www.researchgate.net/publication/262023935_Muecas_A_Multi-Sensor_Robotic_Head_for_Affective_Human_Robot_Interaction_and_Imitation"},{"id":262196356,"url":"https://www.researchgate.net/publication/262196356_Effects_of_specific_emotions_on_subjective_judgment_driving_performance_and_perceived_workload"},{"id":269295473,"url":"https://www.researchgate.net/publication/269295473_Automatic_inference_of_mental_states_from_spontaneous_facial_expressions"},{"id":269295038,"url":"https://www.researchgate.net/publication/269295038_Robust_Canonical_Correlation_Analysis_Audio-visual_fusion_for_learning_continuous_interest"},{"id":271472389,"url":"https://www.researchgate.net/publication/271472389_An_i-vector_based_descriptor_for_alphabetical_gesture_recognition"},{"id":263408986,"url":"https://www.researchgate.net/publication/263408986_Evaluating_the_Research_in_Automatic_Emotion_Recognition"},{"id":262292704,"url":"https://www.researchgate.net/publication/262292704_BAUM-2_A_Multilingual_Audio-Visual_Affective_Face_Database"},{"id":262375227,"url":"https://www.researchgate.net/publication/262375227_Towards_Multimodal_Emotion_Recognition_in_e-Learning_Environments"},{"id":262926540,"url":"https://www.researchgate.net/publication/262926540_EEG-based_classification_of_positive_and_negative_affective_states"},{"id":262017391,"url":"https://www.researchgate.net/publication/262017391_Physio-visual_data_fusion_for_emotion_recognition"},{"id":268513538,"url":"https://www.researchgate.net/publication/268513538_Comparative_learning_applied_to_intensity_rating_of_facial_expressions_of_pain"},{"id":272483822,"url":"https://www.researchgate.net/publication/272483822_Affect_detection_from_non-stationary_physiological_data_using_ensemble_classifiers"},{"id":285926346,"url":"https://www.researchgate.net/publication/285926346_It's_Written_on_Your_Face_Detecting_Affective_States_from_Facial_Expressions_while_Learning_Computer_Programming"},{"id":275963065,"url":"https://www.researchgate.net/publication/275963065_Multimodal_Interfaces_and_Sensory_Fusion_in_VR_for_Social_Interactions"},{"id":269762862,"url":"https://www.researchgate.net/publication/269762862_MULTIMODAL_SENTIMENTS_ANALYSES_OF_FINANCIAL_NEWS_-_A_PROJECT_OUTLINE"},{"id":273397463,"url":"https://www.researchgate.net/publication/273397463_An_Automatic_Framework_for_Textured_3D_Video-Based_Facial_Expression_Recognition"},{"id":273393167,"url":"https://www.researchgate.net/publication/273393167_Intra-Class_Variation_Reduction_Using_Training_Expression_Images_for_Sparse_Representation_Based_Facial_Expression_Recognition"},{"id":263743208,"url":"https://www.researchgate.net/publication/263743208_Adaptive_Cognitive_Technical_Systems"},{"id":263723593,"url":"https://www.researchgate.net/publication/263723593_Human_Emotion_Estimation_Using_Wavelet_Transform_and_t-ROIs_for_Fusion_of_Visible_Images_and_Thermal_Image_Sequences"},{"id":261552087,"url":"https://www.researchgate.net/publication/261552087_Who's_afraid_of_job_interviews_Definitely_a_Question_for_User_Modelling"},{"id":272040406,"url":"https://www.researchgate.net/publication/272040406_User_behavior_fusion_in_dialog_management_with_multi-modal_history_cues"},{"id":261998509,"url":"https://www.researchgate.net/publication/261998509_Computer_analysis_of_face_beauty_A_survey"},{"id":262073398,"url":"https://www.researchgate.net/publication/262073398_Head_movement_and_facial_expressions_as_game_input_EntertainComput"},{"id":265592622,"url":"https://www.researchgate.net/publication/265592622_Magic_Mirror_in_my_Hand_what_is_the_Sentiment_in_the_Lens_an_Action_Unit_based_Approach_for_Mining_Sentiments_from_Multimedia_Contents"},{"id":263390802,"url":"https://www.researchgate.net/publication/263390802_Supervised_super-vector_encoding_for_facial_expression_recognition_Pattern_Recogn_Lett"},{"id":261123173,"url":"https://www.researchgate.net/publication/261123173_Combination_of_sequential_class_distributions_from_multiple_channels_using_Markov_fusion_networks"},{"id":279955331,"url":"https://www.researchgate.net/publication/279955331_Joint_Unsupervised_Face_Alignment_and_Behaviour_Analysis"},{"id":283296874,"url":"https://www.researchgate.net/publication/283296874_Remarks_on_Computational_Facial_Expression_Recognition_from_HOG_Features_Using_Quaternion_Multi-layer_Neural_Network"},{"id":286930692,"url":"https://www.researchgate.net/publication/286930692_Feature_Disentangling_Machine_-A_Novel_Approach_of_Feature_Selection_and_Disentangling_in_Facial_Expression_Analysis"},{"id":265383672,"url":"https://www.researchgate.net/publication/265383672_The_Body_Action_Coding_System_II_Muscle_activations_during_the_perception_and_expression_of_emotion"},{"id":262227036,"url":"https://www.researchgate.net/publication/262227036_Exploiting_Multi-expression_Dependences_for_Implicit_Multi-Emotion_Video_Tagging"},{"id":263012830,"url":"https://www.researchgate.net/publication/263012830_A_survey_on_still_image_based_human_action_recognition"},{"id":259992076,"url":"https://www.researchgate.net/publication/259992076_Automatic_Measurement_of_Ad_Preferences_from_Facial_Responses_Gathered_Over_the_Internet"},{"id":266672947,"url":"https://www.researchgate.net/publication/266672947_Estimating_smile_intensity_A_better_way"},{"id":266909281,"url":"https://www.researchgate.net/publication/266909281_New_Measures_of_Mental_State_and_Behavior_Based_on_Data_Collected_From_Sensors_Smartphones_and_the_Internet"},{"id":267044757,"url":"https://www.researchgate.net/publication/267044757_Erratum_to_Development_of_an_auditory_emotion_recognition_function_using_psychoacoustic_parameters_based_on_the_International_Affective_Digitized_Sounds"},{"id":267743166,"url":"https://www.researchgate.net/publication/267743166_Temporal_Bayesian_Fusion_for_Affect_Sensing_Combining_Video_Audio_and_Lexical_Modalities"},{"id":265911260,"url":"https://www.researchgate.net/publication/265911260_Facial_expression_recognition_using_bag_of_distances"},{"id":271742737,"url":"https://www.researchgate.net/publication/271742737_A_Robot_Learns_the_Facial_Expressions_Recognition_and_FaceNon-face_Discrimination_Through_an_Imitation_Game"},{"id":266205891,"url":"https://www.researchgate.net/publication/266205891_Mobile_User_Authentication_Using_Statistical_Touch_Dynamics_Images"},{"id":278136138,"url":"https://www.researchgate.net/publication/278136138_Facial_expression_recognition_based_on_two-stage_features_extraction"},{"id":280266205,"url":"https://www.researchgate.net/publication/280266205_Recognizing_affect_in_human_touch_of_a_robot"},{"id":268074380,"url":"https://www.researchgate.net/publication/268074380_Multimodal_Affect_Recognition_for_Naturalistic_Human-Computer_and_Human-Robot_Interactions"},{"id":271328911,"url":"https://www.researchgate.net/publication/271328911_Fusion_of_Visible_Images_and_Thermal_Image_Sequences_for_Automated_Facial_Emotion_Estimation"},{"id":269115800,"url":"https://www.researchgate.net/publication/269115800_Discriminative_Shared_Gaussian_Processes_for_Multiview_and_View-Invariant_Facial_Expression_Recognition"},{"id":265170506,"url":"https://www.researchgate.net/publication/265170506_Random_Gabor_based_templates_for_facial_expression_recognition_in_images_with_facial_occlusion"},{"id":265337944,"url":"https://www.researchgate.net/publication/265337944_Log-Normal_and_Log-Gabor_descriptors_for_expressive_events_detection_and_facial_features_segmentation"},{"id":265035288,"url":"https://www.researchgate.net/publication/265035288_Investigation_of_Speaker_Group-Dependent_Modelling_for_Recognition_of_Affective_States_from_Speech"},{"id":272924844,"url":"https://www.researchgate.net/publication/272924844_Emotion_Monitoring_-_Verification_of_Physiological_Characteristics_Measurement_Procedures"},{"id":266561641,"url":"https://www.researchgate.net/publication/266561641_Representation_of_Facial_Expression_Categories_in_Continuous_Arousal-Valence_Space_Feature_and_Correlation"},{"id":278652248,"url":"https://www.researchgate.net/publication/278652248_Minotaurus_A_System_for_Affective_Human-Robot_Interaction_in_Smart_Environments"},{"id":273394198,"url":"https://www.researchgate.net/publication/273394198_Learning_Salient_Features_for_Speech_Emotion_Recognition_Using_Convolutional_Neural_Networks"},{"id":273393917,"url":"https://www.researchgate.net/publication/273393917_Learning_Race_from_Face_A_Survey"},{"id":286377274,"url":"https://www.researchgate.net/publication/286377274_Cascaded_Fusion_of_Dynamic_Spatial_and_Textural_Feature_Sets_for_Person-Independent_Facial_Emotion_Recognition"},{"id":286540247,"url":"https://www.researchgate.net/publication/286540247_Simultaneous_Detection_of_Multiple_Facial_Action_Units_via_Hierarchical_Task_Structure_Learning"},{"id":288386075,"url":"https://www.researchgate.net/publication/288386075_Extracting_and_Visualizing_Research_Impact_Semantics"},{"id":259580097,"url":"https://www.researchgate.net/publication/259580097_Analysis_of_significant_dialog_events_in_realistic_human-computer_interaction"},{"id":286280677,"url":"https://www.researchgate.net/publication/286280677_A_system_for_feature_classification_of_emotions_based_on_speech_analysis_Applications_to_human-robot_interaction"},{"id":275537298,"url":"https://www.researchgate.net/publication/275537298_Investigating_Context_Awareness_of_Affective_Computing_Systems_A_Critical_Approach"},{"id":275541623,"url":"https://www.researchgate.net/publication/275541623_Speech_Emotion_Recognition_in_Acted_and_Spontaneous_Context"},{"id":271470987,"url":"https://www.researchgate.net/publication/271470987_Selection_of_the_most_relevant_physiological_features_for_classifying_emotion"},{"id":273392605,"url":"https://www.researchgate.net/publication/273392605_Electrical_Impedance_Tomography_for_Artificial_Sensitive_Robotic_Skin_A_Review"},{"id":277551354,"url":"https://www.researchgate.net/publication/277551354_Affective_States_Asessment_System_Based_on_Heart_Rate_and_Facial_Expressions_Using_LabVIEW"},{"id":274255043,"url":"https://www.researchgate.net/publication/274255043_Disposition_Recognition_from_Spontaneous_Speech_Towards_a_Combination_with_Co-speech_Gestures"},{"id":281687239,"url":"https://www.researchgate.net/publication/281687239_Bimodal_human_emotion_classification_in_the_Speaker-Dependent_scenario"},{"id":282284437,"url":"https://www.researchgate.net/publication/282284437_An_extensible_platform_for_seamless_integration_and_management_of_applications_for_emotion_sensing_and_interpretation"},{"id":270650448,"url":"https://www.researchgate.net/publication/270650448_Gaze_direction_estimation_by_component_separation_for_recognition_of_Eye_Accessing_Cues"},{"id":271503291,"url":"https://www.researchgate.net/publication/271503291_7_Def_and_applications"},{"id":271503300,"url":"https://www.researchgate.net/publication/271503300_15"},{"id":282289390,"url":"https://www.researchgate.net/publication/282289390_Facial_grid_transformation_A_novel_face_registration_approach_for_improving_facial_action_unit_recognition"},{"id":282382645,"url":"https://www.researchgate.net/publication/282382645_Efficient_recognition_of_human_emotional_states_from_audio_signals"},{"id":272183841,"url":"https://www.researchgate.net/publication/272183841_BODILY_EXPRESSION_FOR_AUTOMATIC_AFFECT_RECOGNITION"},{"id":273514012,"url":"https://www.researchgate.net/publication/273514012_A_Review_and_Meta-Analysis_of_Multimodal_Affect_Detection_Systems"},{"id":276830509,"url":"https://www.researchgate.net/publication/276830509_Towards_robust_automatic_affective_classification_of_images_using_facial_expressions_for_practical_applications"},{"id":274091796,"url":"https://www.researchgate.net/publication/274091796_Multi-Layer_Sparse_Representation_for_Weighted_LBP-Patches_Based_Facial_Expression_Recognition"},{"id":276907567,"url":"https://www.researchgate.net/publication/276907567_Effects_of_cultural_characteristics_on_building_an_emotion_classifier_through_facial_expression_analysis"},{"id":273399576,"url":"https://www.researchgate.net/publication/273399576_Affective_experience_modeling_based_on_interactive_synergetic_dependence_in_big_data"},{"id":273695654,"url":"https://www.researchgate.net/publication/273695654_Face_Recognition_Using_Fuzzy_Clustering_and_Kernel_Least_Square"},{"id":274094896,"url":"https://www.researchgate.net/publication/274094896_Pain_Intensity_Estimation_by_a_Self--Taught_Selection_of_Histograms_of_Topographical_Features"},{"id":271723093,"url":"https://www.researchgate.net/publication/271723093_Perception_and_Automatic_Recognition_of_Laughter_from_Whole-Body_Motion_Continuous_and_Categorical_Perspectives"},{"id":276120298,"url":"https://www.researchgate.net/publication/276120298_Using_Kinect_for_real-time_emotion_recognition_via_facial_expressions"},{"id":274721882,"url":"https://www.researchgate.net/publication/274721882_Intensity_Estimation_of_Spontaneous_Facial_Action_Units_Based_on_Their_Sparsity_Properties"},{"id":274966969,"url":"https://www.researchgate.net/publication/274966969_Neutral_Face_Classification_Using_Personalized_Appearance_Models_for_Fast_and_Robust_Emotion_Detection"},{"id":275038833,"url":"https://www.researchgate.net/publication/275038833_Towards_Real-time_Speech_Emotion_Recognition_for_Affective_E-learning"},{"id":275051361,"url":"https://www.researchgate.net/publication/275051361_Learning_Sample_Specific_Weights_for_Late_Fusion"},{"id":275038937,"url":"https://www.researchgate.net/publication/275038937_101007_s10639-015-9388-2"},{"id":275355521,"url":"https://www.researchgate.net/publication/275355521_Time-Delay_Neural_Network_for_Continuous_Emotional_Dimension_Prediction_From_Facial_Expression_Sequences"},{"id":276113061,"url":"https://www.researchgate.net/publication/276113061_Facial_expression_recognition_using_lp-norm_MKL_multiclass-SVM"},{"id":279059115,"url":"https://www.researchgate.net/publication/279059115_Inference_of_Personality_Traits_and_Affect_Schedule_by_Analysis_of_Spontaneous_Reactions_to_Affective_Videos"},{"id":272494021,"url":"https://www.researchgate.net/publication/272494021_How_much_training_data_for_facial_action_unit_detection"},{"id":271702262,"url":"https://www.researchgate.net/publication/271702262_Action_Unit_Intensity_Estimation_using_Hierarchical_Partial_Least_Squares"},{"id":272684111,"url":"https://www.researchgate.net/publication/272684111_Robots_in_assisted_living_environments_as_an_unobtrusive_efficient_reliable_and_modular_solution_for_independent_ageing_The_RADIO_perspective"},{"id":277414638,"url":"https://www.researchgate.net/publication/277414638_Automatic_facial_attribute_analysis_via_adaptive_sparse_representation_of_random_patches"},{"id":273144119,"url":"https://www.researchgate.net/publication/273144119_Sentiment_Analysis_in_monitoring_software_development_processes_An_exploratory_case_study_on_GitHub's_project_issues"},{"id":273352695,"url":"https://www.researchgate.net/publication/273352695_Multi-label_learning_with_prior_knowledge_for_facial_expression_analysis"},{"id":277963057,"url":"https://www.researchgate.net/publication/277963057_Adaptive_Wavelet_Packet_Filter-Bank_Based_Acoustic_Feature_for_Speech_Emotion_Recognition"},{"id":277671577,"url":"https://www.researchgate.net/publication/277671577_The_digital_stress_coach_Total_control_over_your_mental_health_or_'Big_Brother_is_watching_you'"},{"id":277612342,"url":"https://www.researchgate.net/publication/277612342_Affective_States_Asessment_System_Based_on_Heart_Rate_and_Facial_Expressions_Using_LabVIEW"},{"id":279202364,"url":"https://www.researchgate.net/publication/279202364_Sensor-Free_or_Sensor-Full_A_Comparison_of_Data_Modalities_in_Multi-Channel_Affect_Detection"},{"id":281316619,"url":"https://www.researchgate.net/publication/281316619_Hidden_Markov_Model_Decision_Forest_for_Dynamic_Facial_Expression_Recognition"},{"id":282562283,"url":"https://www.researchgate.net/publication/282562283_An_Efficient_Multimodal_2D_3D_Feature-based_Approach_to_Automatic_Facial_Expression_Recognition"},{"id":282917944,"url":"https://www.researchgate.net/publication/282917944_Predicting_Ad_Liking_and_Purchase_Intent_Large-Scale_Analysis_of_Facial_Responses_to_Ads"},{"id":275059369,"url":"https://www.researchgate.net/publication/275059369_AU-inspired_Deep_Networks_for_Facial_Expression_Feature_Learning"},{"id":281943993,"url":"https://www.researchgate.net/publication/281943993_An_investigation_on_the_serendipity_problem_in_recommender_systems"},{"id":280098467,"url":"https://www.researchgate.net/publication/280098467_Learning_Appearance_Features_for_Pain_Detection_Using_the_UNBC-McMaster_Shoulder_Pain_Expression_Archive_Database"},{"id":283825994,"url":"https://www.researchgate.net/publication/283825994_Cross-cultural_detection_of_depression_from_nonverbal_behaviour"},{"id":280628637,"url":"https://www.researchgate.net/publication/280628637_Adaptive_Facial_Point_Detection_and_Emotion_Recognition_for_a_Humanoid_Robot"},{"id":280968897,"url":"https://www.researchgate.net/publication/280968897_Reliable_Emotion_Recognition_System_Based_on_Dynamic_Adaptive_Fusion_of_Forehead_Biopotentials_and_Physiological_Signals"},{"id":276535776,"url":"https://www.researchgate.net/publication/276535776_Automatic_Interpretation_of_Affective_Facial_Expressions_in_the_Context_of_Interpersonal_Interaction"},{"id":281610214,"url":"https://www.researchgate.net/publication/281610214_A_Review_on_the_Role_of_Color_and_Light_in_Affective_Computing"},{"id":281349511,"url":"https://www.researchgate.net/publication/281349511_Sociable_Dining_Table_Meaning_Acquisition_Exploration_in_Knock-Based_Proto-Communication"},{"id":281776639,"url":"https://www.researchgate.net/publication/281776639_Sociable_Dining_Table_Meaning_Acquisition_Exploration_in_Knock-Based_Proto-Communication"},{"id":282150145,"url":"https://www.researchgate.net/publication/282150145_RehabConnex_-_A_Middleware_for_the_Flexible_Connection_of_Multimodal_Game_Applications_with_Input_Devices_used_in_Movement_Therapy_and_Physical_Exercising"},{"id":281457299,"url":"https://www.researchgate.net/publication/281457299_Design_for_Mood_Twenty_Activity-Based_Opportunities_to_Design_for_Mood_Regulation"},{"id":283195826,"url":"https://www.researchgate.net/publication/283195826_Task-dependent_multi-task_multiple_kernel_learning_for_facial_action_unit_detection"},{"id":281145108,"url":"https://www.researchgate.net/publication/281145108_Audiovisual_Fusion_Challenges_and_New_Approaches"},{"id":286623141,"url":"https://www.researchgate.net/publication/286623141_Potential_clinical_impact_of_positive_affect_in_robot_interactions_for_autism_intervention"},{"id":282008384,"url":"https://www.researchgate.net/publication/282008384_What_Else_Does_Your_Biometric_Data_Reveal_A_Survey_on_Soft_Biometrics"},{"id":283516956,"url":"https://www.researchgate.net/publication/283516956_Towards_Incorporating_Affective_Feedback_into_Context-Aware_Intelligent_Environments"},{"id":283941170,"url":"https://www.researchgate.net/publication/283941170_Multimodal_emotion_recognition_based_on_peak_frame_selection_from_video"},{"id":273308875,"url":"https://www.researchgate.net/publication/273308875_Spatiotemporal_Directional_Number_Transitional_Graph_for_Dynamic_Texture_Recognition"},{"id":283186667,"url":"https://www.researchgate.net/publication/283186667_Affect_control_processes_Intelligent_affective_interaction_using_a_partially_observable_Markov_decision_process"},{"id":282979271,"url":"https://www.researchgate.net/publication/282979271_A_Short_Introduction_To_Laughter"},{"id":283295563,"url":"https://www.researchgate.net/publication/283295563_Assessment_of_Pain_Using_Facial_Pictures_Taken_with_a_Smartphone"},{"id":283904627,"url":"https://www.researchgate.net/publication/283904627_Eye_movements_reveal_epistemic_curiosity_in_human_observers"},{"id":279418989,"url":"https://www.researchgate.net/publication/279418989_Oudjat_A_Configurable_and_Usable_Annotation_Tool_for_the_Study_of_Facial_Expressions_of_Emotion"},{"id":284086510,"url":"https://www.researchgate.net/publication/284086510_Analysis_of_Physiological_for_Emotion_Recognition_with_IRS_Model"},{"id":282922857,"url":"https://www.researchgate.net/publication/282922857_3D_Dynamic_Facial_Expression_Recognition_using_Low-Resolution_Videos"},{"id":283854672,"url":"https://www.researchgate.net/publication/283854672_3D_Dynamic_Facial_Sequences_Analysis_for_Face_Recognition_and_Emotion_Detection"},{"id":283492766,"url":"https://www.researchgate.net/publication/283492766_Association_between_facial_expression_and_PTSD_symptoms_among_young_children_exposed_to_the_Great_East_Japan_Earthquake_A_pilot_study"},{"id":284126862,"url":"https://www.researchgate.net/publication/284126862_Video_modeling_and_learning_on_Riemannian_manifold_for_emotion_recognition_in_the_wild"},{"id":283904877,"url":"https://www.researchgate.net/publication/283904877_A_Review_of_Human_Activity_Recognition_Methods"},{"id":284219822,"url":"https://www.researchgate.net/publication/284219822_Learning_Expressionlets_via_Universal_Manifold_Model_for_Dynamic_Facial_Expression_Recognition"},{"id":284030512,"url":"https://www.researchgate.net/publication/284030512_curiosityEyeMovementVisResearch15"},{"id":284914327,"url":"https://www.researchgate.net/publication/284914327_Facial_expression_recognition_through_modeling_age-related_spatial_patterns"},{"id":288918785,"url":"https://www.researchgate.net/publication/288918785_Spontaneous_Micro-Expression_Spotting_via_Geometric_Deformation_Modeling"},{"id":285574092,"url":"https://www.researchgate.net/publication/285574092_Automatic_Measurement_of_Head_and_Facial_Movement_for_Analysis_and_Detection_of_Infants'_Positive_and_Negative_Affect"},{"id":283962644,"url":"https://www.researchgate.net/publication/283962644_Cross-cultural_Training_Analysis_Via_Social_Science_and_Computer_Vision_Methods"},{"id":284748706,"url":"https://www.researchgate.net/publication/284748706_Emotion_Recognition_in_Never-Seen_Languages_Using_a_Novel_Ensemble_Method_With_Emotion_Profiles"},{"id":283795983,"url":"https://www.researchgate.net/publication/283795983_Measuring_emotions_in_medical_education_Methodological_and_technological_advances_within_authentic_medical_learning_environments"},{"id":288617204,"url":"https://www.researchgate.net/publication/288617204_Emotion_recognition_in_the_wild_via_sparse_transductive_transfer_linear_discriminant_analysis"},{"id":290437637,"url":"https://www.researchgate.net/publication/290437637_Audio-visual_emotion_recognition_using_FCBF_feature_selection_method_and_particle_swarm_optimization_for_fuzzy_ARTMAP_neural_networks"}],"reference":["https://www.researchgate.net/publication/7795362_ASR_for_emotional_speech_Clarifying_the_issues_and_enhancing_performance","https://www.researchgate.net/publication/4119623_Real-Time_Inference_of_Complex_Mental_States_from_Facial_Expressions_and_Head_Gestures","https://www.researchgate.net/publication/4086923_Emotion_recognition_from_the_facial_image_and_speech_signal","https://www.researchgate.net/publication/232459835_Affective_judgment_and_psychophysiological_response_Dimensional_covariation_in_the_evaluation_of_pictorial_stimuli","https://www.researchgate.net/publication/3414026_Learning_From_Examples_in_the_Small_Sample_Case_Face_Expression_Recognition","https://www.researchgate.net/publication/224612458_Bimodal_fusion_of_emotional_data_in_an_automotive_environment","https://www.researchgate.net/publication/7779057_Emotion_recognition_through_facial_expression_analysis_based_on_a_neurofuzzy_network","https://www.researchgate.net/publication/221292140_Comprehensive_Database_for_Facial_Expression_Analysis","https://www.researchgate.net/publication/223776175_Automatic_prediction_of_frustration","https://www.researchgate.net/publication/232470231_Signs_of_Appeasement_Evidence_for_the_Distinct_Displays_of_Embarrassment_Amusement_and_Shame","https://www.researchgate.net/publication/3813462_Explanation-based_facial_motion_tracking_using_a_piecewise_Bezier_volume_deformation_model","https://www.researchgate.net/publication/221052266_Audio-visual_emotion_recognition_in_adult_attachment_interview","https://www.researchgate.net/publication/3424532_Audio-Visual_Affect_Recognition","https://www.researchgate.net/publication/7021128_Detection_of_Cough_Signals_in_Continuous_Audio_Recordings_Using_Hidden_Markov_Models","https://www.researchgate.net/publication/8153453_Semisupervised_learning_of_classifiers_theory_algorithms_and_their_application_to_human-computer_interaction_IEEE_Trans_Pattern_Anal_Mach_Intell","https://www.researchgate.net/publication/7864722_A_video_database_of_moving_faces_and_people","https://www.researchgate.net/publication/18528315_Emotions_and_Speech_Some_Acoustical_Correlates","https://www.researchgate.net/publication/8359228_The_Emotional_Integration_of_Childhood_Experience_Physiological_Facial_Expressive_and_Self-Reported_Emotional_Response_During_the_Adult_Attachment_Interview","https://www.researchgate.net/publication/6139644_Facial_Action_Unit_Recognition_by_Exploiting_Their_Dynamic_and_Semantic_Relationships","https://www.researchgate.net/publication/222430243_Manifold_based_analysis_of_facial_expression","https://www.researchgate.net/publication/2490611_Recognizing_Emotion_In_Speech","https://www.researchgate.net/publication/223460637_Combining_Pattern_Classifiers_Methods_and_Algorithms_Second_Edition","https://www.researchgate.net/publication/4210761_Affect_recognition_from_face_and_body_early_fusion_vs_late_fusion","https://www.researchgate.net/publication/227600768_Robust_full-motion_recovery_of_head_by_dynamic_templates_and_re-registration_techniques","https://www.researchgate.net/publication/225940935_Facial_Expression_Analysis","https://www.researchgate.net/publication/224641094_Combining_Prosodic_Lexical_and_Cepstral_Systems_for_Deceptive_Speech_Detection","https://www.researchgate.net/publication/221571403_Affective_multimodal_human-computer_interaction","https://www.researchgate.net/publication/220931898_Emotion_Recognition_Based_on_Joint_Visual_and_Audio_Cues","https://www.researchgate.net/publication/221052336_Audiovisual_recognition_of_spontaneous_interest_within_conversations","https://www.researchgate.net/publication/221052478_Analysis_of_emotion_recognition_using_facial_expressions_speech_and_multimodal_information","https://www.researchgate.net/publication/221052632_The_painful_face_-_Pain_expression_recognition_using_active_appearance_models","https://www.researchgate.net/publication/221292648_Fully_Automatic_Facial_Action_Recognition_in_Spontaneous_Behavior","https://www.researchgate.net/publication/234793141_The_Vocabulary_Problem_in_Human-System_Communication","https://www.researchgate.net/publication/224623338_Prosody_based_emotion_recognition_for_MEXI","https://www.researchgate.net/publication/222573706_Luettin_J_Automatic_Facial_Expression_Analysis_A_Survey_Pattern_Recognition_361_259-275","https://www.researchgate.net/publication/3334063_Toward_detecting_emotions_in_spoken_dialogs","https://www.researchgate.net/publication/10645218_Facial_expression_of_pain_An_evolutionary_account","https://www.researchgate.net/publication/220755932_Automatic_analysis_and_recognition_of_brow_actions_and_head_motion_in_spontaneous_facial_behavior","https://www.researchgate.net/publication/248036385_The_timing_of_facial_motion_in_posed_and_spontaneous_smiles","https://www.researchgate.net/publication/220816696_Predicting_Emotion_in_Spoken_Dialogue_from_Multiple_Knowledge_Sources","https://www.researchgate.net/publication/221506794_Facial_Expression_Analysis_Using_Nonlinear_Decomposable_Generative_Models","https://www.researchgate.net/publication/4136851_Meta-Classifiers_in_Acoustic_and_Linguistic_Feature_Fusion-Based_Affect_Recognition","https://www.researchgate.net/publication/228787343_'You_stupid_tin_box'_-_Children_interacting_with_the_AIBO_robot_A_cross-linguistic_emotional_speech_corpus","https://www.researchgate.net/publication/2567683_Prosody-Based_Automatic_Detection_Of_Annoyance_And_Frustration_In_Human-Computer_Dialog","https://www.researchgate.net/publication/222417696_The_Production_and_Recognition_of_Emotions_in_Speech_Features_and_Algorithms","https://www.researchgate.net/publication/221479033_Distinguishing_Deceptive_from_Non-Deceptive_Speech","https://www.researchgate.net/publication/23449457_Merging_of_the_Senses","https://www.researchgate.net/publication/221052262_How_to_distinguish_posed_from_spontaneous_smiles_using_geometric_features","https://www.researchgate.net/publication/221482489_Automatic_detection_of_laughter","https://www.researchgate.net/publication/2956285_Socially_Aware_Computation_and_Communication","https://www.researchgate.net/publication/221483179_Detecting_certainness_in_spoken_tutorial_dialogues","https://www.researchgate.net/publication/243763247_The_dictionary_of_affect_in_language","https://www.researchgate.net/publication/221483316_A_study_on_the_automatic_detection_and_characterization_of_emotion_in_a_voice_service_context","https://www.researchgate.net/publication/243773603_Measuring_facial_movement_with_the_facial_action_coding_system","https://www.researchgate.net/publication/238683820_Afiective_Computing","https://www.researchgate.net/publication/228953997_Prosody_and_emotions","https://www.researchgate.net/publication/243774437_Emotion_A_Psycho_Evolutionary_Synthesis","https://www.researchgate.net/publication/248224937_Universal_and_cultural_differences_in_facial_expression_of_emotion","https://www.researchgate.net/publication/247405097_Mother-Infant_Face-to-Face_Interaction_The_Sequence_of_Dyadic_States_at_3_6_and_9_Months","https://www.researchgate.net/publication/3745141_Multimodal_Human_emotionExpression_Recognition","https://www.researchgate.net/publication/209436093_Emotion_in_the_Human_Face","https://www.researchgate.net/publication/4246170_Robust_Real-Time_Face_Pose_and_Facial_Expression_Recovery","https://www.researchgate.net/publication/4246326_3D_Facial_Expression_Recognition_Based_on_Primitive_Surface_Feature_Distribution","https://www.researchgate.net/publication/244446385_Universals_and_Cultural_Differences_in_Facial_Expressions_of_Emotion","https://www.researchgate.net/publication/220654708_Affective_computing_-","https://www.researchgate.net/publication/228977440_Emotion_detection_from_infant_facial_expressions_and_cries","https://www.researchgate.net/publication/14687473_Facial_Expression_and_Emotion","https://www.researchgate.net/publication/4208241_Evaluation_of_natural_emotions_using_self_assessment_manikins","https://www.researchgate.net/publication/4038318_Facial_expression_decomposition","https://www.researchgate.net/publication/226199229_Real-Time_Inference_of_Complex_Mental_States_from_Facial_Expressions_and_Head_Gestures","https://www.researchgate.net/publication/229059871_Thin_Slices_of_Expressive_Behavior_as_Predictors_of_Interpersonal_Consequences_A_Meta-Analysis","https://www.researchgate.net/publication/3413899_Facial_Action_Recognition_for_Facial_Expression_Analysis_From_Static_Face_Images","https://www.researchgate.net/publication/224313060_Audiovisual_discrimination_between_laughter_and_speech","https://www.researchgate.net/publication/2605734_Comprehensive_Database_for_Facial_Expression_Analysis","https://www.researchgate.net/publication/226877512_Face_Databases","https://www.researchgate.net/publication/268239453_A_survey_of_affect_recognition_methods","https://www.researchgate.net/publication/221052396_Faces_of_pain_automated_measurement_of_spontaneous_facial_expressions_of_genuine_and_posed_pain","https://www.researchgate.net/publication/7819746_Emotion_recognition_in_human-computer_interaction","https://www.researchgate.net/publication/222149418_Multimodal_Human_Computer_Interaction_A_Survey","https://www.researchgate.net/publication/224265988_Recognizing_emotion_in_speech","https://www.researchgate.net/publication/42803843_Spontaneous_Emotional_Facial_Expression_Detection","https://www.researchgate.net/publication/7864712_Active_and_dynamic_information_fusion_for_facial_expression_understanding_from_image_sequences_IEEE_Trans_Pattern_Anal_Mach_Intell_PAMI","https://www.researchgate.net/publication/19758199_Watson_D_Clark_LA_Tellegen_A_Development_and_Validation_of_Brief_Measures_of_Positive_and_Negative_Affect_-_the_Panas_Scales_J_Pers_Soc_Psychol_54_1063-1070","https://www.researchgate.net/publication/220360699_Emotion_recognition_through_facial_expression_analysis_based_on_a_neurofuzzy_network","https://www.researchgate.net/publication/220929585_A_Bimodal_Face_and_Body_Gesture_Database_for_Automatic_Analysis_of_Human_Nonverbal_Affective_Behavior","https://www.researchgate.net/publication/266508208_What_the_Face_Reveals_Basic_and_Applied_Studies_of_Spontaneous_Expression_Using_the_Facial_Action_Coding_System_FACS","https://www.researchgate.net/publication/221292455_Haar_features_for_FACS_AU_recognition","https://www.researchgate.net/publication/233893880_Handbook_of_Emotion_Elicitation_and_Assessment","https://www.researchgate.net/publication/220955191_Audio-Visual_Spontaneous_Emotion_Recognition","https://www.researchgate.net/publication/6520512_Facial_Expression_Recognition_in_Image_Sequences_Using_Geometric_Deformation_Features_and_Support_Vector_Machines","https://www.researchgate.net/publication/221622089_Fusing_Face_and_Body_Display_for_Bi-modal_Emotion_Recognition_Single_Frame_Analysis_and_Multi-frame_Post_Integration","https://www.researchgate.net/publication/221264946_Audio-visual_affect_recognition_in_activation-evaluation_space","https://www.researchgate.net/publication/4082330_Audio-visual_based_emotion_recognition_-_a_new_approach","https://www.researchgate.net/publication/221488671_Emotion_recognition_using_a_data-driven_fuzzy_inference_system","https://www.researchgate.net/publication/224929651_Affect-Robust_Speech_Recognition_by_Dynamic_Emotional_Adaptation","https://www.researchgate.net/publication/234816618_Self-Cam_feedback_from_what_would_be_your_social_partner","https://www.researchgate.net/publication/221052154_Spontaneous_vs_posed_facial_behavior_Automatic_analysis_of_brow_actions","https://www.researchgate.net/publication/232585410_Facial_Expressions_of_Emotion","https://www.researchgate.net/publication/2262500_Efficient_Reinforcement_Learning","https://www.researchgate.net/publication/221571461_Training_combination_strategy_of_multi-stream_fused_hidden_Markov_model_for_audio-visual_affect_recognition","https://www.researchgate.net/publication/7749921_Challenges_in_real-life_emotion_annotation_and_machine_learning_based_detection","https://www.researchgate.net/publication/220874274_Predicting_Student_Emotions_in_Computer-Human_Tutoring_Dialogues","https://www.researchgate.net/publication/215835910_MAUI_A_multimodal_affective_user_interface","https://www.researchgate.net/publication/220120632_How_to_find_trouble_in_communication","https://www.researchgate.net/publication/4232829_A_3D_facial_expression_database_for_facial_behavior_research","https://www.researchgate.net/publication/243773817_The_New_Handbook_of_Methods_in_Nonverbal_Behavior_Research","https://www.researchgate.net/publication/221040267_Emotion_Analysis_in_Man-Machine_Interaction_Systems","https://www.researchgate.net/publication/3193199_Automatic_analysis_of_facial_expressions_the_state_of_the_art_IEEE_Trans_PAMI","https://www.researchgate.net/publication/228941240_Reliability_of_lexical_and_prosodic_cues_in_two_real-life_spoken_dialog_corpora","https://www.researchgate.net/publication/14353171_Acoustic_Profiles_in_Vocal_Emotion_Expression","https://www.researchgate.net/publication/4124631_Case-based_reasoning_for_user-profiled_recognition_of_emotions_from_face_images","https://www.researchgate.net/publication/4082376_Probabilistic_expression_analysis_on_manifolds","https://www.researchgate.net/publication/220955196_Gaze-X_Adaptive_Affective_Multimodal_Interface_for_Single-User_Office_Scenarios","https://www.researchgate.net/publication/7806486_2005_Special_Issue_A_systems_approach_to_appraisal_mechanisms_in_emotion","https://www.researchgate.net/publication/220955197_Modeling_Naturalistic_Affective_States_Via_Facial_Vocal_and_Bodily_Expressions_Recognition","https://www.researchgate.net/publication/3529543_The_Recognition_of_Basic_Facial_Expressions_by_Neural_Network","https://www.researchgate.net/publication/228863792_Of_all_things_the_measure_is_man_Automatic_classification_of_emotions_and_inter-labeler_consistency","https://www.researchgate.net/publication/230580794_Emotion_Recognition_in_Spontaneous_Speech_Using_GMMs","https://www.researchgate.net/publication/3845529_Comprehesive_database_for_facial_expression_analysis","https://www.researchgate.net/publication/4181246_Web-based_database_for_facial_expression_analysis","https://www.researchgate.net/publication/232616387_Recognizing_Facial_Expression_Machine_Learning_and_Application_to_Spontaneous_Behavior","https://www.researchgate.net/publication/221486752_Detection_of_real-life_emotions_in_call_centers","https://www.researchgate.net/publication/4076202_An_automated_face_reader_for_fatigue_detection","https://www.researchgate.net/publication/221318664_Latent_semantic_analysis_of_facial_action_codes_for_automatic_facial_expression_recognition","https://www.researchgate.net/publication/221110995_Capturing_Subtle_Facial_Motions_in_3D_Face_Tracking","https://www.researchgate.net/publication/242431684_Joint_processing_of_audio-visual_information_for_the_recognition_of_emotional_expressions_in_human-computer_interaction_PhD_thesis_UIUC","https://www.researchgate.net/publication/222669088_Authentic_Facial_Expression_Analysis","https://www.researchgate.net/publication/2986190_Toward_an_affect-sensitive_multimodal_human-computer_interaction","https://www.researchgate.net/publication/221480756_The_ISL_Meeting_Corpus_The_impact_of_meeting_type_on_speech_style","https://www.researchgate.net/publication/224612469_Recognizing_human_emotion_from_audiovisual_information","https://www.researchgate.net/publication/4156342_Audio-visual_affect_recognition_through_multi-stream_fused_HMM_for_HCI","https://www.researchgate.net/publication/221488147_Real-life_emotions_detection_with_lexical_and_paralinguistic_cues_on_human-human_call_center_dialogs","https://www.researchgate.net/publication/223009662_Automatic_recognition_and_analysis_of_human_faces_and_facial_expression_A_survey_Pattern_Recog","https://www.researchgate.net/publication/220955186_Human_Computing_and_Machine_Understanding_of_Human_Behavior_A_Survey","https://www.researchgate.net/publication/221572470_Multimodal_affect_recognition_in_learning_environments","https://www.researchgate.net/publication/221506786_Automatic_3D_Facial_Expression_Analysis_in_Videos","https://www.researchgate.net/publication/221786192_Investigating_Spontaneous_Facial_Action_Recognition_through_AAM_Representations_of_the_Face","https://www.researchgate.net/publication/222541383_Roach_P_Emotional_speech_towards_a_new_generation_of_databases","https://www.researchgate.net/publication/3414121_A_real_time_automated_system_for_the_recognition_of_human_facial_expressions_IEEE_Trans_Syst_Man_Cybern_B_Cybern","https://www.researchgate.net/publication/220515556_Enhancing_relevance_feedback_in_image_retrieval_using_unlabeled_data","https://www.researchgate.net/publication/2986020_Integrating_perceptual_and_cognitive_modeling_for_adaptive_and_intelligent_human-computer_interaction","https://www.researchgate.net/publication/220754220_Motion_history_for_facial_action_detection_in_video","https://www.researchgate.net/publication/3424414_Recognition_of_facial_expressions_and_measurement_of_levels_of_interest_from_video","https://www.researchgate.net/publication/234837419_Facial_and_Vocal_Expressions_of_Emotion","https://www.researchgate.net/publication/3321357_Emotion_recognition_in_human-computer_interaction_Signal_Process_Mag","https://www.researchgate.net/publication/7176535_Patras_I_Dynamics_of_Facial_Expression_Recognition_of_Facial_Actions_and_Their_Temporal_Segments_From_Face_Profile_Image_Sequences_IEEE_Transactions_on_Systems_Man_and_Cybernetics_Part_B_362_433-449","https://www.researchgate.net/publication/221292183_Robust_Full-Motion_Recovery_of_Head_by_Dynamic_Templates_and_Re-Registration_Techniques","https://www.researchgate.net/publication/242632776_Recognition_of_facial_expression_from_optical_flow_IEICE_Trans_E","https://www.researchgate.net/publication/221052708_Foundations_of_Human_Computing_Facial_Expression_and_Emotion","https://www.researchgate.net/publication/222301239_Facial_expression_recognition_from_video_sequences_temporal_and_static_modeling_Comput_Vis_Image_Underst_911-2160-187","https://www.researchgate.net/publication/221483141_Emotion_recognition_by_speech_signals","https://www.researchgate.net/publication/4119597_Manifold_Based_Analysis_of_Facial_Expression","https://www.researchgate.net/publication/221786197_Machine_Analysis_of_Facial_Expressions","https://www.researchgate.net/publication/3412560_A_probabilistic_framework_for_modeling_and_real-time_monitoring_human_fatigue_IEEE_Trans_Syst_Man_Cybernetics_Part_A_Syst_Humans","https://www.researchgate.net/publication/15034529_Strong_Evidence_for_Universals_in_Facial_Expressions_A_Reply_to_Russell's_Mistaken_Critique","https://www.researchgate.net/publication/222415104_Automatic_discrimination_between_laughter_and_speech","https://www.researchgate.net/publication/222741832_Evidence_for_a_Three-Factor_Theory_of_Emotions","https://www.researchgate.net/publication/221052709_Bimodal_HCI-related_affect_recognition","https://www.researchgate.net/publication/221620082_A_Prototype_for_Automatic_Recognition_of_Spontaneous_Facial_Actions","https://www.researchgate.net/publication/228707883_Annotation_and_analysis_of_emotionally_relevant_behavior_in_the_ISL_Meeting_Corpus","https://www.researchgate.net/publication/7782589_Beyond_emotion_archetypes_Databases_for_emotion_modelling_using_neural_networks","https://www.researchgate.net/publication/209436026_'FEELTRACE'_An_instrument_for_recording_perceived_emotion_in_real_time","https://www.researchgate.net/publication/221489675_Children's_emotion_recognition_in_an_intelligent_tutoring_scenario","https://www.researchgate.net/publication/235726247_Development_and_Validation_of_Brief_Measures_of_Positive_and_Negative_Affect_The_PANAS_Scales"]}