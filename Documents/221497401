{"id":221497401,"title":"Lower Bounds on the Sample Complexity of Exploration in the Multi-armed Bandit Problem","authors":["Shie Mannor","John N. Tsitsiklis"],"_abstract":"We consider the Multi-armed bandit problem under the PAC (\"probably approximately correct\") model. It was shown by Even-Dar et al. (5) that given n arms, it suces to play the arms a total of O (n=\"2)log(1=-) times to find an \"-optimal arm with probability of at least 1ยก-. Our contribution is a matching lower bound that holds for any sampling policy. We also generalize the lower bound to a Bayesian setting, and to the case where the statistics of the arms are known but the identities of the arms are not.","cited_in":[{"id":275587982,"url":"https://www.researchgate.net/publication/275587982_Old_version"},{"id":273067644,"url":"https://www.researchgate.net/publication/273067644_Influence_Maximization_with_Bandits"},{"id":263545276,"url":"https://www.researchgate.net/publication/263545276_Unimodal_Bandits_without_Smoothness"},{"id":262452441,"url":"https://www.researchgate.net/publication/262452441_Multiple-Environment_Markov_Decision_Processes"},{"id":230802961,"url":"https://www.researchgate.net/publication/230802961_The_Sample_Complexity_of_Search_over_Multiple_Populations"},{"id":254056798,"url":"https://www.researchgate.net/publication/254056798_Sensing_and_Probing_Cardinalities_for_Active_Cognitive_Radios"},{"id":221706417,"url":"https://www.researchgate.net/publication/221706417_Real-Time_Scheduling_via_Reinforcement_Learning"},{"id":221664696,"url":"https://www.researchgate.net/publication/221664696_Finding_a_most_biased_coin_with_fewest_flips"},{"id":235683569,"url":"https://www.researchgate.net/publication/235683569_Considering_the_high_level_critical_situations_in_context-_Aware_recommender_systems"},{"id":235683564,"url":"https://www.researchgate.net/publication/235683564_Considering_the_High_Level_Critical_Situations_in_Con-text-Aware_Recommender_Systems"},{"id":220271986,"url":"https://www.researchgate.net/publication/220271986_Learning_to_trade_off_between_exploration_and_exploitation_in_multiclass_bandit_prediction"},{"id":2942622,"url":"https://www.researchgate.net/publication/2942622_The_Sample_Complexity_of_Exploration_in_the_Multi-Armed_Bandit_Problem"},{"id":228780026,"url":"https://www.researchgate.net/publication/228780026_Mathematical_Approaches_to_Infectious_Disease_Prediction_and_Control"},{"id":221344630,"url":"https://www.researchgate.net/publication/221344630_Efficient_Exploration_With_Latent_Structure"},{"id":216301621,"url":"https://www.researchgate.net/publication/216301621_Multi-armed_Bandit_Algorithms_and_Empirical_Evaluation"},{"id":256761419,"url":"https://www.researchgate.net/publication/256761419_Mathematical_psychology-A_perspective"},{"id":220320322,"url":"https://www.researchgate.net/publication/220320322_Action_Elimination_and_Stopping_Conditions_for_the_Multi-Armed_Bandit_and_Reinforcement_Learning_Problems"},{"id":221445026,"url":"https://www.researchgate.net/publication/221445026_An_adaptive_algorithm_for_selecting_profitable_keywords_for_search-based_advertising_services"},{"id":1959227,"url":"https://www.researchgate.net/publication/1959227_Nearly_Optimal_Exploration-Exploitation_Decision_Thresholds"},{"id":221618746,"url":"https://www.researchgate.net/publication/221618746_Near-optimal_Regret_Bounds_for_Reinforcement_Learning"},{"id":220864723,"url":"https://www.researchgate.net/publication/220864723_Efficient_Reinforcement_Learning_in_Parameterized_Models_Discrete_Parameter_Case"},{"id":225106706,"url":"https://www.researchgate.net/publication/225106706_Online_Regret_Bounds_for_Markov_Decision_Processes_with_Deterministic_Transitions"},{"id":221497408,"url":"https://www.researchgate.net/publication/221497408_The_K-armed_Dueling_Bandits_Problem"},{"id":228706258,"url":"https://www.researchgate.net/publication/228706258_The_adaptive_k-Meteorologists_problem_and_its_application_to_structure_learning_and_feature_selection_in_reinforcement_learning"},{"id":224381368,"url":"https://www.researchgate.net/publication/224381368_Optimal_Contraction_Theorem_for_Exploration-Exploitation_Tradeoff_in_Search_and_Optimization"},{"id":224471879,"url":"https://www.researchgate.net/publication/224471879_Regret_and_Convergence_Bounds_for_a_Class_of_Continuum-Armed_Bandit_Problems"},{"id":221394179,"url":"https://www.researchgate.net/publication/221394179_Pure_Exploration_in_Multi-armed_Bandits_Problems"},{"id":220320931,"url":"https://www.researchgate.net/publication/220320931_Reinforcement_learning_in_finite_MDPs_PAC_analysis"},{"id":220696313,"url":"https://www.researchgate.net/publication/220696313_Algorithms_for_Reinforcement_Learning"},{"id":225438563,"url":"https://www.researchgate.net/publication/225438563_Multi-armed_Bandits_with_Episode_Context"},{"id":241179622,"url":"https://www.researchgate.net/publication/241179622_Modification_of_UCT_Algorithm_with_Quiescent_Search_in_Computer_GO"},{"id":220155291,"url":"https://www.researchgate.net/publication/220155291_Online_regret_bounds_for_Markov_decision_processes_with_deterministic_transitions"},{"id":226908641,"url":"https://www.researchgate.net/publication/226908641_UCB_revisited_Improved_regret_bounds_for_the_stochastic_multi-armed_bandit_problem"},{"id":228449097,"url":"https://www.researchgate.net/publication/228449097_System_Identification_with_Binary_Observations_by_Stochastic_Approximation_and_Active_Learning"},{"id":49800511,"url":"https://www.researchgate.net/publication/49800511_Optimizing_Tactics_for_Use_of_the_US_Antiviral_Strategic_National_Stockpile_for_Pandemic_Influenza"},{"id":222523650,"url":"https://www.researchgate.net/publication/222523650_Pure_exploration_in_finitely-armed_and_continuous-armed_bandits"},{"id":224959372,"url":"https://www.researchgate.net/publication/224959372_Multiple_Identifications_in_Multi-Armed_Bandits"},{"id":228095663,"url":"https://www.researchgate.net/publication/228095663_On_the_Sample_Complexity_of_Reinforcement_Learning_with_a_GenerativeModel"},{"id":235683567,"url":"https://www.researchgate.net/publication/235683567_A_Contextual_Bandit_Algorithm_for_Mobile_Context-Aware_Recommender_System"},{"id":235601691,"url":"https://www.researchgate.net/publication/235601691_Adaptive_Crowdsourcing_Algorithms_for_the_Bandit_Survey_Problem"},{"id":260303043,"url":"https://www.researchgate.net/publication/260303043_The_Sample_Complexity_of_Search_Over_Multiple_Populations"},{"id":256070067,"url":"https://www.researchgate.net/publication/256070067_The_Sample-Complexity_of_General_Reinforcement_Learning"},{"id":259478458,"url":"https://www.researchgate.net/publication/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits"},{"id":269307620,"url":"https://www.researchgate.net/publication/269307620_Best-arm_identification_algorithms_for_multi-armed_bandits_in_the_fixed_confidence_setting"},{"id":262302696,"url":"https://www.researchgate.net/publication/262302696_On_the_Complexity_of_AB_Testing"},{"id":265854803,"url":"https://www.researchgate.net/publication/265854803_Near-optimal_PAC_bounds_for_discounted_MDPs"},{"id":281854812,"url":"https://www.researchgate.net/publication/281854812_Combinatorial_pure_exploration_of_multi-armed_bandits"},{"id":269775778,"url":"https://www.researchgate.net/publication/269775778_Improving_daily_deals_recommendation_using_explore-then-exploit_strategies"},{"id":271771759,"url":"https://www.researchgate.net/publication/271771759_Sparse_Dueling_Bandits"},{"id":279168177,"url":"https://www.researchgate.net/publication/279168177_A_perpetual_search_for_talents_across_overlapping_generations_A_learning_process"},{"id":280590277,"url":"https://www.researchgate.net/publication/280590277_Optimally_Confident_UCB_Improved_Regret_for_Finite-Armed_Bandits"},{"id":286933304,"url":"https://www.researchgate.net/publication/286933304_Wrong_version"}],"reference":["https://www.researchgate.net/publication/220616937_The_Non-Stochastic_Multi-Armed_Bandit_Problem","https://www.researchgate.net/publication/239292007_Asymptotically_efficient_adaptive_allocation_rules1","https://www.researchgate.net/publication/3023642_Finite-Time_Lower_Bounds_for_the_Two-Armed_Bandit_Problem","https://www.researchgate.net/publication/220343796_Finite-time_Analysis_of_the_Multiarmed_Bandit_Problem","https://www.researchgate.net/publication/2265004_Gambling_in_a_rigged_casino_The_adversarial_multi-armed_bandit_problem","https://www.researchgate.net/publication/221499155_Gambling_in_a_Rigged_Casino_The_Adversarial_Multi-Arm_Bandit_Problem","https://www.researchgate.net/publication/239064206_Asymptotically_optimal_procedures_for_sequential_adaptive_selection_of_the_best_of_several_normal_means","https://www.researchgate.net/publication/244955528_A_Dynamic_Allocation_Index_for_the_Sequential_Design_of_Experiments","https://www.researchgate.net/publication/265459088_Sequential_Analysis_Tests_and_Confidence_Intervals","https://www.researchgate.net/publication/225176417_PAC_Bounds_for_Multi-armed_Bandit_and_Markov_Decision_Processes","https://www.researchgate.net/publication/201976486_Some_Aspects_of_the_Sequential_Design_of_Experiments","https://www.researchgate.net/publication/220695511_Neural_Network_Learning_Theoretical_Foundations","https://www.researchgate.net/publication/259032648_Stochastic_Processes"]}