{"id":257267505,"title":"Speaker state recognition using an HMM-based feature extraction method","authors":["R. Gajšek","France Mihelic","Simon Dobrisek"],"_abstract":"In this article we present an efficient approach to modeling the acoustic features for the tasks of recognizing various paralinguistic phenomena. Instead of the standard scheme of adapting the Universal Background Model (UBM), represented by the Gaussian Mixture Model (GMM), normally used to model the frame-level acoustic features, we propose to represent the UBM by building a monophone-based Hidden Markov Model (HMM). We present two approaches: transforming the monophone-based segmented HMM–UBM to a GMM–UBM and proceeding with the standard adaptation scheme, or to perform the adaptation directly on the HMM–UBM. Both approaches give superior results than the standard adaptation scheme (GMM–UBM) in both the emotion recognition task and the alcohol detection task. Furthermore, with the proposed method we were able to achieve better results than the current state-of-the-art systems in both tasks.","cited_in":[{"id":286924958,"url":"https://www.researchgate.net/publication/286924958_Annotators'_agreement_and_spontaneous_emotion_classification_performance"},{"id":286681269,"url":"https://www.researchgate.net/publication/286681269_Location_of_an_emotionally_neutral_region_in_valence-arousal_space_Two-class_vs_three-class_cross_corpora_emotion_recognition_evaluations"},{"id":261265181,"url":"https://www.researchgate.net/publication/261265181_Parameter_Optimization_Issues_for_Cross-corpora_Emotion_Classification"},{"id":259065800,"url":"https://www.researchgate.net/publication/259065800_Modeling_phonetic_pattern_variability_in_favor_of_the_creation_of_robust_emotion_classifiers_for_real-life_applications"},{"id":2446719,"url":"https://www.researchgate.net/publication/2446719_Improvements_to_Platt's_SMO_Algorithm_for_SVM_Classifier_Design"},{"id":272180459,"url":"https://www.researchgate.net/publication/272180459_Analysis_and_assessment_of_state_relevance_in_HMM-based_feature_extraction_method"},{"id":261271683,"url":"https://www.researchgate.net/publication/261271683_Determining_the_Smallest_Emotional_Unit_for_Level_of_Arousal_Classification"},{"id":272537514,"url":"https://www.researchgate.net/publication/272537514_Comparison_of_speaker_dependent_and_speaker_independent_emotion_recognition"},{"id":262363611,"url":"https://www.researchgate.net/publication/262363611_Strategies_for_Exploiting_Independent_Cloud_Implementations_of_Biometric_Experts_in_Multibiometric_Scenarios"},{"id":263094221,"url":"https://www.researchgate.net/publication/263094221_Beyond_parametric_score_normalisation_in_biometric_verification_systems"},{"id":282710309,"url":"https://www.researchgate.net/publication/282710309_An_artificial_neural_networks_model_by_using_wavelet_analysis_for_speaker_recognition"},{"id":284887199,"url":"https://www.researchgate.net/publication/284887199_A_Novel_Approach_for_Speaker_Recognition_by_Using_Wavelet_Analysis_and_Support_Vector_Machines"}],"reference":["https://www.researchgate.net/publication/222650661_Recognising_realistic_emotions_and_affect_in_speech_State_of_the_art_and_lessons_learnt_from_the_first_challenge","https://www.researchgate.net/publication/220543125_SMOTE_Synthetic_Minority_Over-sampling_Technique","https://www.researchgate.net/publication/226871174_Spoken_Language_Resources_at_LUKS_of_the_University_of_Ljubljana","https://www.researchgate.net/publication/222674333_Speaker_Verification_Using_Adapted_Gaussian_Mixture_Models","https://www.researchgate.net/publication/224096783_Acoustic_emotion_recognition_A_benchmark_comparison_of_performances","https://www.researchgate.net/publication/234786663_Fast_Training_of_Support_Vector_Machines_Using_Sequential_Minimal_Optimization","https://www.researchgate.net/publication/221486512_University_of_Ljubljana_System_for_Interspeech_2011_Speaker_State_Challenge","https://www.researchgate.net/publication/3321357_Emotion_recognition_in_human-computer_interaction_Signal_Process_Mag","https://www.researchgate.net/publication/221481381_The_INTERSPEECH_2010_paralinguistic_challenge","https://www.researchgate.net/publication/27356074_SpeechNon-Speech_Segmentation_Based_on_Phoneme_Recognition_Features","https://www.researchgate.net/publication/220931779_Multi-modal_Emotion_Recognition_Using_Canonical_Correlations_and_Acoustic_Features","https://www.researchgate.net/publication/38364607_A_Maximization_Technique_Occurring_in_Statistical_Analysis_of_Probabilistic_Functions_of_Markov_Chains","https://www.researchgate.net/publication/222820384_Whodunnit_-_Searching_for_the_Most_Important_Feature_Types_Signalling_Emotion-Related_User_States_in_Speech","https://www.researchgate.net/publication/221480383_Brno_University_of_Technology_system_for_Interspeech_2010_Paralinguistic_Challenge","https://www.researchgate.net/publication/215990408_The_weka_data_mining_software_an_update_SIGKDD_Explor_Newsl","https://www.researchgate.net/publication/221995817_Maximum_Likelihood_from_Incomplete_Data_Via_EM_Algorithm","https://www.researchgate.net/publication/221484470_Age_and_gender_recognition_based_on_multiple_systems_-_early_vs_late_fusion","https://www.researchgate.net/publication/221481970_Brno_University_of_Technology_system_for_interspeech_2009_Emotion_Challenge","https://www.researchgate.net/publication/224640889_Discriminative_Training_Techniques_for_Acoustic_Language","https://www.researchgate.net/publication/225812709_Alcohol_language_corpus_The_first_public_corpus_of_alcoholized_German_speech","https://www.researchgate.net/publication/220116316_Private_emotions_versus_social_interaction_A_data-driven_approach_towards_analysing_emotion_in_speech","https://www.researchgate.net/publication/221485739_Cepstral_and_long-term_features_for_emotion_recognition","https://www.researchgate.net/publication/260673067_An_Algorithm_for_Vector_Quantizer_Design","https://www.researchgate.net/publication/3176788_Mermelstein_P_Comparison_of_parametric_representations_for_monosyllabic_word_recognition_in_continuously_spoken_sentences_IEEE_Trans_Acoust_Speech_Signal_Processing_284_357-366","https://www.researchgate.net/publication/224088060_OpenEAR_-_Introducing_the_Munich_open-source_emotion_and_affect_recognition_toolkit","https://www.researchgate.net/publication/221484084_Automatic_speaker_age_and_gender_recognition_in_the_car_for_tailoring_dialog_and_mobile_services","https://www.researchgate.net/publication/224929655_openSMILE_--_The_Munich_Versatile_and_Fast_Open-Source_Audio_Feature_Extractor","https://www.researchgate.net/publication/2446719_Improvements_to_Platt's_SMO_Algorithm_for_SVM_Classifier_Design","https://www.researchgate.net/publication/224395234_Analysis_of_Emotionally_Salient_Aspects_of_Fundamental_Frequency_for_Emotion_Detection","https://www.researchgate.net/publication/221490308_INTERSPEECH_2007_The_Relevance_of_Feature_Type_for_the_Automatic_Classification_of_Emotional_User_States_Low_Level_Descriptors_and_Functionals","https://www.researchgate.net/publication/221484168_Gender_and_affect_recognition_based_on_GMM_and_GMM-UBM_modeling_with_relevance_MAP_estimation","https://www.researchgate.net/publication/3567686_Speaker_adaptation_based_on_MAP_estimation_of_HMM_parameters","https://www.researchgate.net/publication/221482957_Processing_affected_speech_within_human_machine_interaction","https://www.researchgate.net/publication/279573458_Gender_and_affect_recognition_based_on_GMM_and_GMM-UBM_modeling_with_relevance_MAP_estimation","https://www.researchgate.net/publication/224929624_The_interspeech_2011_speaker_state_challenge"]}