{"id":281276446,"title":"Emotion Recognition In The Wild Challenge 2014: Baseline, Data and Protocol","authors":["Abhinav Dhall","Roland Goecke","Jyoti Joshi","Karan Sikka","Tom Gedeon"],"_abstract":"ABSTRACT The Second Emotion Recognition In The Wild Challenge (EmotiW) 2014 consists of an audio-video based emotion classification challenge, which mimics the real-world conditions. Traditionally, emotion recognition has been performed on data captured in constrained lab-controlled like environment. While this data was a good starting point, such lab controlled data poorly represents the environment and conditions faced in real-world situations. With the exponential increase in the number of video clips being up-loaded online, it is worthwhile to explore the performance of emotion recognition methods that work 'in the wild'. The goal of this Grand Challenge is to carry forward the common platform defined during EmotiW 2013, for evaluation of emotion recognition methods in real-world conditions. The database in the 2014 challenge is the Acted Facial Expression In Wild (AFEW) 4.0, which has been collected from movies showing close-to-real-world conditions. The paper describes the data partitions, the baseline method and the experimental protocol.","cited_in":[{"id":284593847,"url":"https://www.researchgate.net/publication/284593847_Video_and_Image_based_Emotion_Recognition_Challenges_in_the_Wild_EmotiW_2015"},{"id":281829158,"url":"https://www.researchgate.net/publication/281829158_Transductive_Transfer_LDA_with_Riesz-based_Volume_LBP_for_Emotion_Recognition_in_The_Wild"},{"id":282573799,"url":"https://www.researchgate.net/publication/282573799_Contrasting_and_Combining_Least_Squares_Based_Learners_for_Emotion_Recognition_in_the_Wild"},{"id":283315956,"url":"https://www.researchgate.net/publication/283315956_ICMI2015_SEU"},{"id":288492522,"url":"https://www.researchgate.net/publication/288492522_Emotion_Recognition_in_the_Wild"},{"id":282546849,"url":"https://www.researchgate.net/publication/282546849_The_recognition_of_acted_interpersonal_stance_in_police_interrogations_and_the_influence_of_actor_proficiency"},{"id":284126862,"url":"https://www.researchgate.net/publication/284126862_Video_modeling_and_learning_on_Riemannian_manifold_for_emotion_recognition_in_the_wild"},{"id":284234337,"url":"https://www.researchgate.net/publication/284234337_Combining_feature-level_and_decision-level_fusion_in_a_hierarchical_classifier_for_emotion_recognition_in_the_wild"},{"id":288617204,"url":"https://www.researchgate.net/publication/288617204_Emotion_recognition_in_the_wild_via_sparse_transductive_transfer_linear_discriminant_analysis"},{"id":290789182,"url":"https://www.researchgate.net/publication/290789182_Hierarchical_committee_of_deep_convolutional_neural_networks_for_robust_facial_expression_recognition"}],"reference":["https://www.researchgate.net/publication/42803851_Automatic_Recognition_of_Facial_Actions_in_Spontaneous_Expressions","https://www.researchgate.net/publication/262313360_Emotion_Recognition_In_The_Wild_Challenge_2013","https://www.researchgate.net/publication/229049764_Acted_Facial_Expressions_In_The_Wild_Database","https://www.researchgate.net/publication/221429947_Static_facial_expression_analysis_in_tough_conditions_Data_evaluation_protocol_and_benchmark","https://www.researchgate.net/publication/256575180_Collecting_Large_Richly_Annotated_Facial-Expression_Databases_from_Movies","https://www.researchgate.net/publication/256575279_Finding_Happiest_Moments_in_a_Social_Context","https://www.researchgate.net/publication/269300028_A_discriminative_parts_based_model_approach_for_fiducial_points_free_and_shape_constrained_head_pose_normalisation_in_the_wild","https://www.researchgate.net/publication/224088060_OpenEAR_-_Introducing_the_Munich_open-source_emotion_and_affect_recognition_toolkit","https://www.researchgate.net/publication/224929655_openSMILE_--_The_Munich_Versatile_and_Fast_Open-Source_Audio_Feature_Extractor","https://www.researchgate.net/publication/225223935_Pictorial_Structures_for_Object_Recognition","https://www.researchgate.net/publication/3845529_Comprehesive_database_for_facial_expression_analysis","https://www.researchgate.net/publication/266654707_Partial_least_squares_regression_on_Grassmannian_manifold_for_emotion_recognition","https://www.researchgate.net/publication/221481381_The_INTERSPEECH_2010_paralinguistic_challenge","https://www.researchgate.net/publication/221622197_AVEC_2011-The_First_International_AudioVisual_Emotion_Challenge","https://www.researchgate.net/publication/261319549_Weakly_supervised_pain_localization_using_multiple_instance_learning","https://www.researchgate.net/publication/266654836_Multiple_kernel_learning_for_emotion_recognition_in_the_wild","https://www.researchgate.net/publication/220182938_Toward_Practical_Smile_Detection","https://www.researchgate.net/publication/261479309_Supervised_Descent_Method_and_Its_Applications_to_Face_Alignment","https://www.researchgate.net/publication/6397809_Dynamic_Texture_Recognition_Using_Local_Binary_Patterns_with_an_Application_to_Facial_Expressions","https://www.researchgate.net/publication/261306328_Face_Detection_Pose_Estimation_and_Landmark_Localization_in_the_Wild"]}