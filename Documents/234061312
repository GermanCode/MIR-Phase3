{"id":234061312,"title":"Best Arm Identification: A Unified Approach to Fixed Budget and Fixed Confidence","authors":["Victor Gabillon","Mohammad Ghavamzadeh","Alessandro Lazaric"],"_abstract":"ABSTRACT We study the problem of identifying the best arm(s) in the stochastic multi-armed bandit setting. This problem has been studied in the literature from two different perspectives: fixed budget and fixed confidence. We propose a unifying approach that leads to a meta-algorithm called unified gap-based exploration (UGapE), with a common structure and similar theoretical analysis for these two settings. We prove a performance bound for the two versions of the algorithm showing that the two problems are characterized by the same notion of complexity. We also show how the UGapE algorithm as well as its theoretical analysis can be extended to take into account the variance of the arms and to multiple bandits. Finally, we evaluate the performance of UGapE and compare it with a number of existing fixed budget and fixed confidence algorithms.","cited_in":[{"id":287201243,"url":"https://www.researchgate.net/publication/287201243_Approximative_Pareto_Front_Identification"},{"id":273067644,"url":"https://www.researchgate.net/publication/273067644_Influence_Maximization_with_Bandits"},{"id":267632371,"url":"https://www.researchgate.net/publication/267632371_Pareto_Upper_Confidence_Bounds_algorithms_an_empirical_study"},{"id":265967035,"url":"https://www.researchgate.net/publication/265967035_Best-Arm_Identification_in_Linear_Bandits"},{"id":261925202,"url":"https://www.researchgate.net/publication/261925202_Epsilon_approximate_Pareto_optimal_set_of_arm_identification_in_multi-objective_multi-armed_bandits"},{"id":277332487,"url":"https://www.researchgate.net/publication/277332487_Optimistic_Planning_in_Markov_Decision_Processes_Using_a_Generative_Model"},{"id":281854812,"url":"https://www.researchgate.net/publication/281854812_Combinatorial_pure_exploration_of_multi-armed_bandits"}],"reference":["https://www.researchgate.net/publication/221497549_Best_Arm_Identification_in_Multi-Armed_Bandits","https://www.researchgate.net/publication/220343796_Finite-time_Analysis_of_the_Multiarmed_Bandit_Problem","https://www.researchgate.net/publication/221394179_Pure_Exploration_in_Multi-armed_Bandits_Problems","https://www.researchgate.net/publication/224959372_Multiple_Identifications_in_Multi-Armed_Bandits","https://www.researchgate.net/publication/221664771_Active_Learning_for_Developing_Personalized_Treatment","https://www.researchgate.net/publication/220320322_Action_Elimination_and_Stopping_Conditions_for_the_Multi-Armed_Bandit_and_Reinforcement_Learning_Problems","https://www.researchgate.net/publication/234061317_Multi-Bandit_Best_Arm_Identification","https://www.researchgate.net/publication/221344896_Efficient_Selection_of_Multiple_Bandit_Arms_Theory_and_Practice","https://www.researchgate.net/publication/268291396_PAC_Subset_Selection_in_Stochastic_Multi-armed_Bandits","https://www.researchgate.net/publication/2360567_Hoeffding_Races_Accelerating_Model_Selection_Search_for_Classification_and_Function_Approximation","https://www.researchgate.net/publication/45863486_Empirical_Bernstein_Bounds_and_Sample_Variance_Penalization","https://www.researchgate.net/publication/221346082_Empirical_Bernstein_stopping","https://www.researchgate.net/publication/201976486_Some_Aspects_of_the_Sequential_Design_of_Experiments"]}