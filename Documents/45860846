{"id":45860846,"title":"Riemannian Manifold Hamiltonian Monte Carlo","authors":["Mark Girolami","Ben Calderhead","Siu A. Chin"],"_abstract":"ABSTRACT The paper proposes a Riemannian Manifold Hamiltonian Monte Carlo sampler to resolve the shortcomings of existing Monte Carlo algorithms when sampling from target densities that may be high dimensional and exhibit strong correlations. The method provides a fully automated adaptation mechanism that circumvents the costly pilot runs required to tune proposal densities for Metropolis-Hastings or indeed Hybrid Monte Carlo and Metropolis Adjusted Langevin Algorithms. This allows for highly efficient sampling even in very high dimensions where different scalings may be required for the transient and stationary phases of the Markov chain. The proposed method exploits the Riemannian structure of the parameter space of statistical models and thus automatically adapts to the local manifold structure at each step based on the metric tensor. A semi-explicit second order symplectic integrator for non-separable Hamiltonians is derived for simulating paths across this manifold which provides highly efficient convergence and exploration of the target density. The performance of the Riemannian Manifold Hamiltonian Monte Carlo method is assessed by performing posterior inference on logistic regression models, log-Gaussian Cox point processes, stochastic volatility models, and Bayesian estimation of parameter posteriors of dynamical systems described by nonlinear differential equations. Substantial improvements in the time normalised Effective Sample Size are reported when compared to alternative sampling approaches. Matlab code at \\url{http://www.dcs.gla.ac.uk/inference/rmhmc} allows replication of all results.","cited_in":[{"id":220270112,"url":"https://www.researchgate.net/publication/220270112_Variational_Bounds_for_Mixed-Data_Factor_Analysis"},{"id":45897328,"url":"https://www.researchgate.net/publication/45897328_Optimal_tuning_of_the_Hybrid_Monte-Carlo_Algorithm"},{"id":227522317,"url":"https://www.researchgate.net/publication/227522317_Particle_Markov_Chain_Monte_Carlo"},{"id":47820239,"url":"https://www.researchgate.net/publication/47820239_Slice_Sampling_with_Adaptive_Multivariate_Steps_The_Shrinking-Rank_Method"},{"id":251600427,"url":"https://www.researchgate.net/publication/251600427_Natural_computing_for_mechanical_systems_research_A_tutorial_overview"},{"id":227423874,"url":"https://www.researchgate.net/publication/227423874_Hybrid_Monte_Carlo_on_Hilbert_spaces"},{"id":225291078,"url":"https://www.researchgate.net/publication/225291078_MCMC_using_Hamiltonian_dynamics"},{"id":259044429,"url":"https://www.researchgate.net/publication/259044429_Goodness_of_Fit_in_Nonlinear_Dynamics_Mis-specified_Rates_or_Mis-specified_States"}],"reference":["https://www.researchgate.net/publication/221618852_Accelerating_Bayesian_Inference_over_Nonlinear_Differential_Equations_with_Gaussian_Processes","https://www.researchgate.net/publication/2834582_Scaling_Limits_for_the_Transient_Phase_of_Local_Metropolis-Hastings_Algorithms","https://www.researchgate.net/publication/243082537_Extending_Fisher's_Measure_of_Information","https://www.researchgate.net/publication/2800624_Applications_of_Hybrid_Monte_Carlo_to_Bayesian_Generalized_Linear_Models_Quasicomplete_Separation_and_Neural_Networks","https://www.researchgate.net/publication/38363225_Practical_Markov_Chain_Monte_Carlo_Stat_Sci_7_473-483","https://www.researchgate.net/publication/49458431_A_tutorial_on_adaptive_MCMC","https://www.researchgate.net/publication/241904784_Efficient_cosmological_parameter_estimation_with_Hamiltonian_Monte_Carlo_technique","https://www.researchgate.net/publication/226460107_Langevin_Diffusions_and_Metropolis-Hastings_Algorithms","https://www.researchgate.net/publication/2335004_Machine_Learning_Neural_and_Statistical_Classification_Ellis_Horwood"]}